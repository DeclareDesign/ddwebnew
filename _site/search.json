[
  {
    "objectID": "randomizr/news.html",
    "href": "randomizr/news.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "Added a NEWS.md file to track changes to the package.\nRemoved suggests dependency of blockTools per Prof. Ripley email (the package was removed from CRAN)\nAdded Graeme Blair as a contributor\nSmall bug fixes\nAdded permutation support for random sampling functions"
  },
  {
    "objectID": "randomizr/articles/srandomizr_vignette.html",
    "href": "randomizr/articles/srandomizr_vignette.html",
    "title": "Design and Analysis of Experiments with randomizr (Stata)",
    "section": "",
    "text": "A hazy understanding of the random assignment procedure leads to two main problems at the analysis stage. First, units may have different probabilities of assignment to treatment. Analyzing the data as though they have the same probabilities of assignment leads to biased estimates of the treatment effect. Second, units are sometimes assigned to treatment as a cluster. For example, all the students in a single classroom may be assigned to the same intervention together. If the analysis ignores the clustering in the assignments, estimates of average causal effects and the uncertainty attending to them may be incorrect.\n\nA Hypothetical Experiment\nThroughout this vignette, we’ll pretend we’re conducting an experiment among the 592 individuals in R’s HairEyeColor dataset. As we’ll see, there are many ways to randomly assign subjects to treatments. We’ll step through five common designs, each associated with one of the five randomizr functions: simple_ra, complete_ra, block_ra, cluster_ra, and block_and_cluster_ra.\nTypically, researchers know some basic information about their subjects before deploying treatment. For example, they usually know how many subjects there are in the experimental sample (N), and they usually know some basic demographic information about each subject.\nOur new dataset has 592 subjects. We have three pretreatment covariates, Hair, Eye, and Sex, which describe the hair color, eye color, and gender of each subject. We also have potential outcomes. We call the untreated outcome Y0 and we call the treated outcome Y1.\n      . clear all\n\n\n      . use HairEyeColor\n      (Written by R.              )\n\n      . des\n\n      Contains data from HairEyeColor.dta\n        obs:           592                          Written by R.              \n       vars:             6                          28 Aug 2017 01:24\n       size:        18,944                          \n      -----------------------------------------------------------------------------------\n                    storage   display    value\n      variable name   type    format     label      variable label\n      -----------------------------------------------------------------------------------\n      Hair            long    %9.0g      Hair       Hair\n      Eye             long    %9.0g      Eye        Eye\n      Sex             long    %9.0g      Sex        Sex\n      Y1              double  %9.0g                 Y1\n      Y0              double  %9.0g                 Y0\n      id              float   %9.0g                 \n      -----------------------------------------------------------------------------------\n      Sorted by: \n\n      . list in 1/5\n\n           +---------------------------------------------------+\n           |  Hair     Eye    Sex          Y1          Y0   id |\n           |---------------------------------------------------|\n        1. | Black   Brown   Male   -2.983882   -14.98388    1 |\n        2. | Black   Brown   Male    6.616561   -5.383439    2 |\n        3. | Black   Brown   Male    4.711323   -7.288677    3 |\n        4. | Black   Brown   Male   -.2332402   -12.23324    4 |\n        5. | Black   Brown   Male    1.940893   -10.05911    5 |\n           +---------------------------------------------------+\n\n      . set seed 324437641\nImagine that in the absence of any intervention, the outcome (Y0) is correlated with out pretreatment covariates. Imagine further that the effectiveness of the program varies according to these covariates, i.e., the difference between Y1 and Y0 is correlated with the pretreatment covariates.\nIf we were really running an experiment, we would only observe either Y0 or Y1 for each subject, but since we are simulating, we have both. Our inferential target is the average treatment effect (ATE), which is defined as the average difference between Y0 and Y1.\n\n\nSimple Random Assignment\nSimple random assignment assigns all subjects to treatment with an equal probability by flipping a (weighted) coin for each subject. The main trouble with simple random assignment is that the number of subjects assigned to treatment is itself a random number - depending on the random assignment, a different number of subjects might be assigned to each group.\nThe simple_ra function has no required arguments. If no other arguments are specified, simple_ra assumes a two-group design and a 0.50 probability of assignment.\n      . simple_ra Z\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                0 |        294       49.66       49.66\n                1 |        298       50.34      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nTo change the probability of assignment, specify the prob argument:\n      . simple_ra Z, replace prob(.3)\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                0 |        423       71.45       71.45\n                1 |        169       28.55      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nIf you specify num_arms without changing prob_each, simple_ra will assume equal probabilities across all arms.\n      . simple_ra Z, replace num_arms(3)\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                1 |        186       31.42       31.42\n                2 |        193       32.60       64.02\n                3 |        213       35.98      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nYou can also just specify the probabilities of your multiple arms. The probabilities must sum to 1.\n      . simple_ra Z, replace prob_each(.2 .2 .6)\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                1 |        138       23.31       23.31\n                2 |        110       18.58       41.89\n                3 |        344       58.11      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nYou can also name your treatment arms.\n      . simple_ra Z, replace prob_each(.2 .2 .6) conditions(control placebo treatment)\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n          control |        105       17.74       17.74\n          placebo |        119       20.10       37.84\n        treatment |        368       62.16      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\n\n\nComplete Random Assignment\nComplete random assignment is very similar to simple random assignment, except that the researcher can specify exactly how many units are assigned to each condition.\nThe syntax for complete_ra is very similar to that of simple_ra. The argument m is the number of units assigned to treatment in two-arm designs; it is analogous to simple_ra’s prob. Similarly, the argument m_each is analogous to prob_each.\nIf you specify no arguments in complete_ra, it assigns exactly half of the subjects to treatment.\n      . complete_ra Z, replace\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                0 |        296       50.00       50.00\n                1 |        296       50.00      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nTo change the number of units assigned, specify the m argument:\n      . complete_ra Z, m(200) replace\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                0 |        392       66.22       66.22\n                1 |        200       33.78      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nIf you specify multiple arms, complete_ra will assign an equal (within rounding) number of units to treatment.\n      . complete_ra Z, num_arms(3) replace\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                1 |        197       33.28       33.28\n                2 |        197       33.28       66.55\n                3 |        198       33.45      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nYou can also specify exactly how many units should be assigned to each arm. The total of m_each must equal N.\n      . complete_ra Z, m_each(100 200 292) replace\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                1 |        100       16.89       16.89\n                2 |        200       33.78       50.68\n                3 |        292       49.32      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\nYou can also name your treatment arms.\n      . complete_ra Z, m_each(100 200 292) replace conditions(control placebo treatment)\n\n\n      . tab Z\n\n                Z |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n          control |        100       16.89       16.89\n          placebo |        200       33.78       50.68\n        treatment |        292       49.32      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\n\n\nSimple and Complete Random Assignment Compared\nWhen should you use simple_ra versus complete_ra? Basically, if the number of units is known beforehand, complete_ra is always preferred, for two reasons: 1. Researchers can plan exactly how many treatments will be deployed. 2. The standard errors associated with complete random assignment are generally smaller, increasing experimental power. See this guide on EGAP for more on experimental power.\nSince you need to know N beforehand in order to use simple_ra, it may seem like a useless function. Sometimes, however, the random assignment isn’t directly in the researcher’s control. For example, when deploying a survey experiment on a platform like Qualtrics, simple random assignment is the only possibility due to the inflexibility of the built-in random assignment tools. When reconstructing the random assignment for analysis after the experiment has been conducted, simple_ra provides a convenient way to do so.\nTo demonstrate how complete_ra is superior to simple_ra, let’s conduct a small simulation with our HairEyeColor dataset.\n      . local sims=1000\n\n      . matrix simple_ests=J(`sims',1,.)        \n\n      . matrix complete_ests=J(`sims',1,.)\n\n      . forval i=1/`sims' {\n      . local seed=32430641+`i'\n      . set seed `seed'\n      . qui simple_ra Z_simple, replace\n      . qui complete_ra Z_complete, replace\n      . qui tempvar Y_simple Y_complete\n      . qui gen `Y_simple' = Y1*Z_simple + Y0*(1-Z_simple)\n      . qui gen `Y_complete' = Y1*Z_complete + Y0*(1-Z_complete)\n      . qui reg `Y_simple' Z_simple\n      . qui matrix simple_ests[`i',1]=_b[Z_simple]\n      . qui reg `Y_complete' Z_complete\n      . qui matrix complete_ests[`i',1]=_b[Z_complete]\n      . }\nThe standard error of an estimate is defined as the standard deviation of the sampling distribution of the estimator. When standard errors are estimated (i.e., by using the summary() command on a model fit), they are estimated using some approximation. This simulation allows us to measure the standard error directly, since the vectors simple_ests and complete_ests describe the sampling distribution of each design.\n      . mata: st_numscalar(\"simple_var\",variance(st_matrix(\"simple_ests\")))\n\n\n      . mata: st_numscalar(\"complete_var\",variance(st_matrix(\"complete_ests\")))\n\n\n      . disp \"Simple RA S.D.: \" sqrt(simple_var)\n      Simple RA S.D.: .62489587\n\n      . disp \"Complete RA S.D.: \"sqrt(complete_var)\n      Complete RA S.D.: .60401434\nIn this simulation complete random assignment led to a 6% decrease in sampling variability. This decrease was obtained with a small design tweak that costs the researcher essentially nothing.\n\n\nBlock Random Assignment\nBlock random assignment (sometimes known as stratified random assignment) is a powerful tool when used well. In this design, subjects are sorted into blocks (strata) according to their pre-treatment covariates, and then complete random assignment is conducted within each block. For example, a researcher might block on gender, assigning exactly half of the men and exactly half of the women to treatment.\nWhy block? The first reason is to signal to future readers that treatment effect heterogeneity may be of interest: is the treatment effect different for men versus women? Of course, such heterogeneity could be explored if complete random assignment had been used, but blocking on a covariate defends a researcher (somewhat) against claims of data dredging. The second reason is to increase precision. If the blocking variables are predictive of the outcome (i.e., they are correlated with the outcome), then blocking may help to decrease sampling variability. It’s important, however, not to overstate these advantages. The gains from a blocked design can often be realized through covariate adjustment alone.\nBlocking can also produce complications for estimation. Blocking can produce different probabilities of assignment for different subjects. This complication is typically addressed in one of two ways: “controlling for blocks” in a regression context, or inverse probability weights (IPW), in which units are weighted by the inverse of the probability that the unit is in the condition that it is in.\nThe only required argument to block_ra is block_var, which is a variable that describes which block a unit belongs to. block_var can be a string or numeric variable. If no other arguments are specified, block_ra assigns an approximately equal proportion of each block to treatment.\n      . block_ra Z, block_var(Hair) replace\n\n      . tab Z Hair\n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n               0 |        54        143         35         64 |       296 \n               1 |        54        143         36         63 |       296 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \nFor multiple treatment arms, use the num_arms argument, with or without the conditions argument\n      . block_ra Z, block_var(Hair) num_arms(3) replace\n\n      . tab Z Hair\n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n               1 |        36         95         24         43 |       198 \n               2 |        36         96         24         42 |       198 \n               3 |        36         95         23         42 |       196 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \n\n\n      . block_ra Z, block_var(Hair) conditions(Control Placebo Treatment) replace\n\n      . tab Z Hair\n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n         Control |        36         96         23         42 |       197 \n         Placebo |        36         95         23         43 |       197 \n       Treatment |        36         95         25         42 |       198 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \nblock_ra provides a number of ways to adjust the number of subjects assigned to each conditions. The prob_each argument describes what proportion of each block should be assigned to treatment arm. Note of course, that block_ra still uses complete random assignment within each block; the appropriate number of units to assign to treatment within each block is automatically determined.\n      . block_ra Z, block_var(Hair) prob_each(.3 .7) replace\n\n      . tab Z Hair\n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n               0 |        75        201         49         88 |       413 \n               1 |        33         85         22         39 |       179 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \nFor finer control, use the block_m_each argument, which takes a matrix with as many rows as there are blocks, and as many columns as there are treatment conditions. Remember that the rows are in the same order as seen in tab block_var, a command that is good to run before constructing a block_m_each matrix. The matrix can either be defined using the matrix define command or be inputted directly into the block_m_each option.\n      . tab Hair \n\n             Hair |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n            Black |        108       18.24       18.24\n            Brown |        286       48.31       66.55\n              Red |         71       11.99       78.55\n            Blond |        127       21.45      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\n\n      . matrix define block_m_each=(78, 30\\186, 100\\51, 20\\87,40)\n\n      . matrix list block_m_each\n\n      block_m_each[4,2]\n           c1   c2\n      r1   78   30\n      r2  186  100\n      r3   51   20\n      r4   87   40\n\n      . block_ra Z, replace block_var(Hair) block_m_each(block_m_each)\n\n\n      . tab Z Hair \n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n               0 |        30        100         20         40 |       190 \n               1 |        78        186         51         87 |       402 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \n\n\n      . block_ra Z, replace block_var(Hair) block_m_each(78, 30\\186, 100\\51, 20\\87,40)\n\n\n      . tab Z Hair      \n\n                 |                    Hair\n               Z |     Black      Brown        Red      Blond |     Total\n      -----------+--------------------------------------------+----------\n               0 |        30        100         20         40 |       190 \n               1 |        78        186         51         87 |       402 \n      -----------+--------------------------------------------+----------\n           Total |       108        286         71        127 |       592 \n\n\nClustered Assignment\nClustered assignment is unfortunate. If you can avoid assigning subjects to treatments by cluster, you should. Sometimes, clustered assignment is unavoidable. Some common situations include:\n\nHousemates in households: whole households are assigned to treatment or control\nStudents in classrooms: whole classrooms are assigned to treatment or control\nResidents in towns or villages: whole communities are assigned to treatment or control\n\nClustered assignment decreases the effective sample size of an experiment. In the extreme case when outcomes are perfectly correlated with clusters, the experiment has an effective sample size equal to the number of clusters. When outcomes are perfectly uncorrelated with clusters, the effective sample size is equal to the number of subjects. Almost all cluster-assigned experiments fall somewhere in the middle of these two extremes.\nThe only required argument for the cluster_ra function is the clust_var argument, which indicates which cluster each subject belongs to. Let’s pretend that for some reason, we have to assign treatments according to the unique combinations of hair color, eye color, and gender.\n      . egen clust_var=group(Hair Eye Sex)\n\n      . tab clust_var\n\n       group(Hair |\n         Eye Sex) |      Freq.     Percent        Cum.\n      ------------+-----------------------------------\n                1 |         32        5.41        5.41\n                2 |         36        6.08       11.49\n                3 |         11        1.86       13.34\n                4 |          9        1.52       14.86\n                5 |         10        1.69       16.55\n                6 |          5        0.84       17.40\n                7 |          3        0.51       17.91\n                8 |          2        0.34       18.24\n                9 |         53        8.95       27.20\n               10 |         66       11.15       38.34\n               11 |         50        8.45       46.79\n               12 |         34        5.74       52.53\n               13 |         25        4.22       56.76\n               14 |         29        4.90       61.66\n               15 |         15        2.53       64.19\n               16 |         14        2.36       66.55\n               17 |         10        1.69       68.24\n               18 |         16        2.70       70.95\n               19 |         10        1.69       72.64\n               20 |          7        1.18       73.82\n               21 |          7        1.18       75.00\n               22 |          7        1.18       76.18\n               23 |          7        1.18       77.36\n               24 |          7        1.18       78.55\n               25 |          3        0.51       79.05\n               26 |          4        0.68       79.73\n               27 |         30        5.07       84.80\n               28 |         64       10.81       95.61\n               29 |          5        0.84       96.45\n               30 |          5        0.84       97.30\n               31 |          8        1.35       98.65\n               32 |          8        1.35      100.00\n      ------------+-----------------------------------\n            Total |        592      100.00\n\n      . cluster_ra Z_clust, cluster_var(clust_var) \n\n      . tab clust_var Z_clust\n\n      group(Hair |        Z_clust\n        Eye Sex) |         0          1 |     Total\n      -----------+----------------------+----------\n               1 |        32          0 |        32 \n               2 |        36          0 |        36 \n               3 |        11          0 |        11 \n               4 |         9          0 |         9 \n               5 |         0         10 |        10 \n               6 |         5          0 |         5 \n               7 |         0          3 |         3 \n               8 |         2          0 |         2 \n               9 |        53          0 |        53 \n              10 |         0         66 |        66 \n              11 |        50          0 |        50 \n              12 |         0         34 |        34 \n              13 |         0         25 |        25 \n              14 |         0         29 |        29 \n              15 |         0         15 |        15 \n              16 |        14          0 |        14 \n              17 |         0         10 |        10 \n              18 |         0         16 |        16 \n              19 |         0         10 |        10 \n              20 |         0          7 |         7 \n              21 |         0          7 |         7 \n              22 |         7          0 |         7 \n              23 |         7          0 |         7 \n              24 |         7          0 |         7 \n              25 |         0          3 |         3 \n              26 |         4          0 |         4 \n              27 |        30          0 |        30 \n              28 |        64          0 |        64 \n              29 |         5          0 |         5 \n              30 |         0          5 |         5 \n              31 |         0          8 |         8 \n              32 |         0          8 |         8 \n      -----------+----------------------+----------\n           Total |       336        256 |       592 \nThis shows that each cluster is either assigned to treatment or control. No two units within the same cluster are assigned to different conditions.\nAs with all functions in randomizr, you can specify multiple treatment arms in a variety of ways:\n      . cluster_ra Z_clust, cluster_var(clust_var) num_arms(3) replace\n\n\n      . tab clust_var Z_clust\n\n      group(Hair |             Z_clust\n        Eye Sex) |         1          2          3 |     Total\n      -----------+---------------------------------+----------\n               1 |        32          0          0 |        32 \n               2 |        36          0          0 |        36 \n               3 |         0          0         11 |        11 \n               4 |         9          0          0 |         9 \n               5 |        10          0          0 |        10 \n               6 |         0          0          5 |         5 \n               7 |         0          3          0 |         3 \n               8 |         0          0          2 |         2 \n               9 |         0         53          0 |        53 \n              10 |        66          0          0 |        66 \n              11 |         0         50          0 |        50 \n              12 |         0         34          0 |        34 \n              13 |         0          0         25 |        25 \n              14 |         0          0         29 |        29 \n              15 |         0         15          0 |        15 \n              16 |        14          0          0 |        14 \n              17 |         0          0         10 |        10 \n              18 |         0          0         16 |        16 \n              19 |         0         10          0 |        10 \n              20 |         0          7          0 |         7 \n              21 |         7          0          0 |         7 \n              22 |         7          0          0 |         7 \n              23 |         0          0          7 |         7 \n              24 |         0          0          7 |         7 \n              25 |         3          0          0 |         3 \n              26 |         0          4          0 |         4 \n              27 |         0         30          0 |        30 \n              28 |        64          0          0 |        64 \n              29 |         0          0          5 |         5 \n              30 |         0          5          0 |         5 \n              31 |         0          0          8 |         8 \n              32 |         0          8          0 |         8 \n      -----------+---------------------------------+----------\n           Total |       248        219        125 |       592 \n…or using conditions.\n      . cluster_ra Z_clust, cluster_var(clust_var) conditions(control placebo treatment)  replace\n\n\n      . tab clust_var Z_clust\n\n      group(Hair |             Z_clust\n        Eye Sex) |   control    placebo  treatment |     Total\n      -----------+---------------------------------+----------\n               1 |        32          0          0 |        32 \n               2 |         0          0         36 |        36 \n               3 |         0          0         11 |        11 \n               4 |         0          0          9 |         9 \n               5 |        10          0          0 |        10 \n               6 |         0          0          5 |         5 \n               7 |         3          0          0 |         3 \n               8 |         0          2          0 |         2 \n               9 |         0         53          0 |        53 \n              10 |         0         66          0 |        66 \n              11 |        50          0          0 |        50 \n              12 |        34          0          0 |        34 \n              13 |        25          0          0 |        25 \n              14 |         0         29          0 |        29 \n              15 |         0          0         15 |        15 \n              16 |         0         14          0 |        14 \n              17 |         0          0         10 |        10 \n              18 |         0         16          0 |        16 \n              19 |         0         10          0 |        10 \n              20 |         7          0          0 |         7 \n              21 |         0          7          0 |         7 \n              22 |         0          7          0 |         7 \n              23 |         7          0          0 |         7 \n              24 |         0          0          7 |         7 \n              25 |         3          0          0 |         3 \n              26 |         0          0          4 |         4 \n              27 |         0          0         30 |        30 \n              28 |        64          0          0 |        64 \n              29 |         5          0          0 |         5 \n              30 |         0          5          0 |         5 \n              31 |         0          0          8 |         8 \n              32 |         0          8          0 |         8 \n      -----------+---------------------------------+----------\n           Total |       240        217        135 |       592 \n… or using m_each, which describes how many clusters should be assigned to each condition. m_each must sum to the number of clusters.\n      . cluster_ra Z_clust, cluster_var(clust_var) m_each(5 15 12) replace\n\n\n      . tab clust_var Z_clust\n\n      group(Hair |             Z_clust\n        Eye Sex) |         1          2          3 |     Total\n      -----------+---------------------------------+----------\n               1 |         0         32          0 |        32 \n               2 |         0          0         36 |        36 \n               3 |         0          0         11 |        11 \n               4 |         0          0          9 |         9 \n               5 |         0         10          0 |        10 \n               6 |         5          0          0 |         5 \n               7 |         0          0          3 |         3 \n               8 |         0          2          0 |         2 \n               9 |         0         53          0 |        53 \n              10 |         0         66          0 |        66 \n              11 |         0          0         50 |        50 \n              12 |         0          0         34 |        34 \n              13 |         0          0         25 |        25 \n              14 |         0          0         29 |        29 \n              15 |         0         15          0 |        15 \n              16 |         0          0         14 |        14 \n              17 |         0          0         10 |        10 \n              18 |         0          0         16 |        16 \n              19 |         0         10          0 |        10 \n              20 |         0          7          0 |         7 \n              21 |         0          7          0 |         7 \n              22 |         7          0          0 |         7 \n              23 |         0          7          0 |         7 \n              24 |         7          0          0 |         7 \n              25 |         0          3          0 |         3 \n              26 |         4          0          0 |         4 \n              27 |         0         30          0 |        30 \n              28 |         0          0         64 |        64 \n              29 |         0          5          0 |         5 \n              30 |         5          0          0 |         5 \n              31 |         0          8          0 |         8 \n              32 |         0          8          0 |         8 \n      -----------+---------------------------------+----------\n           Total |        28        263        301 |       592 \n\n\nBlock and Clustered Assignment\nThe power of clustered experiments can sometimes be improved through blocking. In this scenario, whole clusters are members of a particular block – imagine villages nested within discrete regions, or classrooms nested within discrete schools.\nAs an example, let’s group our clusters into blocks by size\n      . bysort clust_var: egen cluster_size=count(_n)\n\n      . block_and_cluster_ra Z, block_var(cluster_size) cluster_var(clust_var) replace\n\n      . tab clust_var Z\n\n      group(Hair |           Z\n        Eye Sex) |         0          1 |     Total\n      -----------+----------------------+----------\n               1 |        32          0 |        32 \n               2 |         0         36 |        36 \n               3 |         0         11 |        11 \n               4 |         0          9 |         9 \n               5 |        10          0 |        10 \n               6 |         0          5 |         5 \n               7 |         0          3 |         3 \n               8 |         0          2 |         2 \n               9 |        53          0 |        53 \n              10 |         0         66 |        66 \n              11 |         0         50 |        50 \n              12 |         0         34 |        34 \n              13 |         0         25 |        25 \n              14 |        29          0 |        29 \n              15 |         0         15 |        15 \n              16 |        14          0 |        14 \n              17 |         0         10 |        10 \n              18 |        16          0 |        16 \n              19 |         0         10 |        10 \n              20 |         7          0 |         7 \n              21 |         0          7 |         7 \n              22 |         7          0 |         7 \n              23 |         0          7 |         7 \n              24 |         7          0 |         7 \n              25 |         3          0 |         3 \n              26 |         4          0 |         4 \n              27 |        30          0 |        30 \n              28 |         0         64 |        64 \n              29 |         0          5 |         5 \n              30 |         5          0 |         5 \n              31 |         0          8 |         8 \n              32 |         8          0 |         8 \n      -----------+----------------------+----------\n           Total |       225        367 |       592 \n\n\n      . tab cluster_size Z \n\n      cluster_si |           Z\n              ze |         0          1 |     Total\n      -----------+----------------------+----------\n               2 |         0          2 |         2 \n               3 |         3          3 |         6 \n               4 |         4          0 |         4 \n               5 |         5         10 |        15 \n               7 |        21         14 |        35 \n               8 |         8          8 |        16 \n               9 |         0          9 |         9 \n              10 |        10         20 |        30 \n              11 |         0         11 |        11 \n              14 |        14          0 |        14 \n              15 |         0         15 |        15 \n              16 |        16          0 |        16 \n              25 |         0         25 |        25 \n              29 |        29          0 |        29 \n              30 |        30          0 |        30 \n              32 |        32          0 |        32 \n              34 |         0         34 |        34 \n              36 |         0         36 |        36 \n              50 |         0         50 |        50 \n              53 |        53          0 |        53 \n              64 |         0         64 |        64 \n              66 |         0         66 |        66 \n      -----------+----------------------+----------\n           Total |       225        367 |       592"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html",
    "href": "randomizr/articles/randomizr_vignette.html",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "",
    "text": "randomizr is a small package for r that simplifies the design and analysis of randomized experiments. In particular, it makes the random assignment procedure transparent, flexible, and most importantly reproduceable. By the time that many experiments are written up and made public, the process by which some units received treatments is lost or imprecisely described. The randomizr package makes it easy for even the most forgetful of researchers to generate error-free, reproduceable random assignments.\nA hazy understanding of the random assignment procedure leads to two main problems at the analysis stage. First, units may have different probabilities of assignment to treatment. Analyzing the data as though they have the same probabilities of assignment leads to biased estimates of the treatment effect. Second, units are sometimes assigned to treatment as a cluster. For example, all the students in a single classroom may be assigned to the same intervention together. If the analysis ignores the clustering in the assignments, estimates of average causal effects and the uncertainty attending to them may be incorrect."
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#simple-random-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#simple-random-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Simple random assignment",
    "text": "Simple random assignment\nSimple random assignment assigns all subjects to treatment with an equal probability by flipping a (weighted) coin for each subject. The main trouble with simple random assignment is that the number of subjects assigned to treatment is itself a random number - depending on the random assignment, a different number of subjects might be assigned to each group.\nThe simple_ra() function has one required argument N, the total number of subjects. If no other arguments are specified, simple_ra() assumes a two-group design and a 0.50 probability of assignment.\n\nlibrary(randomizr)\nZ <- simple_ra(N = N)\ntable(Z)\n\n\n\n\n\n\n0\n1\n\n\n\n\n301\n291\n\n\n\n\n\nTo change the probability of assignment, specify the prob argument:\n\nZ <- simple_ra(N = N, prob = 0.30)\ntable(Z)\n\n\n\n\n\n\n0\n1\n\n\n\n\n402\n190\n\n\n\n\n\nIf you specify num_arms without changing prob_each, simple_ra() will assume equal probabilities across all arms.\n\nZ <- simple_ra(N = N, num_arms = 3)\ntable(Z)\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\n191\n215\n186\n\n\n\n\n\nYou can also just specify the probabilities of your multiple arms. The probabilities must sum to 1.\n\nZ <- simple_ra(N = N, prob_each = c(.2, .2, .6))\ntable(Z)\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\n118\n119\n355\n\n\n\n\n\nYou can also name your treatment arms.\n\nZ <- simple_ra(N = N, prob_each = c(.2, .2, .6),\n               conditions=c(\"control\", \"placebo\", \"treatment\"))\ntable(Z)\n\n\n\n\n\n\ncontrol\nplacebo\ntreatment\n\n\n\n\n132\n108\n352"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#complete-random-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#complete-random-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Complete random assignment",
    "text": "Complete random assignment\nComplete random assignment is very similar to simple random assignment, except that the researcher can specify exactly how many units are assigned to each condition.\nThe syntax for complete_ra() is very similar to that of simple_ra(). The argument m is the number of units assigned to treatment in two-arm designs; it is analogous to simple_ra()’s prob. Similarly, the argument m_each is analogous to prob_each.\nIf you only specify N, complete_ra() assigns exactly half of the subjects to treatment.\n\nZ <- complete_ra(N = N)\ntable(Z)\n\n\n\n\n\n\n0\n1\n\n\n\n\n296\n296\n\n\n\n\n\nTo change the number of units assigned, specify the m argument:\n\nZ <- complete_ra(N = N, m = 200)\ntable(Z)\n\n\n\n\n\n\n0\n1\n\n\n\n\n392\n200\n\n\n\n\n\nIf you specify multiple arms, complete_ra() will assign an equal (within rounding) number of units to treatment.\n\nZ <- complete_ra(N = N, num_arms = 3)\ntable(Z)\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\n197\n198\n197\n\n\n\n\n\nYou can also specify exactly how many units should be assigned to each arm. The total of m_each must equal N.\n\nZ <- complete_ra(N = N, m_each = c(100, 200, 292))\ntable(Z)\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\n100\n200\n292\n\n\n\n\n\nYou can also name your treatment arms.\n\nZ <- complete_ra(N = N, m_each = c(100, 200, 292),\n               conditions = c(\"control\", \"placebo\", \"treatment\"))\ntable(Z)\n\n\n\n\n\n\ncontrol\nplacebo\ntreatment\n\n\n\n\n100\n200\n292"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#simple-and-complete-random-assignment-compared",
    "href": "randomizr/articles/randomizr_vignette.html#simple-and-complete-random-assignment-compared",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Simple and Complete random assignment compared",
    "text": "Simple and Complete random assignment compared\nWhen should you use simple_ra() versus complete_ra()? Basically, if the number of units is known beforehand, complete_ra() is always preferred, for two reasons: 1. Researchers can plan exactly how many treatments will be deployed. 2. The standard errors associated with complete random assignment are generally smaller, increasing experimental power.\nSince you need to know N beforehand in order to use simple_ra(), it may seem like a useless function. Sometimes, however, the random assignment isn’t directly in the researcher’s control. For example, when deploying a survey experiment on a platform like Qualtrics, simple random assignment is the only possibility due to the inflexibility of the built-in random assignment tools. When reconstructing the random assignment for analysis after the experiment has been conducted, simple_ra() provides a convenient way to do so.\nTo demonstrate how complete_ra() is superior to simple_ra(), let’s conduct a small simulation with our HairEyeColor dataset.\n\nsims <- 1000\n\n# Set up empty vectors to collect results\nsimple_ests <- rep(NA, sims)\ncomplete_ests <- rep(NA, sims)\n\n# Loop through simulation 2000 times\nfor(i in 1:sims){\n  hec <- within(hec,{\n    \n    # Conduct both kinds of random assignment\n    Z_simple <- simple_ra(N = N)\n    Z_complete <- complete_ra(N = N)\n    \n    # Reveal observed potential outcomes\n    Y_simple <- Y1*Z_simple + Y0*(1-Z_simple)\n    Y_complete <- Y1*Z_complete + Y0*(1-Z_complete)\n    })\n  \n  # Estimate ATE under both models\n  fit_simple <- lm(Y_simple ~ Z_simple, data=hec)\n  fit_complete <- lm(Y_complete ~ Z_complete, data=hec)\n  \n  # Save the estimates\n  simple_ests[i] <- coef(fit_simple)[2]\n  complete_ests[i] <- coef(fit_complete)[2]\n}\n\nThe standard error of an estimate is defined as the standard deviation of the sampling distribution of the estimator. When standard errors are estimated (i.e., by using the summary() command on a model fit), they are estimated using some approximation. This simulation allows us to measure the standard error directly, since the vectors simple_ests and complete_ests describe the sampling distribution of each design.\n\nsd(simple_ests)\n\n0.6\n\nsd(complete_ests)\n\n0.6\nIn this simulation complete random assignment led to a -0.59% decrease in sampling variability. This decrease was obtained with a small design tweak that costs the researcher essentially nothing."
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#block-random-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#block-random-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Block random assignment",
    "text": "Block random assignment\nBlock random assignment (sometimes known as stratified random assignment) is a powerful tool when used well. In this design, subjects are sorted into blocks (strata) according to their pre-treatment covariates, and then complete random assignment is conducted within each block. For example, a researcher might block on gender, assigning exactly half of the men and exactly half of the women to treatment.\nWhy block? The first reason is to signal to future readers that treatment effect heterogeneity may be of interest: is the treatment effect different for men versus women? Of course, such heterogeneity could be explored if complete random assignment had been used, but blocking on a covariate defends a researcher (somewhat) against claims of data dredging. The second reason is to increase precision. If the blocking variables are predictive of the outcome (i.e., they are correlated with the outcome), then blocking may help to decrease sampling variability. It’s important, however, not to overstate these advantages. The gains from a blocked design can often be realized through covariate adjustment alone.\nBlocking can also produce complications for estimation. Blocking can produce different probabilities of assignment for different subjects. This complication is typically addressed in one of two ways: “controlling for blocks” in a regression context, or inverse probability weights (IPW), in which units are weighted by the inverse of the probability that the unit is in the condition that it is in.\nThe only required argument to block_ra() is blocks, which is a vector of length N that describes which block a unit belongs to. blocks can be a factor, character, or numeric variable. If no other arguments are specified, block_ra() assigns an approximately equal proportion of each block to treatment.\n\nZ <- block_ra(blocks = hec$Hair)\ntable(Z, hec$Hair)\n\n\n\n\n\n\n\nBlack\nBrown\nRed\nBlond\n\n\n\n\n0\n54\n143\n36\n64\n\n\n1\n54\n143\n35\n63\n\n\n\n\n\nFor multiple treatment arms, use the num_arms argument, with or without the conditions argument\n\nZ <- block_ra(blocks = hec$Hair, num_arms = 3)\ntable(Z, hec$Hair)\n\n\n\n\n\n\n\nBlack\nBrown\nRed\nBlond\n\n\n\n\nT1\n36\n95\n24\n42\n\n\nT2\n36\n96\n24\n43\n\n\nT3\n36\n95\n23\n42\n\n\n\n\n\n\nZ <- block_ra(blocks = hec$Hair, conditions = c(\"Control\", \"Placebo\", \"Treatment\"))\ntable(Z, hec$Hair)\n\n\n\n\n\n\n\nBlack\nBrown\nRed\nBlond\n\n\n\n\nControl\n36\n95\n24\n42\n\n\nPlacebo\n36\n95\n24\n42\n\n\nTreatment\n36\n96\n23\n43\n\n\n\n\n\nblock_ra() provides a number of ways to adjust the number of subjects assigned to each conditions. The prob_each argument describes what proportion of each block should be assigned to treatment arm. Note of course, that block_ra() still uses complete random assignment within each block; the appropriate number of units to assign to treatment within each block is automatically determined.\n\nZ <- block_ra(blocks = hec$Hair, prob_each = c(.3, .7))\ntable(Z, hec$Hair)\n\n\n\n\n\n\n\nBlack\nBrown\nRed\nBlond\n\n\n\n\n0\n32\n86\n21\n38\n\n\n1\n76\n200\n50\n89\n\n\n\n\n\nFor finer control, use the block_m_each argument, which takes a matrix with as many rows as there are blocks, and as many columns as there are treatment conditions. Remember that the rows are in the same order as sort(unique(blocks)), a command that is good to run before constructing a block_m_each matrix.\n\nsort(unique(hec$Hair))\nblock_m_each <- rbind(c(78, 30),\n                      c(186, 100),\n                      c(51, 20),\n                      c(87,40))\n\nblock_m_each\nZ <- block_ra(blocks = hec$Hair, block_m_each = block_m_each)\ntable(Z, hec$Hair)\n\n\n\n\n\n\n\nBlack\nBrown\nRed\nBlond\n\n\n\n\n0\n78\n186\n51\n87\n\n\n1\n30\n100\n20\n40\n\n\n\n\n\nIn the example above, the different blocks have different probabilities of assignment to treatment. In this case, people with Black hair have a 30/108 = 27.8% chance of being treated, those with Brown hair have 100/286 = 35.0% change, etc. Left unaddressed, this discrepancy could bias treatment effects. We can see this directly with the declare_ra() function.\n\ndeclaration <- declare_ra(blocks = hec$Hair, block_m_each = block_m_each)\n\n# show the probability that each unit is assigned to each condition\nhead(declaration$probabilities_matrix)\n\n\n\n\n\n\nprob_0\nprob_1\n\n\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n\n\n\n\n# Show that the probability of treatment is different within block\ntable(hec$Hair, round(declaration$probabilities_matrix[,2], 3))\n\n\n\n\n\n\n\n0.278\n0.282\n0.315\n0.35\n\n\n\n\nBlack\n108\n0\n0\n0\n\n\nBrown\n0\n0\n0\n286\n\n\nRed\n0\n71\n0\n0\n\n\nBlond\n0\n0\n127\n0\n\n\n\n\n\nThere are two common ways to address this problem: LSDV (Least-Squares Dummy Variable, also known as “control for blocks”) or IPW (Inverse-probability weights).\nThe following code snippet shows how to use either the LSDV approach or the IPW approach. A note for scrupulous readers: the estimands of these two approaches are subtly different from one another. The LSDV approach estimates the average block-level treatment effect. The IPW approach estimates the average individual-level treatment effect. They can be different. Since the average block-level treatment effect is not what most people have in mind when thinking about causal effects, analysts using this approach should present both. The obtain_condition_probabilities() function used to calculate the probabilities of assignment is explained below.\n\nhec <- within(hec,{\n  Z_blocked <- block_ra(blocks = hec$Hair,\n                        block_m_each = block_m_each)\n  Y_blocked <- Y1*(Z_blocked) + Y0*(1-Z_blocked)\n  cond_prob <- obtain_condition_probabilities(declaration, Z_blocked)\n  IPW_weights <- 1/(cond_prob)\n})\n\nfit_LSDV <- lm(Y_blocked ~ Z_blocked + Hair, data=hec)\nfit_IPW <- lm(Y_blocked ~ Z_blocked, weights = IPW_weights, data = hec)\n\nsummary(fit_LSDV)\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(>|t|)\n\n\n\n\n(Intercept)\n-15.8\n0.72\n-21.9\n0.00\n\n\nZ_blocked\n25.8\n0.64\n40.2\n0.00\n\n\nHairBrown\n1.8\n0.82\n2.2\n0.03\n\n\nHairRed\n4.8\n1.11\n4.3\n0.00\n\n\nHairBlond\n8.8\n0.95\n9.3\n0.00\n\n\n\n\n\n\nsummary(fit_IPW)\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(>|t|)\n\n\n\n\n(Intercept)\n-12\n0.49\n-26\n0\n\n\nZ_blocked\n26\n0.69\n37\n0\n\n\n\n\n\nHow to create blocks? In the HairEyeColor dataset, we could make blocks for each unique combination of hair color, eye color, and sex.\n\nblocks <- with(hec, paste(Hair, Eye, Sex, sep = \"_\"))\nZ <- block_ra(blocks = blocks)\nhead(table(blocks, Z))\n\n\n\n\n\n\n\n0\n1\n\n\n\n\nBlack_Blue_Female\n4\n5\n\n\nBlack_Blue_Male\n5\n6\n\n\nBlack_Brown_Female\n18\n18\n\n\nBlack_Brown_Male\n16\n16\n\n\nBlack_Green_Female\n1\n1\n\n\nBlack_Green_Male\n2\n1\n\n\n\n\n\nAn alternative is to use the blockTools package, which constructs matched pairs, trios, quartets, etc. from pretreatment covariates.\n\nlibrary(blockTools)\n\n# BlockTools requires that all variables be numeric\nnumeric_mat <- model.matrix(~Hair+Eye+Sex, data=hec)[,-1]\n\n# BlockTools also requres an id variable\ndf_forBT <- data.frame(id_var = 1:nrow(numeric_mat), numeric_mat)\n\n# Conducting the actual blocking: let's make trios\nout <- block(df_forBT, n.tr = 3, id.vars = \"id_var\", \n             block.vars = colnames(df_forBT)[-1])\n\n# Extact the block_ids\nhec$block_id <- createBlockIDs(out, df_forBT, id.var = \"id_var\")\n\n# Conduct actual random assignment with randomizr\nZ_blocked <- block_ra(blocks = hec$block_id, num_arms = 3)\nhead(table(hec$block_id, Z_blocked))\n\nA note for blockTools users: that package also has an assignment function. My preference is to extract the blocking variable, then conduct the assignment with block_ra(), so that fewer steps are required to reconstruct the random assignment or generate new random assignments for a randomization inference procedure."
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#clustered-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#clustered-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Clustered assignment",
    "text": "Clustered assignment\nClustered assignment is unfortunate. If you can avoid assigning subjects to treatments by cluster, you should. Sometimes, clustered assignment is unavoidable. Some common situations include:\n\nHousemates in households: whole households are assigned to treatment or control\nStudents in classrooms: whole classrooms are assigned to treatment or control\nResidents in towns or villages: whole communities are assigned to treatment or control\n\nClustered assignment decreases the effective sample size of an experiment. In the extreme case when outcomes are perfectly correlated with clusters, the experiment has an effective sample size equal to the number of clusters. When outcomes are perfectly uncorrelated with clusters, the effective sample size is equal to the number of subjects. Almost all cluster-assigned experiments fall somewhere in the middle of these two extremes.\nThe only required argument for the cluster_ra() function is the clusters argument, which is a vector of length N that indicates which cluster each subject belongs to. Let’s pretend that for some reason, we have to assign treatments according to the unique combinations of hair color, eye color, and gender.\n\nclusters <- with(hec, paste(Hair, Eye, Sex, sep = \"_\"))\nhec$clusters <- clusters\n\nZ_clust <- cluster_ra(clusters = clusters)\n\nhead(table(clusters, Z_clust))\n\n\n\n\n\n\n\n0\n1\n\n\n\n\nBlack_Blue_Female\n0\n9\n\n\nBlack_Blue_Male\n0\n11\n\n\nBlack_Brown_Female\n0\n36\n\n\nBlack_Brown_Male\n32\n0\n\n\nBlack_Green_Female\n0\n2\n\n\nBlack_Green_Male\n3\n0\n\n\n\n\n\nThis shows that each cluster is either assigned to treatment or control. No two units within the same cluster are assigned to different conditions.\nAs with all functions in randomizr, you can specify multiple treatment arms in a variety of ways:\n\nZ_clust <- cluster_ra(clusters = clusters, num_arms = 3)\nhead(table(clusters, Z_clust))\n\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\nBlack_Blue_Female\n9\n0\n0\n\n\nBlack_Blue_Male\n11\n0\n0\n\n\nBlack_Brown_Female\n0\n36\n0\n\n\nBlack_Brown_Male\n0\n32\n0\n\n\nBlack_Green_Female\n2\n0\n0\n\n\nBlack_Green_Male\n3\n0\n0\n\n\n\n\n\n… or using conditions\n\nZ_clust <- cluster_ra(clusters=clusters, \n                      conditions=c(\"Control\", \"Placebo\", \"Treatment\"))\nhead(table(clusters, Z_clust))\n\n\n\n\n\n\n\nControl\nPlacebo\nTreatment\n\n\n\n\nBlack_Blue_Female\n0\n0\n9\n\n\nBlack_Blue_Male\n0\n11\n0\n\n\nBlack_Brown_Female\n0\n36\n0\n\n\nBlack_Brown_Male\n32\n0\n0\n\n\nBlack_Green_Female\n0\n0\n2\n\n\nBlack_Green_Male\n0\n0\n3\n\n\n\n\n\n… or using m_each, which describes how many clusters should be assigned to each condition. m_each must sum to the number of clusters.\n\nZ_clust <- cluster_ra(clusters=clusters, m_each=c(5, 15, 12))\nhead(table(clusters, Z_clust))\n\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\nBlack_Blue_Female\n0\n9\n0\n\n\nBlack_Blue_Male\n11\n0\n0\n\n\nBlack_Brown_Female\n0\n0\n36\n\n\nBlack_Brown_Male\n0\n32\n0\n\n\nBlack_Green_Female\n0\n0\n2\n\n\nBlack_Green_Male\n0\n3\n0"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#blocked-and-clustered-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#blocked-and-clustered-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Blocked and clustered assignment",
    "text": "Blocked and clustered assignment\nThe power of clustered experiments can sometimes be improved through blocking. In this scenario, whole clusters are members of a particular block – imagine villages nested within discrete regions, or classrooms nested within discrete schools.\nAs an example, let’s group our clusters into blocks by size using dplyr\n\nsuppressMessages(library(dplyr))\ncluster_level_df <- \n  hec %>%\n  group_by(clusters) %>%\n  summarize(cluster_size = n()) %>%\n  arrange(cluster_size) %>%\n  mutate(blocks = paste0(\"block_\", sprintf(\"%02d\",rep(1:16, each=2))))\n\nhec <- left_join(hec, cluster_level_df)\n#> Joining, by = \"clusters\"\n\n# Extract the cluster and block variables\nclusters <- hec$clusters\nblocks <- hec$blocks\n\nZ <- block_and_cluster_ra(clusters = clusters, blocks = blocks)\nhead(table(clusters, Z))\nhead(table(blocks, Z))\n\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\nBlack_Blue_Female\n0\n9\n0\n\n\nBlack_Blue_Male\n11\n0\n0\n\n\nBlack_Brown_Female\n0\n0\n36\n\n\nBlack_Brown_Male\n0\n32\n0\n\n\nBlack_Green_Female\n0\n0\n2\n\n\nBlack_Green_Male\n0\n3\n0\n\n\n\n\n\n\n\n\n\nT1\nT2\nT3\n\n\n\n\nblock_01\n0\n3\n2\n\n\nblock_02\n0\n0\n7\n\n\nblock_03\n5\n0\n5\n\n\nblock_04\n5\n0\n7\n\n\nblock_05\n0\n7\n7\n\n\nblock_06\n0\n7\n7"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#calculating-probabilities-of-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#calculating-probabilities-of-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Calculating probabilities of assignment",
    "text": "Calculating probabilities of assignment\nAll five random assignment functions in randomizr assign units to treatment with known (if sometimes complicated) probabilities. The declare_ra() and obtain_condition_probabilities() functions calculate these probabilities according to the parameters of your experimental design.\nLet’s take a look at the block random assignment we used before.\n\nblock_m_each <- \n  rbind(c(78, 30),\n        c(186, 100),\n        c(51, 20),\n        c(87, 40))\n  \nZ <- block_ra(blocks = hec$Hair,\n              block_m_each = block_m_each)\n\ntable(hec$Hair, Z)\n\n\n\n\n\n\n\n0\n1\n\n\n\n\nBlack\n78\n30\n\n\nBrown\n186\n100\n\n\nRed\n51\n20\n\n\nBlond\n87\n40\n\n\n\n\n\nIn order to calculate the probabilities of assignment, we call the declare_ra() function with the same exact arguments as we used for the block_ra() call. The declaration object contains a matrix of probabilities of assignment:\n\ndeclaration <- declare_ra(blocks = hec$Hair,\n                          block_m_each = block_m_each)\nprob_mat <- declaration$probabilities_matrix\nhead(prob_mat)\n\n\n\n\n\n\nprob_0\nprob_1\n\n\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n0.72\n0.28\n\n\n\n\n\nThe prob_mat objects has N rows and as many columns as there are treatment conditions, in this case 2.\nIn order to use inverse-probability weights, we need to know the probability of each unit being in the condition that it is in. For each unit, we need to pick the appropriate probability. This bookkeeping is handled automatically by the obtain_condition_probabilities() function.\n\ncond_prob <- obtain_condition_probabilities(declaration, Z)\ntable(cond_prob, Z)\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0.28\n0\n30\n\n\n0.28\n0\n20\n\n\n0.31\n0\n40\n\n\n0.35\n0\n100\n\n\n0.65\n186\n0\n\n\n0.69\n87\n0\n\n\n0.72\n51\n0\n\n\n0.72\n78\n0"
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#random-assignment-procedure-random-assignment-function",
    "href": "randomizr/articles/randomizr_vignette.html#random-assignment-procedure-random-assignment-function",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Random assignment procedure = Random assignment function",
    "text": "Random assignment procedure = Random assignment function\nRandom assignment procedures are often described as a series of steps that are manually carried out be the researcher. In order to make this procedure reproducible, these steps need to be translated into a function that returns a different random assignment each time it is called.\nFor example, consider the following procedure for randomly allocating school vouchers.\n\nEvery eligible student’s names is put on a list\nEach name is assigned a random number\nBalls with the numbers associated with all students are put in an urn.\nThen the urn is “shuffled”\nStudents names are drawn one by one from the urn until all slots are given out.\nIf one sibling in a family wins, all other siblings automatically win too.\n\nIf we write such a procedure into a function, it might look like this:\n\n# 400 families have 1 child in the lottery, 100 families have 2\nfamily_id <- c(sprintf(\"%03d\", 1:500), sprintf(\"%03d\", 1:100))\n\nschool_ra <- function(m){\n  N <- length(family_id)\n  random_number <- sample(1:N, replace=FALSE)\n  Z <- rep(0, N)\n  i <- 1\n  while(sum(Z) <m){\n    Z[family_id==family_id[random_number[i]]] <- 1\n    i <- i + 1\n  }\n  return(Z)\n}\n\nZ <- school_ra(200)\ntable(Z)\n\n\n\n\n\n\n0\n1\n\n\n\n\n400\n200\n\n\n\n\n\nThis assignment procedure is complicated by the sibling rule, which has two effects: first, students are cluster-assigned by family, and second, the probability of assignment varies student to student. Obviously, families who have two children in the lottery have a higher probability of winning the lottery because they effectively have two “tickets.” There may be better ways of running this assignment procedure (for example, with cluster_ra()), but the purpose of this example is to show how complicated real-world procedures can be written up in a simple function. With this function, the random assignment procedure can be reproduced exactly, the complicated probabilities of assignment can be calculated, and the analysis is greatly simplified."
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#check-probabilities-of-assignment-directly",
    "href": "randomizr/articles/randomizr_vignette.html#check-probabilities-of-assignment-directly",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Check probabilities of assignment directly",
    "text": "Check probabilities of assignment directly\nFor many designs, the probability of assignment to treatment can be calculated analytically. For example, in a completely randomized design with 200 units, 60 of which are assigned to treatment, the probability is exactly 0.30 for all units. However, in more complicated designs (such as the schools example described above), analytic probabilities are difficult to calculate. In such a situation, an easy way to obtain the probabilities of assignment is through simulation.\n\nCall your random assignment function an approximately infinite number of times (about 10,000 for most purposes).\nCount how often each unit is assigned to each treatment arm.\n\n\nZ_matrix <- replicate(1000, school_ra(200))\nplot(rowMeans(Z_matrix))\n\n\n\n\nThis plot shows that the students who have a sibling in the lottery have a higher probability of assignment. The more simulations, the more precise the estimate of the probability of assignment."
  },
  {
    "objectID": "randomizr/articles/randomizr_vignette.html#save-your-random-assignment",
    "href": "randomizr/articles/randomizr_vignette.html#save-your-random-assignment",
    "title": "Design and Analysis of Experiments with randomizr",
    "section": "Save your random assignment",
    "text": "Save your random assignment\nWhenever you conduct a random assignment for use in an experiment, save it! At a minimum, the random assignment should be saved with an id variable in a csv.\n\nhec <- within(hec,{\n  Z_blocked <- complete_ra(N = N, m_each = c(100, 200, 292),\n               conditions = c(\"control\", \"placebo\", \"treatment\"))\n  id_var <- 1:nrow(hec)\n})\nwrite.csv(hec[,c(\"id_var\", \"Z_blocked\")], file = \"MyRandomAssignment.csv\")"
  },
  {
    "objectID": "randomizr/index.html",
    "href": "randomizr/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "randomizr: Easy to use tools for common forms of random assignment and sampling ================\nrandomizr is designed to make conducting field, lab, survey, or online experiments easier by automating the random assignment process. Social and lab scientists conducting experiments need a process to assign individuals or units of observation to treatment or control wings. Common designs include simple random assignment, complete randomization, block randomization, cluster randomization, and blocked cluster randomization. randomizr automates all of these processes and assists scientists in doing transparent, replicable science. We offer randomizr for both R and Stata."
  },
  {
    "objectID": "randomizr/index.html#installing-randomizr-for-r",
    "href": "randomizr/index.html#installing-randomizr-for-r",
    "title": "**Declare**Design",
    "section": "Installing randomizr for R",
    "text": "Installing randomizr for R\nInstalling the latest stable version of randomizr in R:.\ninstall.packages(\"randomizr\")\nIf you would like to use the current development release of randomizr (please be aware that development releases may include bugs or syntax changes), run the following:\ninstall.packages(\"randomizr\", repos=\"http://r.declaredesign.org\")"
  },
  {
    "objectID": "randomizr/index.html#getting-started-with-randomizr-for-r",
    "href": "randomizr/index.html#getting-started-with-randomizr-for-r",
    "title": "**Declare**Design",
    "section": "Getting started with randomizr for R",
    "text": "Getting started with randomizr for R\nrandomizr has five main random assignment functions, corresponding to the common experimental designs listed above. You can read more about using each of these functions in our reference library or by clicking on the function names: simple_ra(), complete_ra(), block_ra(), cluster_ra(), and block_and_cluster_ra().\ncomplete_ra() (Complete randomization) is the function that will be most appropriate for a large number of experimental situations: when you want to assign a fixed m units out of a population of N units to treatment:\nlibrary(randomizr)\nZ <- complete_ra(N = 100, m = 50)\ntable(Z)\n\n\n\n0\n1\n\n\n\n\n50\n50\n\n\n\nA more complicated design that, for example, assigns different numbers of clusters to three different treatments, makes use of cluster_ra() (Cluster randomization):\n# This makes a cluster variable: one unit in cluster \"a\", two in \"b\"...\nclust_var <- rep(letters[1:15], times = 1:15)\n\nZ <- cluster_ra(\n  clusters = clust_var,\n  m_each = c(4, 4, 7),\n  conditions = c(\"control\", \"placebo\", \"treatment\")\n  )\ntable(Z, clust_var)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nm\nn\no\n\n\n\n\ncontrol\n1\n0\n0\n0\n0\n0\n0\n0\n9\n0\n0\n0\n0\n14\n15\n\n\nplacebo\n0\n0\n3\n0\n5\n0\n7\n0\n0\n0\n0\n12\n0\n0\n0\n\n\ntreatment\n0\n2\n0\n4\n0\n6\n0\n8\n0\n10\n11\n0\n13\n0\n0\n\n\n\nFor more information about all of randomizr’s functionality, please see our online tutorial"
  },
  {
    "objectID": "randomizr/index.html#randomizr-for-stata",
    "href": "randomizr/index.html#randomizr-for-stata",
    "title": "**Declare**Design",
    "section": "randomizr for Stata",
    "text": "randomizr for Stata\nInstalling the latest stable version of randomizr from ssc is easy:\nssc install randomizr\nIf you would like to install the latest development release directly from GitHub, run the following code:\nnet install randomizr, from(https://raw.githubusercontent.com/DeclareDesign/strandomizr/master/) replace\nHappy randomizing!"
  },
  {
    "objectID": "randomizr/reference/simple_rs.html#description",
    "href": "randomizr/reference/simple_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nsimple_rs implements a random sampling procedure in which units are independently sampled. Because units are sampled independently, the number of units that are sampled can vary from sample to sample. For most applications in which the number of units in the sampling frame is known in advance, complete_rs is better because the number of units sampled is fixed across sampled."
  },
  {
    "objectID": "randomizr/reference/simple_rs.html#usage",
    "href": "randomizr/reference/simple_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsimple_rs(N, prob = NULL, prob_unit = NULL, check_inputs = TRUE, simple = TRUE)"
  },
  {
    "objectID": "randomizr/reference/simple_rs.html#arguments",
    "href": "randomizr/reference/simple_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nprob\nprob is the probability of being sampled must be a real number between 0 and 1 inclusive, and must be of length 1. (optional)\n\n\nprob_unit\nprob is the probability of being sampled must be a real number between 0 and 1 inclusive, and must be of length N. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE.\n\n\nsimple\nlogical. internal use only."
  },
  {
    "objectID": "randomizr/reference/simple_rs.html#value",
    "href": "randomizr/reference/simple_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA numeric vector of length N that indicates if a unit is sampled (1) or not (0)."
  },
  {
    "objectID": "randomizr/reference/simple_rs.html#examples",
    "href": "randomizr/reference/simple_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nS <- simple_rs(N = 100)\ntable(S)\n\nS\n 0  1 \n51 49 \n\nS <- simple_rs(N = 100, prob = 0.3)\ntable(S)\n\nS\n 0  1 \n78 22"
  },
  {
    "objectID": "randomizr/reference/conduct_ra.html#description",
    "href": "randomizr/reference/conduct_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nYou can either give conduct_ra() an declaration, as created by declare_ra or you can specify the other arguments to describe a random assignment procedure."
  },
  {
    "objectID": "randomizr/reference/conduct_ra.html#usage",
    "href": "randomizr/reference/conduct_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nconduct_ra(\n  declaration = NULL,\n  N = NULL,\n  blocks = NULL,\n  clusters = NULL,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  simple = FALSE,\n  permutation_matrix = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/conduct_ra.html#arguments",
    "href": "randomizr/reference/conduct_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random assignment declaration, created by declare_ra.\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nm\nUse for a two-arm design in which m units (or clusters) are assigned to treatment and N-m units (or clusters) are assigned to control. In a blocked design, exactly m units in each block will be treated. (optional)\n\n\nm_unit\nUse for a two-arm trial. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of units (or clusters) assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many units (or clusters) should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be assigned to treatment and with probability prob, ceiling(Nprob) units (or clusters) will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. Under simple random assignment, can be different for each unit or cluster. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nblock_m\nUse for a two-arm design in which block_m describes the number of units to assign to treatment within each block. Note that in previous versions of randomizr, block_m behaved like block_m_each.\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of units (or clusters) assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of units (or clusters) to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random assignment is used. When simple = TRUE, please do not specify m, m_each, block_m, or block_m_each. If simple = TRUE, prob and prob_each may vary by unit.\n\n\npermutation_matrix\nfor custom random assignment procedures.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/conduct_ra.html#examples",
    "href": "randomizr/reference/conduct_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\ndeclaration <- declare_ra(N = 100, m_each = c(30, 30, 40))\nZ <- conduct_ra(declaration = declaration)\ntable(Z)\n\nZ\nT1 T2 T3 \n30 30 40 \n\n# equivalent to\n\nZ <- conduct_ra(N = 100, m_each = c(30, 30, 40))\ntable(Z)\n\nZ\nT1 T2 T3 \n30 30 40"
  },
  {
    "objectID": "randomizr/reference/cluster_rs.html#description",
    "href": "randomizr/reference/cluster_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\ncluster_rs implements a random sampling procedure in which groups of units are sampled together (as a cluster). This function conducts complete random sampling at the cluster level, unless simple = TRUE, in which case simple_rs analogues are used."
  },
  {
    "objectID": "randomizr/reference/cluster_rs.html#usage",
    "href": "randomizr/reference/cluster_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncluster_rs(\n  clusters = NULL,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/cluster_rs.html#arguments",
    "href": "randomizr/reference/cluster_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nn\nUse for a design in which n clusters are sampled. (optional)\n\n\nn_unit\nunique(n_unit) will be passed to n. Must be the same for all units (optional)\n\n\nprob\nUse for a design in which either floor(N_clustersprob) or ceiling(N_clustersprob) clusters are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_clustersprob) clusters will be sampled and with probability prob, ceiling(N_clustersprob) clusters will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nunique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random sampling of clusters. When simple = TRUE, please do not specify n.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/cluster_rs.html#value",
    "href": "randomizr/reference/cluster_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA numeric vector of length N that indicates if a unit is sampled (1) or not (0)."
  },
  {
    "objectID": "randomizr/reference/cluster_rs.html#examples",
    "href": "randomizr/reference/cluster_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nclusters <- rep(letters, times=1:26)\n\nS <- cluster_rs(clusters = clusters)\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  2  3  4  0  6  7  8  0  0 11  0 13  0  0  0 17  0 19  0  0  0 23  0 25\n  1  1  0  0  0  5  0  0  0  9 10  0 12  0 14 15 16  0 18  0 20 21 22  0 24  0\n   clusters\nS    z\n  0 26\n  1  0\n\nS <- cluster_rs(clusters = clusters, n = 13)\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  1  0  0  4  0  6  0  0  0 10  0 12  0  0 15 16 17  0 19  0 21  0  0 24 25\n  1  0  2  3  0  5  0  7  8  9  0 11  0 13 14  0  0  0 18  0 20  0 22 23  0  0\n   clusters\nS    z\n  0 26\n  1  0"
  },
  {
    "objectID": "randomizr/reference/complete_rs_probabilities.html#description",
    "href": "randomizr/reference/complete_rs_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInclusion Probabilities: Complete Random Sampling"
  },
  {
    "objectID": "randomizr/reference/complete_rs_probabilities.html#usage",
    "href": "randomizr/reference/complete_rs_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncomplete_rs_probabilities(\n  N,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/complete_rs_probabilities.html#arguments",
    "href": "randomizr/reference/complete_rs_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nn\nUse for a design in which exactly n units are sampled. (optional)\n\n\nn_unit\nunique(n_unit) will be passed to n. Must be the same for all units (optional)\n\n\nprob\nUse for a design in which either floor(Nprob) or ceiling(Nprob) units are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(Nprob) units will be sampled and with probability prob, ceiling(Nprob) units will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nunique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/complete_rs_probabilities.html#value",
    "href": "randomizr/reference/complete_rs_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector length N indicating the probability of being sampled."
  },
  {
    "objectID": "randomizr/reference/complete_rs_probabilities.html#examples",
    "href": "randomizr/reference/complete_rs_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nprobs <- complete_rs_probabilities(N = 100)\ntable(probs)\n\nprobs\n0.5 \n100 \n\nprobs <- complete_rs_probabilities(N = 100, n = 50)\ntable(probs)\n\nprobs\n0.5 \n100 \n\nprobs <- complete_rs_probabilities(N=100, prob = .3)\ntable(probs)\n\nprobs\n0.3 \n100"
  },
  {
    "objectID": "randomizr/reference/strata_rs_probabilities.html#description",
    "href": "randomizr/reference/strata_rs_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInclusion Probabilities: Stratified Random Sampling"
  },
  {
    "objectID": "randomizr/reference/strata_rs_probabilities.html#usage",
    "href": "randomizr/reference/strata_rs_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nstrata_rs_probabilities(\n  strata = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  n = NULL,\n  n_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/strata_rs_probabilities.html#arguments",
    "href": "randomizr/reference/strata_rs_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to. Can be a character, factor, or numeric vector. (required)\n\n\nprob\nUse for a design in which either floor(N_stratumprob) or ceiling(N_stratumprob) units are sampled within each stratum. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_stratumprob) units will be sampled and with probability prob, ceiling(N_stratumprob) units will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. tapply(prob_unit, strata, unique) will be passed to strata_prob.\n\n\nn\nUse for a design in which the scalar n describes the fixed number of units to sample in each stratum. This number does not vary across strata.\n\n\nn_unit\nMust be of length N. tapply(m_unit, strata, unique) will be passed to strata_n.\n\n\nstrata_n\nUse for a design in which the numeric vector strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/strata_rs_probabilities.html#value",
    "href": "randomizr/reference/strata_rs_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector length N indicating the probability of being sampled."
  },
  {
    "objectID": "randomizr/reference/strata_rs_probabilities.html#examples",
    "href": "randomizr/reference/strata_rs_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nstrata <- rep(c(\"A\", \"B\",\"C\"), times = c(50, 100, 200))\nprobs <- strata_rs_probabilities(strata = strata)\ntable(strata, probs)\n\n      probs\nstrata 0.5\n     A  50\n     B 100\n     C 200\n\nprobs <- strata_rs_probabilities(strata = strata, prob = .2)\ntable(strata, probs)\n\n      probs\nstrata 0.2\n     A  50\n     B 100\n     C 200\n\nprobs <- strata_rs_probabilities(strata = strata, strata_prob = c(.1, .2, .3))\ntable(strata, probs)\n\n      probs\nstrata 0.1 0.2 0.3\n     A  50   0   0\n     B   0 100   0\n     C   0   0 200\n\nprobs <- strata_rs_probabilities(strata = strata, strata_n = c(10, 40, 70))\ntable(strata, probs)\n\n      probs\nstrata 0.2 0.35 0.4\n     A  50    0   0\n     B   0    0 100\n     C   0  200   0"
  },
  {
    "objectID": "randomizr/reference/draw_rs.html#description",
    "href": "randomizr/reference/draw_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nYou can either give draw_rs() an declaration, as created by declare_rs or you can specify the other arguments to describe a random sampling procedure."
  },
  {
    "objectID": "randomizr/reference/draw_rs.html#usage",
    "href": "randomizr/reference/draw_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_rs(\n  declaration = NULL,\n  N = NULL,\n  strata = NULL,\n  clusters = NULL,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/draw_rs.html#arguments",
    "href": "randomizr/reference/draw_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random sampling declaration, created by declare_rs.\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nn\nUse for a design in which n units (or clusters) are sampled. In a stratified design, exactly n units in each stratum will be sampled. (optional)\n\n\nn_unit\nUnder complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nprob\nUse for a design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be sampled and with probability prob, ceiling(Nprob) units (or clusters) will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. Under simple random sampling, can be different for each unit or cluster. Under complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nstrata_n\nUse for a design in which strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random sampling is used. When simple = TRUE, please do not specify n or strata_n. When simple = TRUE, prob may vary by unit.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/draw_rs.html#examples",
    "href": "randomizr/reference/draw_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\ndeclaration <- declare_rs(N = 100, n = 30)\nS <- draw_rs(declaration = declaration)\ntable(S)\n\nS\n 0  1 \n70 30 \n\n# equivalent to\nS <- draw_rs(N = 100, n = 30)\ntable(S)\n\nS\n 0  1 \n70 30"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_matrix.html#description",
    "href": "randomizr/reference/obtain_permutation_matrix.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nObtain Permutation Matrix from a Random Assignment Declaration"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_matrix.html#usage",
    "href": "randomizr/reference/obtain_permutation_matrix.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nobtain_permutation_matrix(declaration, maximum_permutations = 10000)"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_matrix.html#arguments",
    "href": "randomizr/reference/obtain_permutation_matrix.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random assignment declaration, created by declare_ra.\n\n\nmaximum_permutations\nIf the number of possible random assignments exceeds maximum_permutations, obtain_permutation_matrix will return a random sample of maximum_permutations permutations. Defaults to 10,000."
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_matrix.html#value",
    "href": "randomizr/reference/obtain_permutation_matrix.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na matrix of all possible (or a random sample of all possible) random assignments consistent with a declaration."
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_matrix.html#examples",
    "href": "randomizr/reference/obtain_permutation_matrix.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# complete\n\ndeclaration <- declare_ra(N = 4)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 4 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n# blocked\n\nblocks <- c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_ra(blocks = blocks)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]  7 24\n\nobtain_num_permutations(declaration)\n\n[1] 24\n\n# clustered\n\nclusters <- c(\"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_ra(clusters = clusters)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 7 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n# large\n\ndeclaration <- declare_ra(20)\nchoose(20, 10)\n\n[1] 184756\n\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]    20 10000"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra.html#description",
    "href": "randomizr/reference/block_and_cluster_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nA random assignment procedure in which units are assigned as clusters and clusters are nested within blocks."
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra.html#usage",
    "href": "randomizr/reference/block_and_cluster_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nblock_and_cluster_ra(\n  blocks = NULL,\n  clusters = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  m = NULL,\n  m_unit = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra.html#arguments",
    "href": "randomizr/reference/block_and_cluster_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nprob\nUse for a two-arm design in which either floor(N_clusters_blockprob) or ceiling(N_clusters_blockprob) clusters are assigned to treatment within each block. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_clusters_blockprob) clusters will be assigned to treatment and with probability prob, ceiling(N_clusters_blockprob) clusters will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. tapply(prob_unit, blocks, unique) will be passed to block_prob.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of clusters assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nm\nUse for a two-arm design in which the scalar m describes the fixed number of clusters assigned in each block. This number does not vary across blocks.\n\n\nm_unit\nUse for a two-arm design. Must be of length N. tapply(m_unit, blocks, unique) will be passed to block_m.\n\n\nblock_m\nUse for a two-arm design in which block_m describes the number of clusters to assign to treatment within each block. block_m must be a numeric vector that is as long as the number of blocks and is in the same order as sort(unique(blocks)).\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of clusters assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of clusters to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Must be in the same order as sort(unique(blocks)). Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra.html#value",
    "href": "randomizr/reference/block_and_cluster_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit."
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra.html#examples",
    "href": "randomizr/reference/block_and_cluster_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nclusters <- rep(letters, times=1:26)\n\nblocks <- rep(NA, length(clusters))\nblocks[clusters %in% letters[1:5]] <- \"block_1\"\nblocks[clusters %in% letters[6:10]] <- \"block_2\"\nblocks[clusters %in% letters[11:15]] <- \"block_3\"\nblocks[clusters %in% letters[16:20]] <- \"block_4\"\nblocks[clusters %in% letters[21:26]] <- \"block_5\"\n\n\ntable(blocks, clusters)\n\n         clusters\nblocks     a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w\n  block_1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  block_2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n  block_3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0  0\n  block_4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0  0\n  block_5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22 23\n         clusters\nblocks     x  y  z\n  block_1  0  0  0\n  block_2  0  0  0\n  block_3  0  0  0\n  block_4  0  0  0\n  block_5 24 25 26\n\nZ <- block_and_cluster_ra(blocks = blocks,\n                          clusters = clusters)\n\ntable(Z, blocks)\n\n   blocks\nZ   block_1 block_2 block_3 block_4 block_5\n  0      11      13      37      39      73\n  1       4      27      28      51      68\n\ntable(Z, clusters)\n\n   clusters\nZ    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  2  0  4  5  6  7  0  0  0 11 12  0 14  0  0  0  0 19 20  0 22  0  0 25\n  1  1  0  3  0  0  0  0  8  9 10  0  0 13  0 15 16 17 18  0  0 21  0 23 24  0\n   clusters\nZ    z\n  0 26\n  1  0\n\nZ <- block_and_cluster_ra(blocks = blocks,\n                          clusters = clusters,\n                          num_arms = 3)\n\ntable(Z, blocks)\n\n    blocks\nZ    block_1 block_2 block_3 block_4 block_5\n  T1       6      15      26      35      47\n  T2       7       7      27      17      47\n  T3       2      18      12      38      47\n\ntable(Z, clusters)\n\n    clusters\nZ     a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  T1  1  0  0  0  5  6  0  0  9  0 11  0  0  0 15 16  0  0 19  0  0  0 23 24  0\n  T2  0  0  3  4  0  0  7  0  0  0  0  0 13 14  0  0 17  0  0  0 21  0  0  0  0\n  T3  0  2  0  0  0  0  0  8  0 10  0 12  0  0  0  0  0 18  0 20  0 22  0  0 25\n    clusters\nZ     z\n  T1  0\n  T2 26\n  T3  0\n\nZ <- block_and_cluster_ra(blocks = blocks,\n                          clusters = clusters,\n                          prob_each = c(.2, .5, .3))\n\nblock_m_each <- rbind(c(2, 3),\n                      c(1, 4),\n                      c(3, 2),\n                      c(2, 3),\n                      c(5, 1))\n\nZ <- block_and_cluster_ra(blocks = blocks,\n                          clusters = clusters,\n                          block_m_each = block_m_each)\n\ntable(Z, blocks)\n\n   blocks\nZ   block_1 block_2 block_3 block_4 block_5\n  0       8       7      42      34     115\n  1       7      33      23      56      26\n\ntable(Z, clusters)\n\n   clusters\nZ    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  0  3  0  5  0  7  0  0  0  0  0 13 14 15 16  0 18  0  0 21 22 23 24 25\n  1  1  2  0  4  0  6  0  8  9 10 11 12  0  0  0  0 17  0 19 20  0  0  0  0  0\n   clusters\nZ    z\n  0  0\n  1 26"
  },
  {
    "objectID": "randomizr/reference/simple_ra_probabilities.html#description",
    "href": "randomizr/reference/simple_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Simple Random Assignment"
  },
  {
    "objectID": "randomizr/reference/simple_ra_probabilities.html#usage",
    "href": "randomizr/reference/simple_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsimple_ra_probabilities(\n  N,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE,\n  simple = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/simple_ra_probabilities.html#arguments",
    "href": "randomizr/reference/simple_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nprob\nUse for a two-arm design. prob is the probability of assignment to treatment and must be a real number between 0 and 1 inclusive and must be length 1. (optional)\n\n\nprob_unit\nUse for a two-arm design. prob is the probability of assignment to treatment and must be a real number between 0 and 1 inclusive and must be length N. (optional)\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. It may be a conditions-length vector or a N-by-conditions matrix. (optional)\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE.\n\n\nsimple\nlogical. internal use only."
  },
  {
    "objectID": "randomizr/reference/simple_ra_probabilities.html#value",
    "href": "randomizr/reference/simple_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/simple_ra_probabilities.html#examples",
    "href": "randomizr/reference/simple_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# Two Group Designs\nprob_mat <- simple_ra_probabilities(N=100)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- simple_ra_probabilities(N=100, prob=0.5)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- simple_ra_probabilities(N=100, prob_each = c(0.3, 0.7),\n                        conditions = c(\"control\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_treatment\n[1,]          0.3            0.7\n[2,]          0.3            0.7\n[3,]          0.3            0.7\n[4,]          0.3            0.7\n[5,]          0.3            0.7\n[6,]          0.3            0.7\n\n# Multi-arm Designs\nprob_mat <- simple_ra_probabilities(N=100, num_arms=3)\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.3333333 0.3333333 0.3333333\n[2,] 0.3333333 0.3333333 0.3333333\n[3,] 0.3333333 0.3333333 0.3333333\n[4,] 0.3333333 0.3333333 0.3333333\n[5,] 0.3333333 0.3333333 0.3333333\n[6,] 0.3333333 0.3333333 0.3333333\n\nprob_mat <- simple_ra_probabilities(N=100, prob_each=c(0.3, 0.3, 0.4))\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.3     0.3     0.4\n[2,]     0.3     0.3     0.4\n[3,]     0.3     0.3     0.4\n[4,]     0.3     0.3     0.4\n[5,]     0.3     0.3     0.4\n[6,]     0.3     0.3     0.4\n\nprob_mat <- simple_ra_probabilities(N=100, prob_each=c(0.3, 0.3, 0.4),\n                        conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]          0.3          0.3            0.4\n[2,]          0.3          0.3            0.4\n[3,]          0.3          0.3            0.4\n[4,]          0.3          0.3            0.4\n[5,]          0.3          0.3            0.4\n[6,]          0.3          0.3            0.4\n\nprob_mat <- simple_ra_probabilities(N=100, conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]    0.3333333    0.3333333      0.3333333\n[2,]    0.3333333    0.3333333      0.3333333\n[3,]    0.3333333    0.3333333      0.3333333\n[4,]    0.3333333    0.3333333      0.3333333\n[5,]    0.3333333    0.3333333      0.3333333\n[6,]    0.3333333    0.3333333      0.3333333"
  },
  {
    "objectID": "randomizr/reference/simple_ra.html#description",
    "href": "randomizr/reference/simple_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nsimple_ra implements a random assignment procedure in which units are independently assigned to treatment conditions. Because units are assigned independently, the number of units that are assigned to each condition can vary from assignment to assignment. For most experimental applications in which the number of experimental units is known in advance, complete_ra is better because the number of units assigned to each condition is fixed across assignments. In most cases, users should specify N and not more than one of prob, prob_each, or num_arms.\nIf only N is specified, a two-arm trial with prob = 0.5 is assumed."
  },
  {
    "objectID": "randomizr/reference/simple_ra.html#usage",
    "href": "randomizr/reference/simple_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsimple_ra(\n  N,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE,\n  simple = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/simple_ra.html#arguments",
    "href": "randomizr/reference/simple_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nprob\nUse for a two-arm design. prob is the probability of assignment to treatment and must be a real number between 0 and 1 inclusive and must be length 1. (optional)\n\n\nprob_unit\nUse for a two-arm design. prob is the probability of assignment to treatment and must be a real number between 0 and 1 inclusive and must be length N. (optional)\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. It may be a conditions-length vector or a N-by-conditions matrix. (optional)\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE.\n\n\nsimple\nlogical. internal use only."
  },
  {
    "objectID": "randomizr/reference/simple_ra.html#value",
    "href": "randomizr/reference/simple_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit. Is numeric in a two-arm trial and a factor variable (ordered by conditions) in a multi-arm trial."
  },
  {
    "objectID": "randomizr/reference/simple_ra.html#examples",
    "href": "randomizr/reference/simple_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# Two Group Designs\n\nZ <- simple_ra(N=100)\ntable(Z)\n\nZ\n 0  1 \n50 50 \n\nZ <- simple_ra(N=100, prob=0.5)\ntable(Z)\n\nZ\n 0  1 \n49 51 \n\nZ <- simple_ra(N=100, prob_each = c(0.3, 0.7),\n               conditions = c(\"control\", \"treatment\"))\ntable(Z)\n\nZ\n  control treatment \n       28        72 \n\n# Multi-arm Designs\nZ <- simple_ra(N=100, num_arms=3)\ntable(Z)\n\nZ\nT1 T2 T3 \n40 30 30 \n\nZ <- simple_ra(N=100, prob_each=c(0.3, 0.3, 0.4))\ntable(Z)\n\nZ\nT1 T2 T3 \n24 32 44 \n\nZ <- simple_ra(N=100, prob_each=c(0.3, 0.3, 0.4),\n               conditions=c(\"control\", \"placebo\", \"treatment\"))\ntable(Z)\n\nZ\n  control   placebo treatment \n       23        29        48 \n\nZ <- simple_ra(N=100, conditions=c(\"control\", \"placebo\", \"treatment\"))\ntable(Z)\n\nZ\n  control   placebo treatment \n       45        24        31"
  },
  {
    "objectID": "randomizr/reference/cluster_ra.html#description",
    "href": "randomizr/reference/cluster_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\ncluster_ra implements a random assignment procedure in which groups of units are assigned together (as a cluster) to treatment conditions. This function conducts complete random assignment at the cluster level, unless simple = TRUE, in which case simple_ra analogues are used."
  },
  {
    "objectID": "randomizr/reference/cluster_ra.html#usage",
    "href": "randomizr/reference/cluster_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncluster_ra(\n  clusters = NULL,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/cluster_ra.html#arguments",
    "href": "randomizr/reference/cluster_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nm\nUse for a two-arm design in which m clusters are assigned to treatment and N_clusters-m clusters are assigned to control. (optional)\n\n\nm_unit\nUse for a two-arm design in which exactly unique(m_unit) clusters are assigned to treatment and the remainder are assigned to control. m_unit must be of length N and must be the same for all units (optional)\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of clusters assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many clusters should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(N_clustersprob) or ceiling(N_clustersprob) clusters are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_clustersprob) clusters will be assigned to treatment and with probability prob, ceiling(N_clustersprob) clusters will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two-arm design. unique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of clusters assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nnum_arms\nThe total number of treatment arms. If unspecified, will be determined from the length of m_each or conditions.\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named T1, T2, T3, etc.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random assignment of clusters to conditions is used. When simple = TRUE, please do not specify m or m_each.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/cluster_ra.html#value",
    "href": "randomizr/reference/cluster_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit."
  },
  {
    "objectID": "randomizr/reference/cluster_ra.html#examples",
    "href": "randomizr/reference/cluster_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# Two Group Designs\nclusters <- rep(letters, times=1:26)\n\nZ <- cluster_ra(clusters = clusters)\ntable(Z, clusters)\n\n   clusters\nZ    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  1  0  3  0  0  6  0  0  9  0  0 12 13 14 15  0  0  0 19 20 21 22 23  0  0\n  1  0  2  0  4  5  0  7  8  0 10 11  0  0  0  0 16 17 18  0  0  0  0  0 24 25\n   clusters\nZ    z\n  0  0\n  1 26\n\nZ <- cluster_ra(clusters = clusters, m = 13)\ntable(Z, clusters)\n\n   clusters\nZ    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  0  0  4  5  0  0  0  9 10 11  0 13 14 15  0  0 18  0 20 21 22  0  0 25\n  1  1  2  3  0  0  6  7  8  0  0  0 12  0  0  0 16 17  0 19  0  0  0 23 24  0\n   clusters\nZ    z\n  0  0\n  1 26\n\nZ <- cluster_ra(clusters = clusters, m_each = c(10, 16),\n                conditions = c(\"control\", \"treatment\"))\ntable(Z, clusters)\n\n           clusters\nZ            a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  control    0  2  0  0  0  6  7  8  0 10 11  0  0  0  0 16 17  0 19  0  0  0\n  treatment  1  0  3  4  5  0  0  0  9  0  0 12 13 14 15  0  0 18  0 20 21 22\n           clusters\nZ            w  x  y  z\n  control    0  0 25  0\n  treatment 23 24  0 26\n\n# Multi-arm Designs\nZ <- cluster_ra(clusters = clusters, num_arms = 3)\ntable(Z, clusters)\n\n    clusters\nZ     a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  T1  1  2  0  0  5  0  0  8  0  0 11 12  0  0  0  0 17  0  0  0 21 22  0  0  0\n  T2  0  0  0  4  0  6  0  0  0  0  0  0 13 14  0  0  0 18 19  0  0  0  0  0 25\n  T3  0  0  3  0  0  0  7  0  9 10  0  0  0  0 15 16  0  0  0 20  0  0 23 24  0\n    clusters\nZ     z\n  T1  0\n  T2 26\n  T3  0\n\nZ <- cluster_ra(clusters = clusters, m_each = c(7, 7, 12))\ntable(Z, clusters)\n\n    clusters\nZ     a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  T1  0  0  0  0  0  0  0  0  0  0 11  0  0 14 15  0  0 18 19 20  0 22  0  0  0\n  T2  1  0  0  0  5  0  0  0  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0 24 25\n  T3  0  2  3  4  0  6  7  8  0  0  0 12 13  0  0 16 17  0  0  0 21  0 23  0  0\n    clusters\nZ     z\n  T1  0\n  T2 26\n  T3  0\n\nZ <- cluster_ra(clusters = clusters, m_each = c(7, 7, 12),\n                conditions = c(\"control\", \"placebo\", \"treatment\"))\ntable(Z, clusters)\n\n           clusters\nZ            a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  control    1  0  0  4  5  6  7  0  0  0 11  0  0  0  0 16  0  0  0  0  0  0\n  placebo    0  0  0  0  0  0  0  8  9 10  0  0  0  0 15  0  0  0  0  0 21  0\n  treatment  0  2  3  0  0  0  0  0  0  0  0 12 13 14  0  0 17 18 19 20  0 22\n           clusters\nZ            w  x  y  z\n  control    0  0  0  0\n  placebo   23  0  0 26\n  treatment  0 24 25  0\n\nZ <- cluster_ra(clusters = clusters,\n                conditions = c(\"control\", \"placebo\", \"treatment\"))\ntable(Z, clusters)\n\n           clusters\nZ            a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  control    1  0  0  0  5  0  0  0  0 10  0  0 13 14 15  0  0  0 19  0 21  0\n  placebo    0  0  0  4  0  0  0  8  9  0 11  0  0  0  0 16 17  0  0 20  0 22\n  treatment  0  2  3  0  0  6  7  0  0  0  0 12  0  0  0  0  0 18  0  0  0  0\n           clusters\nZ            w  x  y  z\n  control    0 24  0  0\n  placebo    0  0  0  0\n  treatment 23  0 25 26"
  },
  {
    "objectID": "randomizr/reference/cluster_rs_probabilities.html#description",
    "href": "randomizr/reference/cluster_rs_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInclusion Probabilities: Cluster Sampling"
  },
  {
    "objectID": "randomizr/reference/cluster_rs_probabilities.html#usage",
    "href": "randomizr/reference/cluster_rs_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncluster_rs_probabilities(\n  clusters = NULL,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/cluster_rs_probabilities.html#arguments",
    "href": "randomizr/reference/cluster_rs_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nn\nUse for a design in which n clusters are sampled. (optional)\n\n\nn_unit\nunique(n_unit) will be passed to n. Must be the same for all units (optional)\n\n\nprob\nUse for a design in which either floor(N_clustersprob) or ceiling(N_clustersprob) clusters are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_clustersprob) clusters will be sampled and with probability prob, ceiling(N_clustersprob) clusters will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nunique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random sampling of clusters. When simple = TRUE, please do not specify n.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/cluster_rs_probabilities.html#value",
    "href": "randomizr/reference/cluster_rs_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector length N indicating the probability of being sampled."
  },
  {
    "objectID": "randomizr/reference/cluster_rs_probabilities.html#examples",
    "href": "randomizr/reference/cluster_rs_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Two Group Designs\nclusters <- rep(letters, times = 1:26)\nprobs <- cluster_rs_probabilities(clusters = clusters)\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.5  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n     clusters\nprobs  y  z\n  0.5 25 26\n\nprob_mat <- cluster_rs_probabilities(clusters = clusters, n = 10)\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.5  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n     clusters\nprobs  y  z\n  0.5 25 26\n\nprob_mat <- cluster_rs_probabilities(clusters = clusters, prob = .3)\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.5  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n     clusters\nprobs  y  z\n  0.5 25 26"
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs_probabilities.html#description",
    "href": "randomizr/reference/strata_and_cluster_rs_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInclusion Probabilities: Stratified and Clustered Random Sampling"
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs_probabilities.html#usage",
    "href": "randomizr/reference/strata_and_cluster_rs_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nstrata_and_cluster_rs_probabilities(\n  strata = NULL,\n  clusters = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  n = NULL,\n  n_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs_probabilities.html#arguments",
    "href": "randomizr/reference/strata_and_cluster_rs_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nprob\nUse for a design in which either floor(N_clusters_stratumprob) or ceiling(N_clusters_stratumprob) clusters are sampled within each stratum. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_clusters_stratumprob) clusters will be sampled and with probability prob, ceiling(N_clusters_stratumprob) clusters will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. tapply(prob_unit, blocks, unique) will be passed to strata_prob.\n\n\nn\nUse for a design in which the scalar n describes the fixed number of units to sample in each stratum. This number does not vary across strata.\n\n\nn_unit\nMust be of length N. tapply(m_unit, blocks, unique) will be passed to strata_n.\n\n\nstrata_n\nUse for a design in which strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs_probabilities.html#value",
    "href": "randomizr/reference/strata_and_cluster_rs_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector length N indicating the probability of being sampled."
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs_probabilities.html#examples",
    "href": "randomizr/reference/strata_and_cluster_rs_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nclusters <- rep(letters, times = 1:26)\n\nstrata <- rep(NA, length(clusters))\nstrata[clusters %in% letters[1:5]] <- \"stratum_1\"\nstrata[clusters %in% letters[6:10]] <- \"stratum_2\"\nstrata[clusters %in% letters[11:15]] <- \"stratum_3\"\nstrata[clusters %in% letters[16:20]] <- \"stratum_4\"\nstrata[clusters %in% letters[21:26]] <- \"stratum_5\"\n\ntable(strata, clusters)\n\n           clusters\nstrata       a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  stratum_1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0\n  stratum_4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0\n  stratum_5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22\n           clusters\nstrata       w  x  y  z\n  stratum_1  0  0  0  0\n  stratum_2  0  0  0  0\n  stratum_3  0  0  0  0\n  stratum_4  0  0  0  0\n  stratum_5 23 24 25 26\n\nprobs <- strata_and_cluster_rs_probabilities(strata = strata,\n                                         clusters = clusters)\n\ntable(probs, strata)\n\n     strata\nprobs stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0.5        15        40        65        90       141\n\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.5  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n     clusters\nprobs  y  z\n  0.5 25 26\n\nprobs <- strata_and_cluster_rs_probabilities(clusters = clusters,\n                                         strata = strata,\n                                         prob = .5)\n\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.5  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n     clusters\nprobs  y  z\n  0.5 25 26\n\ntable(probs, strata)\n\n     strata\nprobs stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0.5        15        40        65        90       141\n\nprobs <- strata_and_cluster_rs_probabilities(clusters = clusters,\n                                         strata = strata,\n                                         strata_n = c(2, 3, 2, 3, 2))\n\ntable(probs, clusters)\n\n                   clusters\nprobs                a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t\n  0.333333333333333  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0.4                1  2  3  4  5  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0\n  0.6                0  0  0  0  0  6  7  8  9 10  0  0  0  0  0 16 17 18 19 20\n                   clusters\nprobs                u  v  w  x  y  z\n  0.333333333333333 21 22 23 24 25 26\n  0.4                0  0  0  0  0  0\n  0.6                0  0  0  0  0  0\n\ntable(probs, strata)\n\n                   strata\nprobs               stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0.333333333333333         0         0         0         0       141\n  0.4                      15         0        65         0         0\n  0.6                       0        40         0        90         0\n\nprobs <- strata_and_cluster_rs_probabilities(clusters = clusters,\n                                         strata = strata,\n                                         strata_prob = c(.1, .2, .3, .4, .5))\n\ntable(probs, clusters)\n\n     clusters\nprobs  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x\n  0.1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0.2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0.3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0  0  0\n  0.4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0  0  0\n  0.5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22 23 24\n     clusters\nprobs  y  z\n  0.1  0  0\n  0.2  0  0\n  0.3  0  0\n  0.4  0  0\n  0.5 25 26\n\ntable(probs, strata)\n\n     strata\nprobs stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0.1        15         0         0         0         0\n  0.2         0        40         0         0         0\n  0.3         0         0        65         0         0\n  0.4         0         0         0        90         0\n  0.5         0         0         0         0       141"
  },
  {
    "objectID": "randomizr/reference/obtain_num_permutations.html#description",
    "href": "randomizr/reference/obtain_num_permutations.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nObtain the Number of Possible Permutations from a Random Assignment Declaration"
  },
  {
    "objectID": "randomizr/reference/obtain_num_permutations.html#usage",
    "href": "randomizr/reference/obtain_num_permutations.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nobtain_num_permutations(declaration)"
  },
  {
    "objectID": "randomizr/reference/obtain_num_permutations.html#arguments",
    "href": "randomizr/reference/obtain_num_permutations.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random assignment or sampling declaration, created by declare_ra or declare_rs."
  },
  {
    "objectID": "randomizr/reference/obtain_num_permutations.html#value",
    "href": "randomizr/reference/obtain_num_permutations.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na scalar"
  },
  {
    "objectID": "randomizr/reference/obtain_num_permutations.html#examples",
    "href": "randomizr/reference/obtain_num_permutations.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Random assignment\n## complete\n\ndeclaration <- declare_ra(N = 4)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 4 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n## blocked\n\nblocks <- c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_ra(blocks = blocks)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]  7 24\n\nobtain_num_permutations(declaration)\n\n[1] 24\n\n## clustered\n\nclusters <- c(\"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_ra(clusters = clusters)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 7 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n## large\n\ndeclaration <- declare_ra(20)\nchoose(20, 10)\n\n[1] 184756\n\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]    20 10000\n\n# Random sampling\n## complete\n\ndeclaration <- declare_rs(N = 4)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 4 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n## stratified\n\nstrata <- c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_rs(strata = strata)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]  7 24\n\nobtain_num_permutations(declaration)\n\n[1] 24\n\n## clustered\n\nclusters <- c(\"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"C\")\ndeclaration <- declare_rs(clusters = clusters)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1] 7 6\n\nobtain_num_permutations(declaration)\n\n[1] 6\n\n## large\n\ndeclaration <- declare_rs(N = 20)\nperms <- obtain_permutation_matrix(declaration)\ndim(perms)\n\n[1]    20 10000"
  },
  {
    "objectID": "randomizr/reference/index.html",
    "href": "randomizr/reference/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\nblock_and_cluster_ra()\nBlocked and Clustered Random Assignment\n\n\nblock_ra()\nBlock Random Assignment\n\n\ncluster_ra()\nCluster Random Assignment\n\n\ncomplete_ra()\nComplete Random Assignment\n\n\nsimple_ra()\nSimple Random Assignment\n\n\nconduct_ra()\nConduct a random assignment\n\n\ncustom_ra()\nCustom Random Assignment\n\n\ndeclare_ra()\nDeclare a random assignment procedure."
  },
  {
    "objectID": "randomizr/reference/index.html#functions-for-calculating-probabilities-of-assignment",
    "href": "randomizr/reference/index.html#functions-for-calculating-probabilities-of-assignment",
    "title": "**Declare**Design",
    "section": "Functions for calculating probabilities of assignment",
    "text": "Functions for calculating probabilities of assignment\n\n\n\nFunction(s)\nDescription\n\n\n\n\nobtain_condition_probabilities()\nObtain the probabilities of units being in the conditions that they are in.\n\n\nobtain_num_permutations()\nObtain the Number of Possible Permutations from a Random Assignment Declaration\n\n\nobtain_permutation_matrix()\nObtain Permutation Matrix from a Random Assignment Declaration\n\n\nobtain_permutation_probabilities()\nObtain the probabilities of permutations\n\n\nblock_and_cluster_ra_probabilities()\nprobabilities of assignment: Blocked and Clustered Random Assignment\n\n\nblock_ra_probabilities()\nprobabilities of assignment: Block Random Assignment\n\n\ncluster_ra_probabilities()\nprobabilities of assignment: Cluster Random Assignment\n\n\ncustom_ra_probabilities()\nprobabilities of assignment: Custom Random Assignment\n\n\nsimple_ra_probabilities()\nprobabilities of assignment: Simple Random Assignment\n\n\ncomplete_ra_probabilities()\nprobabilities of assignment: Complete Random Assignment"
  },
  {
    "objectID": "randomizr/reference/index.html#random-sampling",
    "href": "randomizr/reference/index.html#random-sampling",
    "title": "**Declare**Design",
    "section": "Random sampling",
    "text": "Random sampling\n\n\n\nFunction(s)\nDescription\n\n\n\n\ndraw_rs()\nDraw a random sample\n\n\nsimple_rs()\nSimple Random Sampling\n\n\ncomplete_rs()\nComplete Random Sampling\n\n\nstrata_rs()\nStratified Random Sampling\n\n\nstrata_and_cluster_rs()\nStratified and Clustered Random Sampling\n\n\ndeclare_rs()\nDeclare a random sampling procedure.\n\n\ncluster_rs()\nCluster Random Sampling"
  },
  {
    "objectID": "randomizr/reference/index.html#functions-for-calculating-sampling-inclusion-probabilities",
    "href": "randomizr/reference/index.html#functions-for-calculating-sampling-inclusion-probabilities",
    "title": "**Declare**Design",
    "section": "Functions for calculating sampling inclusion probabilities",
    "text": "Functions for calculating sampling inclusion probabilities\n\n\n\nFunction(s)\nDescription\n\n\n\n\nobtain_inclusion_probabilities()\nObtain inclusion probabilities\n\n\ncluster_rs_probabilities()\nInclusion Probabilities: Cluster Sampling\n\n\ncomplete_rs_probabilities()\nInclusion Probabilities: Complete Random Sampling\n\n\nsimple_rs_probabilities()\nInclusion Probabilities: Simple Random Sampling\n\n\nstrata_and_cluster_rs_probabilities()\nInclusion Probabilities: Stratified and Clustered Random Sampling\n\n\nstrata_rs_probabilities()\nInclusion Probabilities: Stratified Random Sampling"
  },
  {
    "objectID": "randomizr/reference/randomizr.html#description",
    "href": "randomizr/reference/randomizr.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nEasy-to-Use Tools for Common Forms of Random Assignment and Sampling"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_probabilities.html#description",
    "href": "randomizr/reference/obtain_permutation_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nObtain the probabilities of permutations"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_probabilities.html#usage",
    "href": "randomizr/reference/obtain_permutation_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nobtain_permutation_probabilities(declaration)"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_probabilities.html#arguments",
    "href": "randomizr/reference/obtain_permutation_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random assignment declaration, created by declare_ra."
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_probabilities.html#value",
    "href": "randomizr/reference/obtain_permutation_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na vector of probabilities"
  },
  {
    "objectID": "randomizr/reference/obtain_permutation_probabilities.html#examples",
    "href": "randomizr/reference/obtain_permutation_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\ndeclaration <- declare_ra(N = 5, prob_each = c(.49, .51))\nobtain_num_permutations(declaration)\n\n[1] 20\n\nperm_probs <- obtain_permutation_probabilities(declaration)\nperms <- obtain_permutation_matrix(declaration)\n\n# probabilities of assignment from declaration *should* match the average over all permutations\ntrue_probabilities <- declaration$probabilities_matrix[,2]\ntrue_probabilities\n\n[1] 0.51 0.51 0.51 0.51 0.51\n\n# correctly WRONG because the perms have different probs!\nrowMeans(perms)\n\n[1] 0.5 0.5 0.5 0.5 0.5\n\n# correctly correct!\nperms %*% perm_probs\n\n     [,1]\n[1,] 0.51\n[2,] 0.51\n[3,] 0.51\n[4,] 0.51\n[5,] 0.51"
  },
  {
    "objectID": "randomizr/reference/obtain_condition_probabilities.html#description",
    "href": "randomizr/reference/obtain_condition_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nYou can either give obtain_condition_probabilities() an declaration, as created by declare_ra or you can specify the other arguments to describe a random assignment procedure. This function is especially useful when units have different probabilities of assignment and the analyst plans to use inverse-probability weights."
  },
  {
    "objectID": "randomizr/reference/obtain_condition_probabilities.html#usage",
    "href": "randomizr/reference/obtain_condition_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nobtain_condition_probabilities(\n  declaration = NULL,\n  assignment,\n  N = NULL,\n  blocks = NULL,\n  clusters = NULL,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  simple = FALSE,\n  permutation_matrix = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/obtain_condition_probabilities.html#arguments",
    "href": "randomizr/reference/obtain_condition_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random assignment declaration, created by declare_ra.\n\n\nassignment\nA vector of random assignments, often created by conduct_ra.\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nm\nUse for a two-arm design in which m units (or clusters) are assigned to treatment and N-m units (or clusters) are assigned to control. In a blocked design, exactly m units in each block will be treated. (optional)\n\n\nm_unit\nUse for a two-arm trial. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of units (or clusters) assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many units (or clusters) should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be assigned to treatment and with probability prob, ceiling(Nprob) units (or clusters) will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. Under simple random assignment, can be different for each unit or cluster. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nblock_m\nUse for a two-arm design in which block_m describes the number of units to assign to treatment within each block. Note that in previous versions of randomizr, block_m behaved like block_m_each.\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of units (or clusters) assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of units (or clusters) to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random assignment is used. When simple = TRUE, please do not specify m, m_each, block_m, or block_m_each. If simple = TRUE, prob and prob_each may vary by unit.\n\n\npermutation_matrix\nfor custom random assignment procedures.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/obtain_condition_probabilities.html#examples",
    "href": "randomizr/reference/obtain_condition_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Conduct a block random assignment\nblocks <- rep(c(\"A\", \"B\",\"C\"), times=c(50, 100, 200))\nblock_m_each <- rbind(c(10, 40),\n                 c(30, 70),\n                 c(50, 150))\ndeclaration <- declare_ra(blocks = blocks, block_m_each = block_m_each)\nZ <- conduct_ra(declaration = declaration)\ntable(Z, blocks)\n\n   blocks\nZ     A   B   C\n  0  10  30  50\n  1  40  70 150\n\nobserved_probabilities <-\n   obtain_condition_probabilities(declaration = declaration, assignment = Z)\n\n\n# Probabilities in the control group:\ntable(observed_probabilities[Z == 0], blocks[Z == 0])\n\n      \n        A  B  C\n  0.2  10  0  0\n  0.25  0  0 50\n  0.3   0 30  0\n\n# Probabilities in the treatment group:\ntable(observed_probabilities[Z == 1], blocks[Z == 1])\n\n      \n         A   B   C\n  0.7    0  70   0\n  0.75   0   0 150\n  0.8   40   0   0\n\n# Sometimes it is convenient to skip the declaration step\nZ <- conduct_ra(blocks = blocks, block_m_each = block_m_each)\nobserved_probabilities <-\n   obtain_condition_probabilities(assignment = Z,\n                                  blocks = blocks,\n                                  block_m_each = block_m_each)\ntable(observed_probabilities[Z == 0], blocks[Z == 0])\n\n      \n        A  B  C\n  0.2  10  0  0\n  0.25  0  0 50\n  0.3   0 30  0\n\ntable(observed_probabilities[Z == 1], blocks[Z == 1])\n\n      \n         A   B   C\n  0.7    0  70   0\n  0.75   0   0 150\n  0.8   40   0   0"
  },
  {
    "objectID": "randomizr/reference/block_ra_probabilities.html#description",
    "href": "randomizr/reference/block_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Block Random Assignment"
  },
  {
    "objectID": "randomizr/reference/block_ra_probabilities.html#usage",
    "href": "randomizr/reference/block_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nblock_ra_probabilities(\n  blocks = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  m = NULL,\n  m_unit = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/block_ra_probabilities.html#arguments",
    "href": "randomizr/reference/block_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to. Can be a character, factor, or numeric vector. (required)\n\n\nprob\nUse for a two-arm design in which either floor(N_blockprob) or ceiling(N_blockprob) units are assigned to treatment within each block. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_blockprob) units will be assigned to treatment and with probability prob, ceiling(N_blockprob) units will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. tapply(prob_unit, blocks, unique) will be passed to block_prob.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nm\nUse for a two-arm design in which the scalar m describes the fixed number of units to assign in each block. This number does not vary across blocks.\n\n\nm_unit\nUse for a two-arm design. Must be of length N. tapply(m_unit, blocks, unique) will be passed to block_m.\n\n\nblock_m\nUse for a two-arm design in which the vector block_m describes the number of units to assign to treatment within each block. block_m must be a numeric vector that is as long as the number of blocks and is in the same order as sort(unique(blocks)).\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of units assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of units to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Must be in the same order as sort(unique(blocks)). Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/block_ra_probabilities.html#value",
    "href": "randomizr/reference/block_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/block_ra_probabilities.html#examples",
    "href": "randomizr/reference/block_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nblocks <- rep(c(\"A\", \"B\",\"C\"), times = c(50, 100, 200))\nprob_mat <- block_ra_probabilities(blocks = blocks)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- block_ra_probabilities(blocks = blocks, m = 20)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.6    0.4\n[2,]    0.6    0.4\n[3,]    0.6    0.4\n[4,]    0.6    0.4\n[5,]    0.6    0.4\n[6,]    0.6    0.4\n\nblock_m_each <- rbind(c(25, 25),\n                 c(50, 50),\n                 c(100, 100))\n\nprob_mat <- block_ra_probabilities(blocks = blocks, block_m_each = block_m_each)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nblock_m_each <- rbind(c(10, 40),\n                 c(30, 70),\n                 c(50, 150))\n\nprob_mat <- block_ra_probabilities(blocks = blocks,\n                                   block_m_each = block_m_each,\n                                   conditions = c(\"control\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_treatment\n[1,]          0.2            0.8\n[2,]          0.2            0.8\n[3,]          0.2            0.8\n[4,]          0.2            0.8\n[5,]          0.2            0.8\n[6,]          0.2            0.8\n\nprob_mat <- block_ra_probabilities(blocks = blocks, num_arms = 3)\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.3333333 0.3333333 0.3333333\n[2,] 0.3333333 0.3333333 0.3333333\n[3,] 0.3333333 0.3333333 0.3333333\n[4,] 0.3333333 0.3333333 0.3333333\n[5,] 0.3333333 0.3333333 0.3333333\n[6,] 0.3333333 0.3333333 0.3333333\n\nblock_m_each <- rbind(c(10, 20, 20),\n                 c(30, 50, 20),\n                 c(50, 75, 75))\nprob_mat <- block_ra_probabilities(blocks = blocks, block_m_each = block_m_each)\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.2     0.4     0.4\n[2,]     0.2     0.4     0.4\n[3,]     0.2     0.4     0.4\n[4,]     0.2     0.4     0.4\n[5,]     0.2     0.4     0.4\n[6,]     0.2     0.4     0.4\n\nprob_mat <- block_ra_probabilities(blocks=blocks, block_m_each=block_m_each,\n                       conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]          0.2          0.4            0.4\n[2,]          0.2          0.4            0.4\n[3,]          0.2          0.4            0.4\n[4,]          0.2          0.4            0.4\n[5,]          0.2          0.4            0.4\n[6,]          0.2          0.4            0.4\n\nprob_mat <- block_ra_probabilities(blocks=blocks, prob_each=c(.1, .1, .8))\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.1     0.1     0.8\n[2,]     0.1     0.1     0.8\n[3,]     0.1     0.1     0.8\n[4,]     0.1     0.1     0.8\n[5,]     0.1     0.1     0.8\n[6,]     0.1     0.1     0.8"
  },
  {
    "objectID": "randomizr/reference/complete_rs.html#description",
    "href": "randomizr/reference/complete_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\ncomplete_rs implements a random sampling procedure in which fixed numbers of units are sampled. The canonical example of complete random sampling is a procedure in which exactly n of N units are sampled. Users can set the exact number of units to sample with n. Alternatively, users can specify the probability of being sampled with prob and complete_rs will infer the correct number of units to sample. complete_rs will either sample floor(Nprob) or ceiling(Nprob) units, choosing between these two values to ensure that the overall probability of being sampled is exactly prob. Users should specify N and not more than one of n or prob.\nIf only N is specified, N/2 units will be sampled. If N is odd, either floor(N/2) units or ceiling(N/2) units will be sampled."
  },
  {
    "objectID": "randomizr/reference/complete_rs.html#usage",
    "href": "randomizr/reference/complete_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncomplete_rs(\n  N,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/complete_rs.html#arguments",
    "href": "randomizr/reference/complete_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nn\nUse for a design in which exactly n units are sampled. (optional)\n\n\nn_unit\nunique(n_unit) will be passed to n. Must be the same for all units (optional)\n\n\nprob\nUse for a design in which either floor(Nprob) or ceiling(Nprob) units are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(Nprob) units will be sampled and with probability prob, ceiling(Nprob) units will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nunique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/complete_rs.html#value",
    "href": "randomizr/reference/complete_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA numeric vector of length N that indicates if a unit is sampled (1) or not (0)."
  },
  {
    "objectID": "randomizr/reference/complete_rs.html#examples",
    "href": "randomizr/reference/complete_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nS <- complete_rs(N = 100)\ntable(S)\n\nS\n 0  1 \n50 50 \n\nS <- complete_rs(N = 100, n = 50)\ntable(S)\n\nS\n 0  1 \n50 50 \n\nS <- complete_rs(N = 100, n_unit = rep(50, 100))\ntable(S)\n\nS\n 0  1 \n50 50 \n\nS <- complete_rs(N = 100, prob = .111)\ntable(S)\n\nS\n 0  1 \n89 11 \n\nS <- complete_rs(N = 100, prob_unit = rep(.1, 100))\ntable(S)\n\nS\n 0  1 \n90 10 \n\n# If N = n, sample with 100% probability...\ncomplete_rs(N=2, n=2)\n\n[1] 1 1\n\n# Up through randomizr 0.12.0, \n# This behavior has been deprecated\ncomplete_rs(N=1, n=1) # sampled with 50% probability\n\n[1] 1"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra_probabilities.html#description",
    "href": "randomizr/reference/block_and_cluster_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Blocked and Clustered Random Assignment"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra_probabilities.html#usage",
    "href": "randomizr/reference/block_and_cluster_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nblock_and_cluster_ra_probabilities(\n  blocks = NULL,\n  clusters = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  m = NULL,\n  m_unit = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra_probabilities.html#arguments",
    "href": "randomizr/reference/block_and_cluster_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nprob\nUse for a two-arm design in which either floor(N_clusters_blockprob) or ceiling(N_clusters_blockprob) clusters are assigned to treatment within each block. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_clusters_blockprob) clusters will be assigned to treatment and with probability prob, ceiling(N_clusters_blockprob) clusters will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. tapply(prob_unit, blocks, unique) will be passed to block_prob.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of clusters assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nm\nUse for a two-arm design in which the scalar m describes the fixed number of clusters assigned in each block. This number does not vary across blocks.\n\n\nm_unit\nUse for a two-arm design. Must be of length N. tapply(m_unit, blocks, unique) will be passed to block_m.\n\n\nblock_m\nUse for a two-arm design in which block_m describes the number of clusters to assign to treatment within each block. block_m must be a numeric vector that is as long as the number of blocks and is in the same order as sort(unique(blocks)).\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of clusters assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of clusters to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Must be in the same order as sort(unique(blocks)). Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra_probabilities.html#value",
    "href": "randomizr/reference/block_and_cluster_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/block_and_cluster_ra_probabilities.html#examples",
    "href": "randomizr/reference/block_and_cluster_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nclusters <- rep(letters, times=1:26)\nblocks <- rep(NA, length(clusters))\nblocks[clusters %in% letters[1:5]] <- \"block_1\"\nblocks[clusters %in% letters[6:10]] <- \"block_2\"\nblocks[clusters %in% letters[11:15]] <- \"block_3\"\nblocks[clusters %in% letters[16:20]] <- \"block_4\"\nblocks[clusters %in% letters[21:26]] <- \"block_5\"\n\n\nprob_mat <- block_and_cluster_ra_probabilities(clusters = clusters,\n                                               blocks = blocks)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- block_and_cluster_ra_probabilities(clusters = clusters,\n                                               blocks = blocks,\n                                               num_arms = 3)\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.3333333 0.3333333 0.3333333\n[2,] 0.3333333 0.3333333 0.3333333\n[3,] 0.3333333 0.3333333 0.3333333\n[4,] 0.3333333 0.3333333 0.3333333\n[5,] 0.3333333 0.3333333 0.3333333\n[6,] 0.3333333 0.3333333 0.3333333\n\nprob_mat <- block_and_cluster_ra_probabilities(clusters = clusters,\n                                               blocks = blocks,\n                                               prob_each = c(.2, .5, .3))\nhead(prob_mat)                                    \n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.2     0.5     0.3\n[2,]     0.2     0.5     0.3\n[3,]     0.2     0.5     0.3\n[4,]     0.2     0.5     0.3\n[5,]     0.2     0.5     0.3\n[6,]     0.2     0.5     0.3\n\nblock_m_each <- rbind(c(2, 3),\n                      c(1, 4),\n                      c(3, 2),\n                      c(2, 3),\n                      c(5, 1))\n\nprob_mat <- block_and_cluster_ra_probabilities(clusters = clusters, \n                                               blocks = blocks, \n                                               block_m_each = block_m_each)\nhead(prob_mat)                                    \n\n     prob_0 prob_1\n[1,]    0.4    0.6\n[2,]    0.4    0.6\n[3,]    0.4    0.6\n[4,]    0.4    0.6\n[5,]    0.4    0.6\n[6,]    0.4    0.6"
  },
  {
    "objectID": "randomizr/reference/declare_ra.html#description",
    "href": "randomizr/reference/declare_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare a random assignment procedure."
  },
  {
    "objectID": "randomizr/reference/declare_ra.html#usage",
    "href": "randomizr/reference/declare_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_ra(\n  N = NULL,\n  blocks = NULL,\n  clusters = NULL,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  simple = FALSE,\n  permutation_matrix = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/declare_ra.html#arguments",
    "href": "randomizr/reference/declare_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nm\nUse for a two-arm design in which m units (or clusters) are assigned to treatment and N-m units (or clusters) are assigned to control. In a blocked design, exactly m units in each block will be treated. (optional)\n\n\nm_unit\nUse for a two-arm trial. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of units (or clusters) assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many units (or clusters) should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be assigned to treatment and with probability prob, ceiling(Nprob) units (or clusters) will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. Under simple random assignment, can be different for each unit or cluster. Under complete random assignment, must be constant across units. Under blocked random assignment, must be constant within blocks.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nblock_m\nUse for a two-arm design in which block_m describes the number of units to assign to treatment within each block. Note that in previous versions of randomizr, block_m behaved like block_m_each.\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of units (or clusters) assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of units (or clusters) to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random assignment is used. When simple = TRUE, please do not specify m, m_each, block_m, or block_m_each. If simple = TRUE, prob and prob_each may vary by unit.\n\n\npermutation_matrix\nfor custom random assignment procedures.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/declare_ra.html#value",
    "href": "randomizr/reference/declare_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA list of class “declaration”. The list has five entries: $ra_function, a function that generates random assignments according to the declaration. $ra_type, a string indicating the type of random assignment used $probabilities_matrix, a matrix with N rows and num_arms columns, describing each unit’s probabilities of assignment to conditions. $blocks, the blocking variable. $clusters, the clustering variable."
  },
  {
    "objectID": "randomizr/reference/declare_ra.html#examples",
    "href": "randomizr/reference/declare_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# The declare_ra function is used in three ways:\n\n# 1. To obtain some basic facts about a randomization:\ndeclaration <- declare_ra(N=100, m_each=c(30, 30, 40))\ndeclaration\n\nRandom assignment procedure: Complete random assignment \nNumber of units: 100 \nNumber of treatment arms: 3 \nThe possible treatment categories are T1 and T2 and T3.\nThe number of possible random assignments is approximately infinite. \nThe probabilities of assignment are constant across units: \nprob_T1 prob_T2 prob_T3 \n    0.3     0.3     0.4 \n\n# 2. To conduct a random assignment:\n\nZ <- conduct_ra(declaration)\ntable(Z)\n\nZ\nT1 T2 T3 \n30 30 40 \n\n# 3. To obtain observed condition probabilities\n\nprobs <- obtain_condition_probabilities(declaration, Z)\ntable(probs, Z)\n\n     Z\nprobs T1 T2 T3\n  0.3 30 30  0\n  0.4  0  0 40\n\n# Simple Random Assignment Declarations\n\ndeclare_ra(N=100, simple = TRUE)\n\nRandom assignment procedure: Simple random assignment \nNumber of units: 100 \nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is 1.26765060022823e+30.  \nThe probabilities of assignment are constant across units: \nprob_0 prob_1 \n   0.5    0.5 \n\ndeclare_ra(N=100, prob = .4, simple = TRUE)\n\nRandom assignment procedure: Simple random assignment \nNumber of units: 100 \nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is 1.26765060022823e+30.  \nThe probabilities of assignment are constant across units: \nprob_0 prob_1 \n   0.6    0.4 \n\ndeclare_ra(N=100, prob_each=c(0.3, 0.3, 0.4),\n           conditions=c(\"control\", \"placebo\", \"treatment\"), simple=TRUE)\n\nRandom assignment procedure: Simple random assignment \nNumber of units: 100 \nNumber of treatment arms: 3 \nThe possible treatment categories are control and placebo and treatment.\nThe number of possible random assignments is 5.15377520732011e+47.  \nThe probabilities of assignment are constant across units: \n  prob_control   prob_placebo prob_treatment \n           0.3            0.3            0.4 \n\n# Complete Random Assignment Declarations\n\ndeclare_ra(N=100)\n\nRandom assignment procedure: Complete random assignment \nNumber of units: 100 \nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is approximately infinite. \nThe probabilities of assignment are constant across units: \nprob_0 prob_1 \n   0.5    0.5 \n\ndeclare_ra(N=100, m_each = c(30, 70),\n           conditions = c(\"control\", \"treatment\"))\n\nRandom assignment procedure: Complete random assignment \nNumber of units: 100 \nNumber of treatment arms: 2 \nThe possible treatment categories are control and treatment.\nThe number of possible random assignments is approximately infinite. \nThe probabilities of assignment are constant across units: \n  prob_control prob_treatment \n           0.3            0.7 \n\ndeclare_ra(N=100, m_each=c(30, 30, 40))\n\nRandom assignment procedure: Complete random assignment \nNumber of units: 100 \nNumber of treatment arms: 3 \nThe possible treatment categories are T1 and T2 and T3.\nThe number of possible random assignments is approximately infinite. \nThe probabilities of assignment are constant across units: \nprob_T1 prob_T2 prob_T3 \n    0.3     0.3     0.4 \n\n# Block Random Assignment Declarations\n\nblocks <- rep(c(\"A\", \"B\",\"C\"), times = c(50, 100, 200))\n\nblock_m_each <- rbind(c(10, 40),\n                 c(30, 70),\n                 c(50, 150))\ndeclare_ra(blocks = blocks, block_m_each = block_m_each)\n\nRandom assignment procedure: Block random assignment \nNumber of units: 350 \nNumber of blocks: 3\nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is approximately infinite. \nThe probabilities of assignment are NOT constant across units. Your analysis strategy must account for differential probabilities of assignment, typically by employing inverse probability weights.\n\n# Cluster Random Assignment Declarations\n\nclusters <- rep(letters, times = 1:26)\ndeclare_ra(clusters = clusters)\n\nRandom assignment procedure: Cluster random assignment \nNumber of units: 351 \nNumber of clusters: 26\nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is 10400600.  \nThe probabilities of assignment are constant across units: \nprob_0 prob_1 \n   0.5    0.5 \n\ndeclare_ra(clusters = clusters, m_each = c(7, 7, 12))\n\nRandom assignment procedure: Cluster random assignment \nNumber of units: 351 \nNumber of clusters: 26\nNumber of treatment arms: 3 \nThe possible treatment categories are T1 and T2 and T3.\nThe number of possible random assignments is 33145226400.  \nThe probabilities of assignment are constant across units: \n  prob_T1   prob_T2   prob_T3 \n0.2692308 0.2692308 0.4615385 \n\n# Blocked and Clustered Random Assignment Declarations\n\nclusters <- rep(letters, times=1:26)\nblocks <- rep(NA, length(clusters))\nblocks[clusters %in% letters[1:5]] <- \"block_1\"\nblocks[clusters %in% letters[6:10]] <- \"block_2\"\nblocks[clusters %in% letters[11:15]] <- \"block_3\"\nblocks[clusters %in% letters[16:20]] <- \"block_4\"\nblocks[clusters %in% letters[21:26]] <- \"block_5\"\n\ntable(blocks, clusters)\n\n         clusters\nblocks     a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w\n  block_1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  block_2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n  block_3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0  0\n  block_4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0  0\n  block_5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22 23\n         clusters\nblocks     x  y  z\n  block_1  0  0  0\n  block_2  0  0  0\n  block_3  0  0  0\n  block_4  0  0  0\n  block_5 24 25 26\n\ndeclare_ra(clusters = clusters, blocks = blocks)\n\nRandom assignment procedure: Blocked and clustered random assignment \nNumber of units: 351 \nNumber of blocks: 5\nNumber of clusters: 26\nNumber of treatment arms: 2 \nThe possible treatment categories are 0 and 1.\nThe number of possible random assignments is 3200000.  \nThe probabilities of assignment are constant across units: \nprob_0 prob_1 \n   0.5    0.5 \n\ndeclare_ra(clusters = clusters, blocks = blocks, prob_each = c(.2, .5, .3))\n\nRandom assignment procedure: Blocked and clustered random assignment \nNumber of units: 351 \nNumber of blocks: 5\nNumber of clusters: 26\nNumber of treatment arms: 3 \nThe possible treatment categories are T1 and T2 and T3.\nThe number of possible random assignments is 6.144e+09.  \nThe probabilities of assignment are constant across units: \nprob_T1 prob_T2 prob_T3 \n    0.2     0.5     0.3"
  },
  {
    "objectID": "randomizr/reference/custom_ra_probabilities.html#description",
    "href": "randomizr/reference/custom_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Custom Random Assignment"
  },
  {
    "objectID": "randomizr/reference/custom_ra_probabilities.html#usage",
    "href": "randomizr/reference/custom_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncustom_ra_probabilities(permutation_matrix)"
  },
  {
    "objectID": "randomizr/reference/custom_ra_probabilities.html#arguments",
    "href": "randomizr/reference/custom_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\npermutation_matrix\nA permutation matrix"
  },
  {
    "objectID": "randomizr/reference/custom_ra_probabilities.html#value",
    "href": "randomizr/reference/custom_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/custom_ra_probabilities.html#examples",
    "href": "randomizr/reference/custom_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# TODO"
  },
  {
    "objectID": "randomizr/reference/cluster_ra_probabilities.html#description",
    "href": "randomizr/reference/cluster_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Cluster Random Assignment"
  },
  {
    "objectID": "randomizr/reference/cluster_ra_probabilities.html#usage",
    "href": "randomizr/reference/cluster_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncluster_ra_probabilities(\n  clusters = NULL,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/cluster_ra_probabilities.html#arguments",
    "href": "randomizr/reference/cluster_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nm\nUse for a two-arm design in which m clusters are assigned to treatment and N_clusters-m clusters are assigned to control. (optional)\n\n\nm_unit\nUse for a two-arm design in which exactly unique(m_unit) clusters are assigned to treatment and the remainder are assigned to control. m_unit must be of length N and must be the same for all units (optional)\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of clusters assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many clusters should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(N_clustersprob) or ceiling(N_clustersprob) clusters are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_clustersprob) clusters will be assigned to treatment and with probability prob, ceiling(N_clustersprob) clusters will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two-arm design. unique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of clusters assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nnum_arms\nThe total number of treatment arms. If unspecified, will be determined from the length of m_each or conditions.\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named T1, T2, T3, etc.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random assignment of clusters to conditions is used. When simple = TRUE, please do not specify m or m_each.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/cluster_ra_probabilities.html#value",
    "href": "randomizr/reference/cluster_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/cluster_ra_probabilities.html#examples",
    "href": "randomizr/reference/cluster_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Two Group Designs\nclusters <- rep(letters, times = 1:26)\nprob_mat <- cluster_ra_probabilities(clusters = clusters)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters, m = 10)\nhead(prob_mat)\n\n        prob_0    prob_1\n[1,] 0.6153846 0.3846154\n[2,] 0.6153846 0.3846154\n[3,] 0.6153846 0.3846154\n[4,] 0.6153846 0.3846154\n[5,] 0.6153846 0.3846154\n[6,] 0.6153846 0.3846154\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters,\n                                     m_each = c(9, 17),\n                                     conditions = c(\"control\", \"treatment\"))\n\n# Multi-arm Designs\nprob_mat <- cluster_ra_probabilities(clusters = clusters, num_arms = 3)\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.3333333 0.3333333 0.3333333\n[2,] 0.3333333 0.3333333 0.3333333\n[3,] 0.3333333 0.3333333 0.3333333\n[4,] 0.3333333 0.3333333 0.3333333\n[5,] 0.3333333 0.3333333 0.3333333\n[6,] 0.3333333 0.3333333 0.3333333\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters, m_each = c(7, 7, 12))\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.2692308 0.2692308 0.4615385\n[2,] 0.2692308 0.2692308 0.4615385\n[3,] 0.2692308 0.2692308 0.4615385\n[4,] 0.2692308 0.2692308 0.4615385\n[5,] 0.2692308 0.2692308 0.4615385\n[6,] 0.2692308 0.2692308 0.4615385\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters, m_each = c(7, 7, 12),\n                         conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]    0.2692308    0.2692308      0.4615385\n[2,]    0.2692308    0.2692308      0.4615385\n[3,]    0.2692308    0.2692308      0.4615385\n[4,]    0.2692308    0.2692308      0.4615385\n[5,]    0.2692308    0.2692308      0.4615385\n[6,]    0.2692308    0.2692308      0.4615385\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters,\n                         conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]    0.3333333    0.3333333      0.3333333\n[2,]    0.3333333    0.3333333      0.3333333\n[3,]    0.3333333    0.3333333      0.3333333\n[4,]    0.3333333    0.3333333      0.3333333\n[5,]    0.3333333    0.3333333      0.3333333\n[6,]    0.3333333    0.3333333      0.3333333\n\nprob_mat <- cluster_ra_probabilities(clusters = clusters,\n                                     prob_each = c(.1, .2, .7))\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.1     0.2     0.7\n[2,]     0.1     0.2     0.7\n[3,]     0.1     0.2     0.7\n[4,]     0.1     0.2     0.7\n[5,]     0.1     0.2     0.7\n[6,]     0.1     0.2     0.7"
  },
  {
    "objectID": "randomizr/reference/obtain_inclusion_probabilities.html#description",
    "href": "randomizr/reference/obtain_inclusion_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nYou can either give obtain_inclusion_probabilities() an declaration, as created by declare_rs or you can specify the other arguments to describe a random sampling procedure. This function is especially useful when units have different inclusion probabilities and the analyst plans to use inverse-probability weights."
  },
  {
    "objectID": "randomizr/reference/obtain_inclusion_probabilities.html#usage",
    "href": "randomizr/reference/obtain_inclusion_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nobtain_inclusion_probabilities(\n  declaration = NULL,\n  N = NULL,\n  strata = NULL,\n  clusters = NULL,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/obtain_inclusion_probabilities.html#arguments",
    "href": "randomizr/reference/obtain_inclusion_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndeclaration\nA random sampling declaration, created by declare_rs.\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nn\nUse for a design in which n units (or clusters) are sampled. In a stratified design, exactly n units in each stratum will be sampled. (optional)\n\n\nn_unit\nUnder complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nprob\nUse for a design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be sampled and with probability prob, ceiling(Nprob) units (or clusters) will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. Under simple random sampling, can be different for each unit or cluster. Under complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nstrata_n\nUse for a design in which strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random sampling is used. When simple = TRUE, please do not specify n or strata_n. When simple = TRUE, prob may vary by unit.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/obtain_inclusion_probabilities.html#examples",
    "href": "randomizr/reference/obtain_inclusion_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Draw a stratified random sample\nstrata <- rep(c(\"A\", \"B\",\"C\"), times=c(50, 100, 200))\n\ndeclaration <- declare_rs(strata = strata)\n\nobserved_probabilities <-\n   obtain_inclusion_probabilities(declaration = declaration)\n\ntable(strata, observed_probabilities)\n\n      observed_probabilities\nstrata 0.5\n     A  50\n     B 100\n     C 200\n\n# Sometimes it is convenient to skip the declaration step\nobserved_probabilities <-\n   obtain_inclusion_probabilities(strata = strata)\n\ntable(strata, observed_probabilities)\n\n      observed_probabilities\nstrata 0.5\n     A  50\n     B 100\n     C 200"
  },
  {
    "objectID": "randomizr/reference/declare_rs.html#description",
    "href": "randomizr/reference/declare_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare a random sampling procedure."
  },
  {
    "objectID": "randomizr/reference/declare_rs.html#usage",
    "href": "randomizr/reference/declare_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_rs(\n  N = NULL,\n  strata = NULL,\n  clusters = NULL,\n  n = NULL,\n  n_unit = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  simple = FALSE,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/declare_rs.html#arguments",
    "href": "randomizr/reference/declare_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nn\nUse for a design in which n units (or clusters) are sampled. In a stratified design, exactly n units in each stratum will be sampled. (optional)\n\n\nn_unit\nUnder complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nprob\nUse for a design in which either floor(Nprob) or ceiling(Nprob) units (or clusters) are sampled. The probability of being sampled is exactly prob because with probability 1-prob, floor(Nprob) units (or clusters) will be sampled and with probability prob, ceiling(Nprob) units (or clusters) will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. Under simple random sampling, can be different for each unit or cluster. Under complete random sampling, must be constant across units. Under stratified random sampling, must be constant within strata.\n\n\nstrata_n\nUse for a design in which strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\nsimple\nlogical, defaults to FALSE. If TRUE, simple random sampling is used. When simple = TRUE, please do not specify n or strata_n. When simple = TRUE, prob may vary by unit.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/declare_rs.html#value",
    "href": "randomizr/reference/declare_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA list of class “declaration”. The list has five entries: $rs_function, a function that generates random samplings according to the declaration. $rs_type, a string indicating the type of random sampling used $probabilities_vector, A vector length N indicating the probability of being sampled. $strata, the stratification variable. $clusters, the clustering variable."
  },
  {
    "objectID": "randomizr/reference/declare_rs.html#examples",
    "href": "randomizr/reference/declare_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# The declare_rs function is used in three ways:\n\n# 1. To obtain some basic facts about a sampling procedure:\ndeclaration <- declare_rs(N = 100, n = 30)\ndeclaration\n\nRandom sampling procedure: Complete random sampling \nNumber of units: 100 \nThe inclusion probabilities are constant across units.\n\n# 2. To draw a random sample:\n\nS <- draw_rs(declaration)\ntable(S)\n\nS\n 0  1 \n70 30 \n\n# 3. To obtain inclusion probabilities\n\nprobs <- obtain_inclusion_probabilities(declaration)\ntable(probs, S)\n\n     S\nprobs  0  1\n  0.3 70 30\n\n# Simple Random Sampling Declarations\n\ndeclare_rs(N = 100, simple = TRUE)\n\nRandom sampling procedure: Simple random sampling \nNumber of units: 100 \nThe inclusion probabilities are constant across units.\n\ndeclare_rs(N = 100, prob = .4, simple = TRUE)\n\nRandom sampling procedure: Simple random sampling \nNumber of units: 100 \nThe inclusion probabilities are constant across units.\n\n# Complete Random Sampling Declarations\n\ndeclare_rs(N = 100)\n\nRandom sampling procedure: Complete random sampling \nNumber of units: 100 \nThe inclusion probabilities are constant across units.\n\ndeclare_rs(N = 100, n = 30)\n\nRandom sampling procedure: Complete random sampling \nNumber of units: 100 \nThe inclusion probabilities are constant across units.\n\n# Stratified Random Sampling Declarations\n\nstrata <- rep(c(\"A\", \"B\",\"C\"), times=c(50, 100, 200))\ndeclare_rs(strata = strata)\n\nRandom sampling procedure: Stratified random sampling \nNumber of units: 350 \nNumber of strata: 3 \nThe inclusion probabilities are constant across units.\n\ndeclare_rs(strata = strata, prob = .5)\n\nRandom sampling procedure: Stratified random sampling \nNumber of units: 350 \nNumber of strata: 3 \nThe inclusion probabilities are constant across units.\n\n# Cluster Random Sampling Declarations\n\nclusters <- rep(letters, times = 1:26)\ndeclare_rs(clusters = clusters)\n\nRandom sampling procedure: Cluster random sampling \nNumber of units: 351 \nNumber of clusters: 26 \nThe inclusion probabilities are constant across units.\n\ndeclare_rs(clusters = clusters, n = 10)\n\nRandom sampling procedure: Cluster random sampling \nNumber of units: 351 \nNumber of clusters: 26 \nThe inclusion probabilities are constant across units.\n\n# Stratified and Clustered Random Sampling Declarations\n\nclusters <- rep(letters, times = 1:26)\nstrata <- rep(NA, length(clusters))\nstrata[clusters %in% letters[1:5]] <- \"stratum_1\"\nstrata[clusters %in% letters[6:10]] <- \"stratum_2\"\nstrata[clusters %in% letters[11:15]] <- \"stratum_3\"\nstrata[clusters %in% letters[16:20]] <- \"stratum_4\"\nstrata[clusters %in% letters[21:26]] <- \"stratum_5\"\n\ntable(strata, clusters)\n\n           clusters\nstrata       a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  stratum_1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0\n  stratum_4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0\n  stratum_5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22\n           clusters\nstrata       w  x  y  z\n  stratum_1  0  0  0  0\n  stratum_2  0  0  0  0\n  stratum_3  0  0  0  0\n  stratum_4  0  0  0  0\n  stratum_5 23 24 25 26\n\ndeclare_rs(clusters = clusters, strata = strata)\n\nRandom sampling procedure: Stratified and clustered random sampling \nNumber of units: 351 \nNumber of strata: 5 \nNumber of clusters: 26 \nThe inclusion probabilities are constant across units.\n\ndeclare_rs(clusters = clusters, strata = strata, prob = .3)\n\nRandom sampling procedure: Stratified and clustered random sampling \nNumber of units: 351 \nNumber of strata: 5 \nNumber of clusters: 26 \nThe inclusion probabilities are constant across units."
  },
  {
    "objectID": "randomizr/reference/complete_ra.html#description",
    "href": "randomizr/reference/complete_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\ncomplete_ra implements a random assignment procedure in which fixed numbers of units are assigned to treatment conditions. The canonical example of complete random assignment is a procedure in which exactly m of N units are assigned to treatment and N-m units are assigned to control. Users can set the exact number of units to assign to each condition with m or m_each. Alternatively, users can specify probabilities of assignment with prob or prob_each and complete_ra will infer the correct number of units to assign to each condition. In a two-arm design, complete_ra will either assign floor(Nprob) or ceiling(Nprob) units to treatment, choosing between these two values to ensure that the overall probability of assignment is exactly prob. In a multi-arm design, complete_ra will first assign floor(N*prob_each) units to their respective conditions, then will assign the remaining units using simple random assignment, choosing these second-stage probabilities so that the overall probabilities of assignment are exactly prob_each. In most cases, users should specify N and not more than one of m, m_each, prob, prob_each, or num_arms.\nIf only N is specified, a two-arm trial in which N/2 units are assigned to treatment is assumed. If N is odd, either floor(N/2) units or ceiling(N/2) units will be assigned to treatment."
  },
  {
    "objectID": "randomizr/reference/complete_ra.html#usage",
    "href": "randomizr/reference/complete_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncomplete_ra(\n  N,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/complete_ra.html#arguments",
    "href": "randomizr/reference/complete_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nm\nUse for a two-arm design in which m units are assigned to treatment and N-m units are assigned to control. (optional)\n\n\nm_unit\nUse for a two-arm design in which exactly unique(m_unit) units are assigned to treatment and the remainder are assigned to control. m_unit must be of length N and must be the same for all units (optional)\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of units assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many units should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(Nprob) or ceiling(Nprob) units are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(Nprob) units will be assigned to treatment and with probability prob, ceiling(Nprob) units will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two-arm design. unique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/complete_ra.html#value",
    "href": "randomizr/reference/complete_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit. Is numeric in a two-arm trial and a factor variable (ordered by conditions) in a multi-arm trial."
  },
  {
    "objectID": "randomizr/reference/complete_ra.html#examples",
    "href": "randomizr/reference/complete_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# Two-arm Designs\nZ <- complete_ra(N = 100)\ntable(Z)\n\nZ\n 0  1 \n50 50 \n\nZ <- complete_ra(N = 100, m = 50)\ntable(Z)\n\nZ\n 0  1 \n50 50 \n\nZ <- complete_ra(N = 100, m_unit = rep(50, 100))\ntable(Z)\n\nZ\n 0  1 \n50 50 \n\nZ <- complete_ra(N = 100, prob = .111)\ntable(Z)\n\nZ\n 0  1 \n88 12 \n\nZ <- complete_ra(N = 100, prob_unit = rep(0.1, 100))\ntable(Z)\n\nZ\n 0  1 \n90 10 \n\nZ <- complete_ra(N = 100, conditions = c(\"control\", \"treatment\"))\ntable(Z)\n\nZ\n  control treatment \n       50        50 \n\n# Multi-arm Designs\nZ <- complete_ra(N = 100, num_arms = 3)\ntable(Z)\n\nZ\nT1 T2 T3 \n33 33 34 \n\nZ <- complete_ra(N = 100, m_each = c(30, 30, 40))\ntable(Z)\n\nZ\nT1 T2 T3 \n30 30 40 \n\nZ <- complete_ra(N = 100, prob_each = c(.1, .2, .7))\ntable(Z)\n\nZ\nT1 T2 T3 \n10 20 70 \n\nZ <- complete_ra(N = 100, conditions = c(\"control\", \"placebo\", \"treatment\"))\ntable(Z)\n\nZ\n  control   placebo treatment \n       34        33        33 \n\n# Special Cases\n# Two-arm trial where the conditions are by default \"T1\" and \"T2\"\nZ <- complete_ra(N = 100, num_arms = 2)\ntable(Z)\n\nZ\nT1 T2 \n50 50 \n\n# If N = m, assign with 100% probability\ncomplete_ra(N=2, m=2)\n\n[1] 1 1\n\n# Up through randomizr 0.12.0, \ncomplete_ra(N=1, m=1) # assigned with 50% probability\n\n[1] 1\n\n# This behavior has been deprecated"
  },
  {
    "objectID": "randomizr/reference/simple_rs_probabilities.html#description",
    "href": "randomizr/reference/simple_rs_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInclusion Probabilities: Simple Random Sampling"
  },
  {
    "objectID": "randomizr/reference/simple_rs_probabilities.html#usage",
    "href": "randomizr/reference/simple_rs_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsimple_rs_probabilities(\n  N,\n  prob = NULL,\n  prob_unit = NULL,\n  check_inputs = TRUE,\n  simple = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/simple_rs_probabilities.html#arguments",
    "href": "randomizr/reference/simple_rs_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nprob\nprob is the probability of being sampled must be a real number between 0 and 1 inclusive, and must be of length 1. (optional)\n\n\nprob_unit\nprob is the probability of being sampled must be a real number between 0 and 1 inclusive, and must be of length N. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE.\n\n\nsimple\nlogical. internal use only."
  },
  {
    "objectID": "randomizr/reference/simple_rs_probabilities.html#value",
    "href": "randomizr/reference/simple_rs_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector length N indicating the probability of being sampled."
  },
  {
    "objectID": "randomizr/reference/simple_rs_probabilities.html#examples",
    "href": "randomizr/reference/simple_rs_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nprobs <- simple_ra_probabilities(N = 100)\ntable(probs)\n\nprobs\n0.5 \n200 \n\nprobs <- simple_ra_probabilities(N = 100, prob = 0.3)\ntable(probs)\n\nprobs\n0.3 0.7 \n100 100"
  },
  {
    "objectID": "randomizr/reference/block_ra.html#description",
    "href": "randomizr/reference/block_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nblock_ra implements a random assignment procedure in which units that are grouped into blocks defined by pre-treatment covariates are assigned using complete random assignment within block. For example, imagine that 50 of 100 men are assigned to treatment and 75 of 200 women are assigned to treatment."
  },
  {
    "objectID": "randomizr/reference/block_ra.html#usage",
    "href": "randomizr/reference/block_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nblock_ra(\n  blocks = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  m = NULL,\n  m_unit = NULL,\n  block_m = NULL,\n  block_m_each = NULL,\n  block_prob = NULL,\n  block_prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/block_ra.html#arguments",
    "href": "randomizr/reference/block_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nblocks\nA vector of length N that indicates which block each unit belongs to. Can be a character, factor, or numeric vector. (required)\n\n\nprob\nUse for a two-arm design in which either floor(N_blockprob) or ceiling(N_blockprob) units are assigned to treatment within each block. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(N_blockprob) units will be assigned to treatment and with probability prob, ceiling(N_blockprob) units will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two arm design. Must of be of length N. tapply(prob_unit, blocks, unique) will be passed to block_prob.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nm\nUse for a two-arm design in which the scalar m describes the fixed number of units to assign in each block. This number does not vary across blocks.\n\n\nm_unit\nUse for a two-arm design. Must be of length N. tapply(m_unit, blocks, unique) will be passed to block_m.\n\n\nblock_m\nUse for a two-arm design in which the vector block_m describes the number of units to assign to treatment within each block. block_m must be a numeric vector that is as long as the number of blocks and is in the same order as sort(unique(blocks)).\n\n\nblock_m_each\nUse for a multi-arm design in which the values of block_m_each determine the number of units assigned to each condition. block_m_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the number of units to be assigned to each treatment arm within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). The columns should be in the order of conditions, if specified.\n\n\nblock_prob\nUse for a two-arm design in which block_prob describes the probability of assignment to treatment within each block. Must be in the same order as sort(unique(blocks)). Differs from prob in that the probability of assignment can vary across blocks.\n\n\nblock_prob_each\nUse for a multi-arm design in which the values of block_prob_each determine the probabilities of assignment to each treatment condition. block_prob_each must be a matrix with the same number of rows as blocks and the same number of columns as treatment arms. Cell entries are the probabilities of assignment to treatment within each block. The rows should respect the ordering of the blocks as determined by sort(unique(blocks)). Use only if the probabilities of assignment should vary by block, otherwise use prob_each. Each row of block_prob_each must sum to 1.\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/block_ra.html#value",
    "href": "randomizr/reference/block_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit. Is numeric in a two-arm trial and a factor variable (ordered by conditions) in a multi-arm trial."
  },
  {
    "objectID": "randomizr/reference/block_ra.html#examples",
    "href": "randomizr/reference/block_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\n# Two-arm Designs\n\nblocks <- rep(c(\"A\", \"B\",\"C\"), times = c(50, 100, 200))\nZ <- block_ra(blocks = blocks)\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  25  25\n     B  50  50\n     C 100 100\n\nZ <- block_ra(blocks = blocks, prob = .3)\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  35  15\n     B  70  30\n     C 140  60\n\nZ <- block_ra(blocks = blocks, block_prob = c(.1, .2, .3))\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  45   5\n     B  80  20\n     C 140  60\n\nZ <- block_ra(blocks = blocks, \n              prob_unit = rep(c(.1, .2, .3), \n                              times = c(50, 100, 200)))\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  45   5\n     B  80  20\n     C 140  60\n\nZ <- block_ra(blocks = blocks, m = 20)\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  30  20\n     B  80  20\n     C 180  20\n\nZ <- block_ra(blocks = blocks, block_m = c(20, 30, 40))\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  30  20\n     B  70  30\n     C 160  40\n\nZ <- block_ra(blocks = blocks, \n              m_unit = rep(c(20, 30, 40),\n                           times = c(50, 100, 200)))\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  30  20\n     B  70  30\n     C 160  40\n\nblock_m_each <- rbind(c(25, 25),\n                 c(50, 50),\n                 c(100, 100))\n\nZ <- block_ra(blocks = blocks, block_m_each = block_m_each)\ntable(blocks, Z)\n\n      Z\nblocks   0   1\n     A  25  25\n     B  50  50\n     C 100 100\n\nblock_m_each <- rbind(c(10, 40),\n                 c(30, 70),\n                 c(50, 150))\n\nZ <- block_ra(blocks = blocks, block_m_each = block_m_each,\n              conditions = c(\"control\", \"treatment\"))\ntable(blocks, Z)\n\n      Z\nblocks control treatment\n     A      10        40\n     B      30        70\n     C      50       150\n\n# Multi-arm Designs\nZ <- block_ra(blocks = blocks, num_arms = 3)\ntable(blocks, Z)\n\n      Z\nblocks T1 T2 T3\n     A 17 16 17\n     B 33 34 33\n     C 67 67 66\n\nblock_m_each <- rbind(c(10, 20, 20),\n                 c(30, 50, 20),\n                 c(50, 75, 75))\nZ <- block_ra(blocks = blocks, block_m_each = block_m_each)\ntable(blocks, Z)\n\n      Z\nblocks T1 T2 T3\n     A 10 20 20\n     B 30 50 20\n     C 50 75 75\n\nZ <- block_ra(blocks = blocks, block_m_each = block_m_each,\n              conditions = c(\"control\", \"placebo\", \"treatment\"))\ntable(blocks, Z)\n\n      Z\nblocks control placebo treatment\n     A      10      20        20\n     B      30      50        20\n     C      50      75        75\n\nZ <- block_ra(blocks = blocks, prob_each = c(.1, .1, .8))\ntable(blocks, Z)\n\n      Z\nblocks  T1  T2  T3\n     A   5   5  40\n     B  10  10  80\n     C  20  20 160"
  },
  {
    "objectID": "randomizr/reference/strata_rs.html#description",
    "href": "randomizr/reference/strata_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nstrata_rs implements a random sampling procedure in which units that are grouped into strata defined by covariates are sample using complete random sampling within stratum For example, imagine that 50 of 100 men are sampled and 75 of 200 women are sampled."
  },
  {
    "objectID": "randomizr/reference/strata_rs.html#usage",
    "href": "randomizr/reference/strata_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nstrata_rs(\n  strata = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  n = NULL,\n  n_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/strata_rs.html#arguments",
    "href": "randomizr/reference/strata_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to. Can be a character, factor, or numeric vector. (required)\n\n\nprob\nUse for a design in which either floor(N_stratumprob) or ceiling(N_stratumprob) units are sampled within each stratum. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_stratumprob) units will be sampled and with probability prob, ceiling(N_stratumprob) units will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. tapply(prob_unit, strata, unique) will be passed to strata_prob.\n\n\nn\nUse for a design in which the scalar n describes the fixed number of units to sample in each stratum. This number does not vary across strata.\n\n\nn_unit\nMust be of length N. tapply(m_unit, strata, unique) will be passed to strata_n.\n\n\nstrata_n\nUse for a design in which the numeric vector strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/strata_rs.html#value",
    "href": "randomizr/reference/strata_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA numeric vector of length N that indicates if a unit is sampled (1) or not (0)."
  },
  {
    "objectID": "randomizr/reference/strata_rs.html#examples",
    "href": "randomizr/reference/strata_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n\nstrata <- rep(c(\"A\", \"B\",\"C\"), times = c(50, 100, 200))\nZ <- strata_rs(strata = strata)\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  25  25\n     B  50  50\n     C 100 100\n\nZ <- strata_rs(strata = strata, prob = .3)\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  35  15\n     B  70  30\n     C 140  60\n\nZ <- strata_rs(strata = strata, n = 20)\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  30  20\n     B  80  20\n     C 180  20\n\nZ <- strata_rs(strata = strata, strata_prob = c(.1, .2, .3))\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  45   5\n     B  80  20\n     C 140  60\n\nZ <- strata_rs(strata = strata, \n               prob_unit = rep(c(.1, .2, .3), times = c(50, 100, 200)))\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  45   5\n     B  80  20\n     C 140  60\n\nZ <- strata_rs(strata = strata, strata_n = c(20, 30, 40))\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  30  20\n     B  70  30\n     C 160  40\n\nZ <- strata_rs(strata = strata, \n               n_unit = rep(c(20, 30, 40), times = c(50, 100, 200)))\ntable(strata, Z)\n\n      Z\nstrata   0   1\n     A  30  20\n     B  70  30\n     C 160  40"
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs.html#description",
    "href": "randomizr/reference/strata_and_cluster_rs.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nA random sampling procedure in which units are sampled as clusters and clusters are nested within strata."
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs.html#usage",
    "href": "randomizr/reference/strata_and_cluster_rs.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nstrata_and_cluster_rs(\n  strata = NULL,\n  clusters = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  n = NULL,\n  n_unit = NULL,\n  strata_n = NULL,\n  strata_prob = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs.html#arguments",
    "href": "randomizr/reference/strata_and_cluster_rs.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nstrata\nA vector of length N that indicates which stratum each unit belongs to.\n\n\nclusters\nA vector of length N that indicates which cluster each unit belongs to.\n\n\nprob\nUse for a design in which either floor(N_clusters_stratumprob) or ceiling(N_clusters_stratumprob) clusters are sampled within each stratum. The probability of being sampled is exactly prob because with probability 1-prob, floor(N_clusters_stratumprob) clusters will be sampled and with probability prob, ceiling(N_clusters_stratumprob) clusters will be sampled. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nMust of be of length N. tapply(prob_unit, blocks, unique) will be passed to strata_prob.\n\n\nn\nUse for a design in which the scalar n describes the fixed number of units to sample in each stratum. This number does not vary across strata.\n\n\nn_unit\nMust be of length N. tapply(m_unit, blocks, unique) will be passed to strata_n.\n\n\nstrata_n\nUse for a design in which strata_n describes the number of units to sample within each stratum.\n\n\nstrata_prob\nUse for a design in which strata_prob describes the probability of being sampled within each stratum. Differs from prob in that the probability of being sampled can vary across strata.\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs.html#value",
    "href": "randomizr/reference/strata_and_cluster_rs.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA numeric vector of length N that indicates if a unit is sampled (1) or not (0)."
  },
  {
    "objectID": "randomizr/reference/strata_and_cluster_rs.html#examples",
    "href": "randomizr/reference/strata_and_cluster_rs.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\nclusters <- rep(letters, times = 1:26)\n\nstrata <- rep(NA, length(clusters))\nstrata[clusters %in% letters[1:5]] <- \"stratum_1\"\nstrata[clusters %in% letters[6:10]] <- \"stratum_2\"\nstrata[clusters %in% letters[11:15]] <- \"stratum_3\"\nstrata[clusters %in% letters[16:20]] <- \"stratum_4\"\nstrata[clusters %in% letters[21:26]] <- \"stratum_5\"\n\ntable(strata, clusters)\n\n           clusters\nstrata       a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v\n  stratum_1  1  2  3  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_2  0  0  0  0  0  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0\n  stratum_3  0  0  0  0  0  0  0  0  0  0 11 12 13 14 15  0  0  0  0  0  0  0\n  stratum_4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 17 18 19 20  0  0\n  stratum_5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21 22\n           clusters\nstrata       w  x  y  z\n  stratum_1  0  0  0  0\n  stratum_2  0  0  0  0\n  stratum_3  0  0  0  0\n  stratum_4  0  0  0  0\n  stratum_5 23 24 25 26\n\nS <- strata_and_cluster_rs(strata = strata,\n                          clusters = clusters)\n\ntable(S, strata)\n\n   strata\nS   stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0         3        13        27        51        75\n  1        12        27        38        39        66\n\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  1  2  0  0  0  6  7  0  0  0  0  0 13 14  0 16 17 18  0  0  0  0  0 24 25\n  1  0  0  3  4  5  0  0  8  9 10 11 12  0  0 15  0  0  0 19 20 21 22 23  0  0\n   clusters\nS    z\n  0 26\n  1  0\n\nS <- strata_and_cluster_rs(clusters = clusters,\n                           strata = strata,\n                           prob = .5)\n\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  0  3  4  0  0  0  8  9  0  0  0  0 14 15  0  0 18 19 20  0 22  0  0 25\n  1  1  2  0  0  5  6  7  0  0 10 11 12 13  0  0 16 17  0  0  0 21  0 23 24  0\n   clusters\nS    z\n  0 26\n  1  0\n\ntable(S, strata)\n\n   strata\nS   stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0         7        17        29        57        73\n  1         8        23        36        33        68\n\nS <- strata_and_cluster_rs(clusters = clusters,\n                           strata = strata,\n                           strata_n = c(2, 3, 2, 3, 2))\n\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  0  2  0  4  5  0  0  0  9 10 11 12 13  0  0 16  0  0 19  0 21  0 23 24 25\n  1  1  0  3  0  0  6  7  8  0  0  0  0  0 14 15  0 17 18  0 20  0 22  0  0  0\n   clusters\nS    z\n  0  0\n  1 26\n\ntable(S, strata)\n\n   strata\nS   stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0        11        19        36        35        93\n  1         4        21        29        55        48\n\nS <- strata_and_cluster_rs(clusters = clusters,\n                           strata = strata,\n                           strata_prob = c(.1, .2, .3, .4, .5))\n\ntable(S, clusters)\n\n   clusters\nS    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y\n  0  1  0  3  4  5  6  7  0  9 10 11  0 13 14  0 16 17  0  0 20  0 22  0  0 25\n  1  0  2  0  0  0  0  0  8  0  0  0 12  0  0 15  0  0 18 19  0 21  0 23 24  0\n   clusters\nS    z\n  0 26\n  1  0\n\ntable(S, strata)\n\n   strata\nS   stratum_1 stratum_2 stratum_3 stratum_4 stratum_5\n  0        13        32        38        53        73\n  1         2         8        27        37        68"
  },
  {
    "objectID": "randomizr/reference/custom_ra.html#description",
    "href": "randomizr/reference/custom_ra.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nTODO"
  },
  {
    "objectID": "randomizr/reference/custom_ra.html#usage",
    "href": "randomizr/reference/custom_ra.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncustom_ra(permutation_matrix)"
  },
  {
    "objectID": "randomizr/reference/custom_ra.html#arguments",
    "href": "randomizr/reference/custom_ra.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\npermutation_matrix\nA permutation matrix"
  },
  {
    "objectID": "randomizr/reference/custom_ra.html#value",
    "href": "randomizr/reference/custom_ra.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of length N that indicates the treatment condition of each unit. Is numeric in a two-arm trial and a factor variable (ordered by conditions) in a multi-arm trial."
  },
  {
    "objectID": "randomizr/reference/custom_ra.html#examples",
    "href": "randomizr/reference/custom_ra.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# TODO"
  },
  {
    "objectID": "randomizr/reference/complete_ra_probabilities.html#description",
    "href": "randomizr/reference/complete_ra_probabilities.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nprobabilities of assignment: Complete Random Assignment"
  },
  {
    "objectID": "randomizr/reference/complete_ra_probabilities.html#usage",
    "href": "randomizr/reference/complete_ra_probabilities.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncomplete_ra_probabilities(\n  N,\n  m = NULL,\n  m_unit = NULL,\n  m_each = NULL,\n  prob = NULL,\n  prob_unit = NULL,\n  prob_each = NULL,\n  num_arms = NULL,\n  conditions = NULL,\n  check_inputs = TRUE\n)"
  },
  {
    "objectID": "randomizr/reference/complete_ra_probabilities.html#arguments",
    "href": "randomizr/reference/complete_ra_probabilities.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nN\nThe number of units. N must be a positive integer. (required)\n\n\nm\nUse for a two-arm design in which m units are assigned to treatment and N-m units are assigned to control. (optional)\n\n\nm_unit\nUse for a two-arm design in which exactly unique(m_unit) units are assigned to treatment and the remainder are assigned to control. m_unit must be of length N and must be the same for all units (optional)\n\n\nm_each\nUse for a multi-arm design in which the values of m_each determine the number of units assigned to each condition. m_each must be a numeric vector in which each entry is a nonnegative integer that describes how many units should be assigned to the 1st, 2nd, 3rd… treatment condition. m_each must sum to N. (optional)\n\n\nprob\nUse for a two-arm design in which either floor(Nprob) or ceiling(Nprob) units are assigned to treatment. The probability of assignment to treatment is exactly prob because with probability 1-prob, floor(Nprob) units will be assigned to treatment and with probability prob, ceiling(Nprob) units will be assigned to treatment. prob must be a real number between 0 and 1 inclusive. (optional)\n\n\nprob_unit\nUse for a two-arm design. unique(prob_unit) will be passed to the prob argument and must be the same for all units.\n\n\nprob_each\nUse for a multi-arm design in which the values of prob_each determine the probabilities of assignment to each treatment condition. prob_each must be a numeric vector giving the probability of assignment to each condition. All entries must be nonnegative real numbers between 0 and 1 inclusive and the total must sum to 1. Because of integer issues, the exact number of units assigned to each condition may differ (slightly) from assignment to assignment, but the overall probability of assignment is exactly prob_each. (optional)\n\n\nnum_arms\nThe number of treatment arms. If unspecified, num_arms will be determined from the other arguments. (optional)\n\n\nconditions\nA character vector giving the names of the treatment groups. If unspecified, the treatment groups will be named 0 (for control) and 1 (for treatment) in a two-arm trial and T1, T2, T3, in a multi-arm trial. An exception is a two-group design in which num_arms is set to 2, in which case the condition names are T1 and T2, as in a multi-arm trial with two arms. (optional)\n\n\ncheck_inputs\nlogical. Defaults to TRUE."
  },
  {
    "objectID": "randomizr/reference/complete_ra_probabilities.html#value",
    "href": "randomizr/reference/complete_ra_probabilities.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA matrix of probabilities of assignment"
  },
  {
    "objectID": "randomizr/reference/complete_ra_probabilities.html#examples",
    "href": "randomizr/reference/complete_ra_probabilities.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(randomizr)\n\n# 2-arm designs\nprob_mat <- complete_ra_probabilities(N=100)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- complete_ra_probabilities(N=100, m=50)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.5    0.5\n[2,]    0.5    0.5\n[3,]    0.5    0.5\n[4,]    0.5    0.5\n[5,]    0.5    0.5\n[6,]    0.5    0.5\n\nprob_mat <- complete_ra_probabilities(N=100, prob = .3)\nhead(prob_mat)\n\n     prob_0 prob_1\n[1,]    0.7    0.3\n[2,]    0.7    0.3\n[3,]    0.7    0.3\n[4,]    0.7    0.3\n[5,]    0.7    0.3\n[6,]    0.7    0.3\n\nprob_mat <- complete_ra_probabilities(N=100, m_each = c(30, 70),\n                          conditions = c(\"control\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_treatment\n[1,]          0.3            0.7\n[2,]          0.3            0.7\n[3,]          0.3            0.7\n[4,]          0.3            0.7\n[5,]          0.3            0.7\n[6,]          0.3            0.7\n\n# Multi-arm Designs\nprob_mat <- complete_ra_probabilities(N=100, num_arms=3)\nhead(prob_mat)\n\n       prob_T1   prob_T2   prob_T3\n[1,] 0.3333333 0.3333333 0.3333333\n[2,] 0.3333333 0.3333333 0.3333333\n[3,] 0.3333333 0.3333333 0.3333333\n[4,] 0.3333333 0.3333333 0.3333333\n[5,] 0.3333333 0.3333333 0.3333333\n[6,] 0.3333333 0.3333333 0.3333333\n\nprob_mat <- complete_ra_probabilities(N=100, m_each=c(30, 30, 40))\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.3     0.3     0.4\n[2,]     0.3     0.3     0.4\n[3,]     0.3     0.3     0.4\n[4,]     0.3     0.3     0.4\n[5,]     0.3     0.3     0.4\n[6,]     0.3     0.3     0.4\n\nprob_mat <- complete_ra_probabilities(N=100, m_each=c(30, 30, 40),\n                          conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]          0.3          0.3            0.4\n[2,]          0.3          0.3            0.4\n[3,]          0.3          0.3            0.4\n[4,]          0.3          0.3            0.4\n[5,]          0.3          0.3            0.4\n[6,]          0.3          0.3            0.4\n\nprob_mat <- complete_ra_probabilities(N=100, conditions=c(\"control\", \"placebo\", \"treatment\"))\nhead(prob_mat)\n\n     prob_control prob_placebo prob_treatment\n[1,]    0.3333333    0.3333333      0.3333333\n[2,]    0.3333333    0.3333333      0.3333333\n[3,]    0.3333333    0.3333333      0.3333333\n[4,]    0.3333333    0.3333333      0.3333333\n[5,]    0.3333333    0.3333333      0.3333333\n[6,]    0.3333333    0.3333333      0.3333333\n\nprob_mat <- complete_ra_probabilities(N=100, prob_each = c(.2, .7, .1))\nhead(prob_mat)\n\n     prob_T1 prob_T2 prob_T3\n[1,]     0.2     0.7     0.1\n[2,]     0.2     0.7     0.1\n[3,]     0.2     0.7     0.1\n[4,]     0.2     0.7     0.1\n[5,]     0.2     0.7     0.1\n[6,]     0.2     0.7     0.1"
  },
  {
    "objectID": "DeclareDesign/news.html",
    "href": "DeclareDesign/news.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "DeclareDesign 1.0.0\n\nAllow diagnoses to group by outcomes.\nSimplify print(design).\nLaunch version 1.\n\n\n\nDeclareDesign 0.30.0\n\nNew tidy(diagnosis) function to construct a tidy data frame of diagnosand estimates and summary statistics including bootstrapped standard error and confidence intervals.\nRemove draw_assignment and draw_sample function.\nAdded diagnosis duration to summary function.\nBug fixes.\n\n\n\nDeclareDesign 0.28.0\n\nTo simplify output of diagnoses, we changed the names of the variables from design_label to design, inquiry_label to inquiry, and estimator_label to estimator.\ndeclare_assignment() and declare_sampling() have the default values for legacy set to FALSE. You can still use the legacy versions of these functions by manually setting legacy = TRUE for some time, but this functionality will later be removed.\n\n\n\nDeclareDesign 0.26.0\n\nRapid development phase is beginning to prepare for DeclareDesign 1.0.\nAdd new step declare_model for defining the model of the world including sample size, levels of the data, and variables.\nAdd new step declare_inquiry to replace declare_estimand. declare_estimand is still available but deprecated.\nSoft-introduce new syntax for declare_assignment and declare_sampling. Old syntax is still available with legacy = TRUE, the current default. To use the new syntax, set legacy = FALSE. In future versions of DeclareDesign, the default will be set to FALSE.\nreveal_outcomes, created in 0.24.0, has been removed as a step.\nChange labels produced in diagnoses and run_design output to be inquiry_label rather than estimand_label.\nAllow estimands to be functions of other estimands.\n\n\n\nDeclareDesign 0.24.0\n\nAdd new step declare_measurement for measuring outcome variables.\nAdd declare_test to enable hypothesis testing where no estimand is targeted. For example, declare_test could be used for a K-S test of distributional equality and declare_estimator for a difference-in-means estimate of an average treatment effect.\nAdd model_summary option to declare_estimator, to enable specifying a model and then a separate post-estimation function to extract coefficient estimates (e.g., estimate of a treatment effect) or model summary statistics (e.g., R^2 or the result of an F-test from a regression).\nSimplify declare_diagnosands functionality. diagnose_design() by default runs an internal function with a set of default diagnosands, including power, RMSE, bias, type S rate, coverage, mean estimate, and mean estimand.\nImprove compatibility with dplyr verbs as handlers. filter now works.\nRename declare_reveal to reveal_outcomes. Both continue to work.\n\n\n\nDeclareDesign 0.22.0\n\nFix ability to set sampling_variable in declare_sampling.\nAdd ability to retain nonsampled data after sampling via drop_nonsampled flag in declare_sampling.\n\n\n\nDeclareDesign 0.20.0\n\nAdd compare_diagnoses function to compare two designs on the basis of their design diagnoses.\nCompatibility with rlang 0.4.0\nBug fixes\n\n\n\nDeclareDesign 0.18.0\n\nAdd compare_designs functions to compare the code and output of designs side-by-side.\nBug fixes\n\n\n\nDeclareDesign 0.16.0\n\nAdd draw_assignment function to draw an assignment vector(s) given data\nAdd draw_sample function to draw a sample or multiple sequential samples from data\nRewrite draw_data to optionally take a data argument. draw_data now can be used to draw data for the full design, or for subsets of it. start and end flags are added to select which portions of the design to run\nBug fixes\n\n\n\nDeclareDesign 0.14.0\n\nImproved generics interoperability\nBug fixes\n\n\n\nDeclareDesign 0.12.0\n\nAdd ability to use get_estimates with data, useful for example for getting estimates after data is collected for a study. To draw estimates or estimands from simulated data, now use renamed draw_estimates and draw_estimands functions.\nDocumentation improvements\nBug fixes\n\n\n\nDeclareDesign 0.10.0\n\nFirst CRAN version"
  },
  {
    "objectID": "DeclareDesign/articles/custom_functions.html",
    "href": "DeclareDesign/articles/custom_functions.html",
    "title": "Custom functions and DeclareDesign",
    "section": "",
    "text": "The declare_* functions in DeclareDesign use functions in the fabricatr, randomizr, and estimatr packages as defaults, which work great for most designs. Sometimes, however, you might want to write your own function. This advanced vignette declares a design using only custom functions.\nFirst, we’ll write custom functions for each of the steps in the design. All functions must take a data.frame and return a data.frame, with the exception of a population step, whose inputs can be anything but whose output must be a data.frame.\n\n# M: Model\ncustom_population <- function(N) {\n  data.frame(u = rnorm(N))\n}\ncustom_potential_outcomes <-\n  function(data) {\n    within(data,{\n      Y_Z_0 <- u\n      Y_Z_1 <- 0.25 + u\n    })\n  }\n\n# I: Inquiry\ncustom_inquiry <- function(data, label) {\n  data.frame(inquiry = label,\n  inquiry = with(data, median(Y_Z_1 - Y_Z_0)))\n}\n\n# D: Data Strategy\ncustom_sampling <- function(data) {\n     data$S <- rbinom(n = nrow(data),\n            size = 1,\n            prob = 0.1)\n     data[data$S == 1, ]\n}\n\ncustom_assignment <- function(data) {\n  data$Z <- rbinom(n = nrow(data),\n         size = 1,\n         prob = 0.5)\n  data\n}\n\ncustom_reveal <- function(data){\n  within(data, Y <- Y_Z_1 * Z + Y_Z_0 * (1 - Z))\n}\n\n# A: Answer strategy\ncustom_estimator <- function(data){\n  data.frame(estimate = with(data, mean(Y)))\n}\n\nIn order to declare the design, we pass each of the custom functions to the handler argument of each declaration step:\n\ndesign <- \n  declare_model(handler = custom_population, N = 100) + \n  declare_potential_outcomes(handler = custom_potential_outcomes) + \n  declare_inquiry(handler = custom_inquiry, label = \"medianTE\") + \n  declare_sampling(handler = custom_sampling) + \n  declare_assignment(handler = custom_assignment) + \n  declare_reveal(handler = custom_reveal) + \n  declare_estimator(handler = tidy_estimator(custom_estimator), \n                    inquiry = \"medianTE\")\n\nWarning in tidy_estimator(custom_estimator): tidy_estimator() has been\ndeprecated. Please use label_estimator() instead.\n\nhead(draw_data(design))\n\n      u Y_Z_1 Y_Z_0 S Z    Y\n7  1.51  1.76  1.51 1 0 1.51\n24 1.21  1.46  1.21 1 0 1.21\n35 0.50  0.75  0.50 1 0 0.50\n50 0.66  0.91  0.66 1 0 0.66\n64 1.40  1.65  1.40 1 1 1.65\n69 0.92  1.17  0.92 1 1 1.17\n\nrun_design(design)\n\n   inquiry inquiry.1 estimator estimate\n1 medianTE      0.25 estimator    -0.36\n\n\nThis example used very simple custom functions, but this framework is flexible enough to accommodate any design step that can be expressed as a function of data that returns data."
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html",
    "href": "DeclareDesign/articles/declaredesign_101.html",
    "title": "DeclareDesign 101",
    "section": "",
    "text": "This vignette serves as a brief introduction to the DeclareDesign package for R. DeclareDesign is a software implementation of every step of the design-diagnose-redesign process. While you can of course declare, diagnose, and redesign your design using nearly any programming language, DeclareDesign is structured to make it easy to mix-and-match design elements while handling the tedious simulation bookkeeping behind the scenes."
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#installing-r",
    "href": "DeclareDesign/articles/declaredesign_101.html#installing-r",
    "title": "DeclareDesign 101",
    "section": "Installing R",
    "text": "Installing R\nYou can download the statistical computing environment R for free from CRAN. We also recommend the free program RStudio, which provides a friendly interface to R. Both R and RStudio are available on Windows, Mac, and Linux.\nOnce you have R and RStudio installed, open it up and install DeclareDesign and its related packages. These include three packages that enable specific steps in the research process (fabricatr for simulating social science data; randomizr for random sampling and random assignment; and estimatr for design-based estimators). You can also install DesignLibrary, which gets standard designs up-and-running in one line. To install them, copy the following code into your R console:\n\ninstall.packages(c(\n  \"DeclareDesign\",\n  \"fabricatr\",\n  \"randomizr\",\n  \"estimatr\",\n  \"DesignLibrary\"\n))\n\nWe also recommend that you install and get to know the tidyverse suite of packages for data analysis, which we will use throughout the book:\n\ninstall.packages(\"tidyverse\")\n\nFor introductions to R and the tidyverse we especially recommend the free resource R for Data Science."
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#building-a-step-of-a-research-design",
    "href": "DeclareDesign/articles/declaredesign_101.html#building-a-step-of-a-research-design",
    "title": "DeclareDesign 101",
    "section": "Building a step of a research design",
    "text": "Building a step of a research design\nA research design is a concatenation of design steps. The best way to learn how to build a design is to learn how to make a step. We will start out by making—or declaring—a step that implements random assignment.\nAlmost all steps take a dataset as input and return a dataset as output. We will imagine input data that describes a set of voters in Los Angeles. The research project we are planning involves randomly assigning voters to receive (or not receive) a knock on their door from a canvasser. Our data look like this:\n\n\n\n\n\n\n\nExample data\n \n  \n    ID \n    age \n    sex \n    party \n    precinct \n  \n \n\n  \n    001 \n    66 \n    M \n    REP \n    9104 \n  \n  \n    002 \n    54 \n    F \n    DEM \n    8029 \n  \n  \n    003 \n    18 \n    M \n    GRN \n    8383 \n  \n  \n    004 \n    42 \n    F \n    DEM \n    2048 \n  \n  \n    005 \n    27 \n    M \n    REP \n    5210 \n  \n\n\n\n\n\nThere are 100 voters in the dataset.\nWe want a function that takes this dataset, implements a random assignment, adds it to the dataset, and then returns the new dataset containing the random assignment.\nYou could write your own function to do that but you can also use one of the declare_* functions in DeclareDesign that are designed to write functions. Each one of these functions is a kind of function factory: it takes a set of parameters about your research design like the number of units and the random assignment probability as inputs, and returns a function as an output. Here is an example of a declare_assignment step.\n\nsimple_random_assignment_step <- \n  declare_assignment(Z = complete_ra(N, prob = 0.6),\n                     Z_cond_prob = obtain_condition_probabilities(Z, declaration = declare_ra(N, prob = 0.6)))\n\nThe big idea here is that the object we created, simple_random_assignment_step, is not a particular assignment, it is a function that conducts assignment when called. You can run the function on data:\n\nsimple_random_assignment_step(voter_file) \n\n\n\n\n\nData output following implementation of an assignment step.\n \n  \n    ID \n    age \n    sex \n    party \n    precinct \n    Z \n    Z_cond_prob \n  \n \n\n  \n    001 \n    66 \n    M \n    REP \n    9104 \n    0 \n    0.4 \n  \n  \n    002 \n    54 \n    F \n    DEM \n    8029 \n    0 \n    0.4 \n  \n  \n    003 \n    18 \n    M \n    GRN \n    8383 \n    1 \n    0.6 \n  \n  \n    004 \n    42 \n    F \n    DEM \n    2048 \n    0 \n    0.4 \n  \n  \n    005 \n    27 \n    M \n    REP \n    5210 \n    0 \n    0.4 \n  \n\n\n\n\n\nThe output of the simple_random_assignment_step(voter_file) call is the original dataset with a new column indicating treatment assignment (Z) appended. As a bonus, the data also includes the probability that each unit is assigned to the condition in which it is in (Z_cond), which is an extremely useful number to know in many analysis settings. The most important thing to understand here is that steps are “dataset-in, dataset-out” functions. The simple_random_assignment_step took the voter_file dataset and returned a dataset with assignment information appended.\nEvery step of a research design declaration can be written using one of the declare_* functions. This table collects these according to the four elements of a research design. Below, we walk through the common uses of each of these declaration functions.\n\n\n\n\n\n\n\n\nDesign component\nFunction\nDescription\n\n\n\n\nModel\ndeclare_model()\ndefine background causal model\n\n\nInquiry\ndeclare_inquiry()\ndefine research question\n\n\nData strategy\ndeclare_sampling()\nspecify sampling procedures\n\n\n\ndeclare_assignment()\nspecify assignment procedures\n\n\n\ndeclare_measurement()\nspecify measurement procedures\n\n\nAnswer strategy\ndeclare_estimator()\nspecify data summary procedures\n\n\n\ndeclare_test()\nspecify testing procedures\n\n\n\n\nOptions and defaults\nEach of the declare_* functions has many options. In general, you do not have to specify these as default values are usually provided. For instance, you might have noticed above that when you ran the assignment step above, the new variable that was created was called Z. This is because declare_assignment has an argument assignment_variable that defaults to Z. You can change that of course to whatever you want.\nMore subtly, the declare_* functions also default to “handlers” which have their own default arguments. These handlers are generally well-developed sets of functions that implement the tasks needed by the declare_ function. For instance, assignment_handler defaults to the conduct_ra function from the randomizr package. The declaration passes any additional arguments that you give it on to conduct_ra, and, by the same token, assumes the default values of the handler. In the example above, we had prob = 0.6 as an argument. If you look at the documentation, prob is not an argument of declare_assignment but it is an argument of conduct_ra, with a default value of 0.5. If we had left this bit out we would have gotten a function that assigned treatment with probability 0.5. As with any software, learning these defaults will take some time and can be looked up in the help files, e.g. ?declare_assignment.\n\n\nYour own handlers\nThe built-in functions we provide in the DeclareDesign package are quite flexible and handle many major designs, but not all. The framework is built so that you are never constrained by what we provide. At any point, rather than using the default handlers (such as conduct_ra), you can write a function that implements your own procedures. The only discipline that the framework imposes is that you write your procedure as a function that takes data in and sends data back.\nHere is an example of how you turn your own functions into design steps.\n\ncustom_assignment <- function(data) {\n  mutate(data, Z = rbinom(n = nrow(data), 1, prob = 0.5))\n}\n\nmy_assignment_step <- declare_assignment(handler = custom_assignment)\n\nmy_assignment_step(voter_file)  \n\n\n\n\n\nData generated using a custom function\n \n  \n    ID \n    age \n    sex \n    party \n    precinct \n    Z \n  \n \n\n  \n    001 \n    66 \n    M \n    REP \n    9104 \n    0 \n  \n  \n    002 \n    54 \n    F \n    DEM \n    8029 \n    1 \n  \n  \n    003 \n    18 \n    M \n    GRN \n    8383 \n    1 \n  \n  \n    004 \n    42 \n    F \n    DEM \n    2048 \n    0 \n  \n  \n    005 \n    27 \n    M \n    REP \n    5210 \n    1"
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#research-design-steps",
    "href": "DeclareDesign/articles/declaredesign_101.html#research-design-steps",
    "title": "DeclareDesign 101",
    "section": "Research design steps",
    "text": "Research design steps\nIn this section, we walk through how to declare each step of a research design using DeclareDesign. In the next section, we build those steps into a research design, and then describe how to interrogate the design.\n\nModel\nThe model defines the structure of the world, both its size and background characteristics as well as how interventions in the world determine outcomes.\nThe model defines the number of units in the population, any multilevel structure to the data, and its background characteristics. We can define the population in several ways. In some cases, you may start a design with data on the population. When that happens, we do not need to simulate it. We can simply declare the data as our population:\n\ndeclare_model(data = voter_file)\n\n\n\n\n\nDraw from a fixed population\n \n  \n    ID \n    age \n    sex \n    party \n    precinct \n  \n \n\n  \n    001 \n    66 \n    M \n    REP \n    9104 \n  \n  \n    002 \n    54 \n    F \n    DEM \n    8029 \n  \n  \n    003 \n    18 \n    M \n    GRN \n    8383 \n  \n  \n    004 \n    42 \n    F \n    DEM \n    2048 \n  \n  \n    005 \n    27 \n    M \n    REP \n    5210 \n  \n\n\n\n\n\nWhen we do not have complete data on the population, we simulate it. Relying on the data simulation functions from our fabricatr package, declare_model asks about the size and variables of the population. For instance, if we want a function that generates a dataset with 100 units and a random variable U we write:\n\ndeclare_model(N = 100, U = rnorm(N))\n\nWhen we run this population function, we will get a different 100-unit dataset each time, as shown here.\n\n\n\n\nFive draws from the population.\n \n\nDraw 1\nDraw 2\nDraw 3\nDraw 4\nDraw 5\n\n  \n    ID \n    U \n    ID \n    U \n    ID \n    U \n    ID \n    U \n    ID \n    U \n  \n \n\n  \n    001 \n    -0.32 \n    001 \n    0.19 \n    001 \n    -1.280 \n    001 \n    -0.38 \n    001 \n    0.744 \n  \n  \n    002 \n    1.17 \n    002 \n    0.69 \n    002 \n    1.880 \n    002 \n    -0.35 \n    002 \n    2.445 \n  \n  \n    003 \n    1.70 \n    003 \n    0.82 \n    003 \n    0.597 \n    003 \n    -0.64 \n    003 \n    0.043 \n  \n  \n    004 \n    0.93 \n    004 \n    -0.98 \n    004 \n    -1.963 \n    004 \n    0.40 \n    004 \n    0.159 \n  \n  \n    005 \n    -1.15 \n    005 \n    -1.29 \n    005 \n    0.084 \n    005 \n    0.34 \n    005 \n    1.686 \n  \n\n\n\n\n\nThe fabricatr package can simulate many different types of data, including various types of categorical variables or different types of data structures, such as panel or multilevel structures. You can read the fabricatr website vignette to get started simulating data.\nAs an example of a two-level hierarchical data structure, here is a declaration for 100 households with a random number of individuals within each household. This two-level structure could be declared as:\n\ndeclare_model(\n  households = add_level(\n    N = 100,\n    individuals_per_hh = sample(1:6, N, replace = TRUE)\n  ),\n  individuals = add_level(\n    N = individuals_per_hh, \n    age = sample(1:100, N, replace = TRUE)\n  )\n)\n\nAs always, you can exit our built-in way of doing things and bring in your own code. This is useful for complex designs, or when you have already written code for your design and you want to use it directly. Here is an example of a custom population declaration:\n\ncomplex_model_function <- function(data, N_units) {\n  data.frame(U = rnorm(N_units))\n}\n\ndeclare_model(\n  handler = complex_model_function, N_units = 100\n)\n\n\nPotential outcomes\nDefining potential outcomes is as easy as a single expression per potential outcome. Potential outcomes may depend on background characteristics, other potential outcomes, or other R functions.\n\ndeclare_model(\n  Y_Z_0 = U, \n  Y_Z_1 = Y_Z_0 + 0.25)\n\n\ndesign <- \n  declare_model(\n    N = 100,\n    U = rnorm(N),\n    potential_outcomes(Y ~ 0.25 * Z + U)\n  ) + NULL\n\ndraw_data(design)\n\n\n\n\n\nAdding potential outcomes to the population.\n \n  \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n  \n \n\n  \n    001 \n    1.53 \n    1.53 \n    1.782 \n  \n  \n    002 \n    0.92 \n    0.92 \n    1.172 \n  \n  \n    003 \n    -1.19 \n    -1.19 \n    -0.937 \n  \n  \n    004 \n    -0.20 \n    -0.20 \n    0.046 \n  \n  \n    005 \n    -1.06 \n    -1.06 \n    -0.809 \n  \n\n\n\n\n\nThe potential_outcomes formula syntax lets you specify “regression-like” outcome equations. One downside is that it mildly obscures how the names of the eventual potential outcomes columns are named. We build the names of the potential outcomes columns the outcome name (here Y on the left-hand side of the formula) and from the assignment_variables argument (here Z).\n\ndeclare_model(N = 100, potential_outcomes(Y ~ 0.25 * Z + U, assignment_variables = Z))\n\nEither way of creating potential outcomes works; one may be easier or harder to code up in a given research design setting.\n\n\n\nInquiry\nTo define your inquiry, declare your estimand. Estimands are typically summaries of the data produced in declare_model. Here we define the average treatment effect as follows:\n\ndeclare_inquiry(PATE = mean(Y_Z_1 - Y_Z_0))\n\nNotice that we defined the PATE (the population average treatment effect), but said nothing special related to the population – it looks like we just defined the average treatment effect. This is because order matters. If we want to define a SATE (the sample average treatment effect), we would have to do so after sampling has occurred. We will see how to do this in a moment.\n\n\nData strategy\nThe data strategy constitutes one or more steps representing interventions the researcher makes in the world from sampling to assignment to measurement.\n\nSampling\nThe sampling step relies on the randomizr package to conduct random sampling. Here we define a procedure for drawing a 50-unit sample from the population:\n\ndeclare_sampling(S = complete_rs(N, n = 50))\n\nWhen we draw data from our simple design at this point, it will have fewer rows: it will have shrunk from 100 units in the population to a data frame of 50 units representing the sample. The new data frame also includes a variable indicating the probability of being included in the sample. In this case, every unit in the population had an equal inclusion probability of 0.5.\n\n\n\n\nSampled data.\n \n  \n      \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n    S \n  \n \n\n  \n    5 \n    005 \n    -0.59 \n    -0.59 \n    -0.34 \n    1 \n  \n  \n    7 \n    007 \n    0.86 \n    0.86 \n    1.11 \n    1 \n  \n  \n    9 \n    009 \n    -0.43 \n    -0.43 \n    -0.18 \n    1 \n  \n  \n    10 \n    010 \n    -0.94 \n    -0.94 \n    -0.69 \n    1 \n  \n  \n    12 \n    012 \n    1.00 \n    1.00 \n    1.25 \n    1 \n  \n\n\n\n\n\nSampling could also be non-random, which could be accomplished by using a custom handler.\n\n\nAssignment\nThe default handler for declare_assignment also relies on the randomizr package for random assignment. Here, we define an assignment procedure that allocates subjects to treatment with probability 0.5. One subtlety is that by default, declare_assignment conducts complete random assignment (exactly \\(m\\) of \\(N\\) units assigned to treatment, where \\(m\\) = prob * \\(N\\)).\n\ndeclare_assignment(Z = complete_ra(N, prob = 0.5))\n\nAfter treatments are assigned, some potential outcomes are revealed. Treated units reveal their treated potential outcomes and untreated units reveal their untreated potential outcomes. The reveal_outcomes function performs this switching operation within a declare_measurement call.\n\ndeclare_measurement(Y = reveal_outcomes(Y ~ Z))\n\nAdding these two declarations to the design results in a data frame with an additional indicator Z for the assignment as well as its corresponding probability of assignment. Again, here the assignment probabilities are constant, but in other designs they are not and this is crucial information for the analysis stage. The outcome variable Y is composed of each unit’s potential outcomes depending on its treatment status.\n\n\n\n\nSampled data with assignment indicator.\n \n  \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n    S \n    Z \n    Y \n  \n \n\n  \n    003 \n    0.92 \n    0.92 \n    1.17 \n    1 \n    0 \n    0.92 \n  \n  \n    005 \n    0.69 \n    0.69 \n    0.94 \n    1 \n    1 \n    0.94 \n  \n  \n    006 \n    0.45 \n    0.45 \n    0.70 \n    1 \n    1 \n    0.70 \n  \n  \n    008 \n    0.15 \n    0.15 \n    0.40 \n    1 \n    0 \n    0.15 \n  \n  \n    010 \n    0.80 \n    0.80 \n    1.05 \n    1 \n    1 \n    1.05 \n  \n\n\n\n\n\n\n\nMeasurement\nMeasurement is a critical part of every research design; sometimes it is beneficial to explicitly declare the measurement procedures of the design, rather than allowing them to be implicit in the ways variables are created in declare_model. For example, we might imagine that the normally distributed outcome variable Y is a latent outcome that will be translated into a binary outcome when measured by the researcher:\n\ndeclare_measurement(Y_binary = rbinom(N, 1, prob = pnorm(Y)))\n\n\n\n\n\nSampled data with an explicitly measured outcome.\n \n  \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n    S \n    Z \n    Y \n    Y_binary \n  \n \n\n  \n    004 \n    -1.71 \n    -1.71 \n    -1.46 \n    1 \n    1 \n    -1.46 \n    0 \n  \n  \n    009 \n    1.86 \n    1.86 \n    2.11 \n    1 \n    1 \n    2.11 \n    1 \n  \n  \n    011 \n    0.96 \n    0.96 \n    1.21 \n    1 \n    0 \n    0.96 \n    1 \n  \n  \n    015 \n    -0.21 \n    -0.21 \n    0.04 \n    1 \n    1 \n    0.04 \n    0 \n  \n  \n    016 \n    -1.14 \n    -1.14 \n    -0.89 \n    1 \n    0 \n    -1.14 \n    0 \n  \n\n\n\n\n\n\n\n\nAnswer strategy\nThrough our model and data strategy steps, we have simulated a dataset with two key inputs to the answer strategy: an assignment variable and an outcome. In other answer strategies, pretreatment characteristics from the model might also be relevant. The data look like this:\n\n\n\n\nData with revealed outcomes.\n \n  \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n    S \n    Z \n    Y \n  \n \n\n  \n    001 \n    1.68 \n    1.68 \n    1.93 \n    1 \n    1 \n    1.93 \n  \n  \n    003 \n    -1.28 \n    -1.28 \n    -1.03 \n    1 \n    0 \n    -1.28 \n  \n  \n    004 \n    -0.13 \n    -0.13 \n    0.12 \n    1 \n    1 \n    0.12 \n  \n  \n    005 \n    0.61 \n    0.61 \n    0.86 \n    1 \n    1 \n    0.86 \n  \n  \n    007 \n    -0.71 \n    -0.71 \n    -0.46 \n    1 \n    1 \n    -0.46 \n  \n\n\n\n\n\nOur estimator is the difference-in-means estimator, which compares outcomes between the group that was assigned to treatment and that assigned to control. The difference_in_means() function in the estimatr package calculates the estimate, the standard error, \\(p\\)-value and confidence interval for you:\n\ndifference_in_means(Y ~ Z, data = simple_design_data)\n\n\n\n\n\nDifference-in-means estimate from simulated data.\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n    df \n    outcome \n  \n \n\n  \n    Z \n    0.92 \n    0.29 \n    3.2 \n    0.003 \n    0.34 \n    1.5 \n    40 \n    Y \n  \n\n\n\n\n\nNow, in order to declare our estimator, we can send the name of a modeling function to declare_estimator. R has many modeling functions that work with declare_estimator, including lm, glm, or the ictreg function from the list package, among hundreds of others. Throughout the book, we will be using many estimators from estimatr because they are fast and calculate robust standard errors easily. Estimators are (almost always) associated with estimands.1 Here, we are targeting the population average treatment effect with the difference-in-means estimator.\n\ndeclare_estimator(\n  Y ~ Z, .method = difference_in_means, estimand = \"PATE\"\n)\n\n\nTwo finer points: model_summary and label_estimator\nMany answer strategies use modeling functions like lm, lm_robust, or glm. The output from these modeling functions are typically very complicated list objects that contain large amounts of information about the modeling process. We typically only want a few summary pieces of information out of these model objects, like the coefficient estimates, standard errors, and confidence intervals. We use model summary functions passed to the model_summary argument of declare_estimator to do so. Model summary functions take models as inputs and return data frames as outputs.\nThe default model summary function is tidy:\n\ndeclare_estimator(\n  Y ~ Z, .method = lm_robust, .summary = tidy\n)\n\nYou could also use glance to get model fit statistics like \\(R^2\\).\n\ndeclare_estimator(\n  Y ~ Z, .method = lm_robust, .summary = glance\n)\n\nOccasionally, you’ll need to write your own model summary function that takes a model fit object and returns a data.frame with the information you need. For example, in order to calculate average marginal effects estimates from a logistic regression, we run a glm model through the margins function from the margins package; we then need to “tidy” the output from margins using the tidy function. Here we’re also asking for a 95% confidence interval.\n\ntidy_margins <- function(x) {\n  tidy(margins(x, data = x$data), conf.int = TRUE)\n}\n\ndeclare_estimator(\n  Y ~ Z + X,\n  .method = glm,\n  family = binomial(\"logit\"),\n  .summary = tidy_margins,\n  term = \"Z\"\n) \n\nIf your answer strategy does not use a model function, you’ll need to provide a function that takes data as an input and returns a data.frame with the estimate. Set the handler to be label_estimator(your_function_name) to take advantage of DeclareDesign’s mechanism for matching estimands to estimators. When you use label_estimator, you can provide an estimand, and DeclareDesign will keep track of which estimates match each estimand. For example, to calculate the mean of an outcome, you could write your own estimator in this way:\n\nmy_estimator <- function(data){\n  data.frame(estimate = mean(data$Y))\n}\ndeclare_estimator(handler = label_estimator(my_estimator), label = \"mean\", estimand = \"Y_bar\")\n\ndeclare_estimator(estimand = \"Y_bar\", handler = label_estimator(my_estimator), \n    label = \"mean\")\n\n\n\n\n\nOther design steps\nThe main declare_* functions cover many elements of research designs, but not all. You can include any operations we haven’t explicitly included as steps in your design too, using declare_step. Here, you must define a specific handler. Some handlers that may be useful are the dplyr verbs such as mutate and summarize, and the fabricate function from our fabricatr package.\nTo add a variable using fabricate:\n\ndeclare_step(handler = fabricate, added_variable = rnorm(N))\n\nIf you have district-month data you may want to analyze at the district level, collapsing across months:\n\ncollapse_data <- function(data, collapse_by) {\n  data %>% \n    group_by({{ collapse_by }}) %>% \n    summarize_all(mean, na.rm = TRUE)\n}\n\ndeclare_step(handler = collapse_data, collapse_by = district)\n\n# Note: The `{{ }}` syntax is handy for writing functions in `dplyr` \n# where you want to be able to reuse the function with different variable \n# names. Here, the `collapse_data` function will `group_by` the \n# variable you send to the argument `collapse_by`, which in our \n# declaration we set to `district`. The pipeline within the function \n# then calculates the mean in each district."
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#building-a-design-from-design-steps",
    "href": "DeclareDesign/articles/declaredesign_101.html#building-a-design-from-design-steps",
    "title": "DeclareDesign 101",
    "section": "Building a design from design steps",
    "text": "Building a design from design steps\nIn the last section, we defined a set of individual research steps. We draw one version of them together here:\n\nmodel <- \n  declare_model(\n    N = 100, \n    U = rnorm(N), \n    potential_outcomes(Y ~ 0.25 * Z + U)\n  )\n\ninquiry <- \n  declare_inquiry(PATE = mean(Y_Z_1 - Y_Z_0)) \n\nsampling <- \n  declare_sampling(S = complete_rs(N, n = 50))\n\nassignment <- \n  declare_assignment(Z = complete_ra(N, prob = 0.5))\n\nmeasurement <- \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) \n\nestimator <- \n  declare_estimator(\n    Y ~ Z, .method = difference_in_means, estimand = \"PATE\"\n  )\n\nTo construct a research design object that we can operate on — diagnose it, redesign it, draw data from it, etc. — we add them together with the + operator, just as %>% makes dplyr pipelines or + creates ggplot objects.\n\ndesign <- \n  model + inquiry + sampling + assignment + measurement + estimator\n\nWe will usually declare designs more compactly, concatenating steps directly with +:\n\ndesign <- \n  declare_model(\n    N = 100, \n    U = rnorm(N),\n    potential_outcomes(Y ~ 0.25 * Z + U)\n  ) +\n  declare_inquiry(PATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N, n = 50)) +\n  declare_assignment(Z = complete_ra(N, prob = 0.5)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, .method = difference_in_means, estimand = \"PATE\")\n\n\nOrder matters\nWhen defining a design, the order in which steps are included in the design via the + operator matters. Think of the order of your design as the temporal order in which steps take place. Here, since the estimand comes before sampling and assignment, it is a population estimand, the population average treatment effect.\n\nmodel + inquiry + sampling + assignment + measurement + estimator\n\nWe could define our estimand as a sample average treatment effect by putting inquiry after sampling:\n\nmodel + sampling + inquiry + assignment + measurement + estimator"
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#simulating-a-research-design",
    "href": "DeclareDesign/articles/declaredesign_101.html#simulating-a-research-design",
    "title": "DeclareDesign 101",
    "section": "Simulating a research design",
    "text": "Simulating a research design\nDiagnosing a research design — learning about its properties — requires first simulating running the design over and over. We need to simulate the data generating process, then calculate the estimands, then calculate the resulting estimates.\nWith the design defined as an object, we can learn about what kind of data it generates, the values of its estimand and estimates, and other features. For example, to draw simulated data based on the design, we use draw_data:\n\ndraw_data(design)\n\n\n\n\n\nSimulated data draw.\n \n  \n    ID \n    U \n    Y_Z_0 \n    Y_Z_1 \n    S \n    Z \n    Y \n  \n \n\n  \n    002 \n    0.94 \n    0.94 \n    1.19 \n    1 \n    0 \n    0.94 \n  \n  \n    005 \n    -0.43 \n    -0.43 \n    -0.18 \n    1 \n    0 \n    -0.43 \n  \n  \n    006 \n    -1.13 \n    -1.13 \n    -0.88 \n    1 \n    0 \n    -1.13 \n  \n  \n    007 \n    -2.24 \n    -2.24 \n    -1.99 \n    1 \n    0 \n    -2.24 \n  \n  \n    008 \n    0.52 \n    0.52 \n    0.77 \n    1 \n    0 \n    0.52 \n  \n\n\n\n\n\ndraw_data runs all of the “data steps” in a design, which are both from the model (population and potential outcomes) and from the data strategy (sampling, assignment, and measurement).\nTo simulate the estimands from a single run of the design, we use draw_estimands. This runs two operations at once: it draws the data, and calculates the estimands at the point defined by the design. For example, in our design, the estimand comes just after the potential outcomes. In this design, draw_estimands will run the first two steps and then calculate the estimands from the estimand function we declared:\n\ndraw_estimands(design)\n\n\n\n\n\nEstimands calculated from simulated data.\n \n  \n    inquiry \n    estimand \n  \n \n\n  \n    PATE \n    0.25 \n  \n\n\n\n\n\nSimilarly, we can draw the estimates from a single run with draw_estimates which simulates data and, at the appropriate moment, calculates estimates.\n\ndraw_estimates(design)\n\n\n\n\n\nEstimates calculated from simulated data.\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n    df \n    outcome \n    inquiry \n  \n \n\n  \n    Z \n    0.57 \n    0.28 \n    2 \n    0.046 \n    0.009 \n    1.1 \n    47 \n    Y \n    PATE \n  \n\n\n\n\n\nTo simulate designs, we use the simulate_design function to draw data, calculate estimands and estimates, and then repeat the process over and over.\n\nsimulation_df <- simulate_design(design)\n\n\n\n\n\nSimulations data frame.\n \n  \n    sim_ID \n    estimand \n    estimate \n    std.error \n    statistic \n    p.value \n    conf.low \n    conf.high \n    df \n  \n \n\n  \n    1 \n    0.25 \n    0.418 \n    0.31 \n    1.34 \n    0.185 \n    -0.21 \n    1.04 \n    48 \n  \n  \n    2 \n    0.25 \n    0.447 \n    0.35 \n    1.29 \n    0.205 \n    -0.25 \n    1.15 \n    47 \n  \n  \n    3 \n    0.25 \n    0.233 \n    0.27 \n    0.87 \n    0.391 \n    -0.31 \n    0.78 \n    46 \n  \n  \n    4 \n    0.25 \n    -0.044 \n    0.24 \n    -0.19 \n    0.853 \n    -0.53 \n    0.44 \n    43 \n  \n  \n    5 \n    0.25 \n    0.742 \n    0.29 \n    2.57 \n    0.014 \n    0.16 \n    1.32 \n    44"
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#diagnosing-a-research-design",
    "href": "DeclareDesign/articles/declaredesign_101.html#diagnosing-a-research-design",
    "title": "DeclareDesign 101",
    "section": "Diagnosing a research design",
    "text": "Diagnosing a research design\nUsing the simulations data frame, we can calculate diagnosands like bias, root mean-squared-error, and power for each estimator-estimand pair. In DeclareDesign, we do this in two steps. First, declare your diagnosands, which are functions that summarize simulations data. The software includes many pre-coded diagnosands, though you can write your own like this:\n\nstudy_diagnosands <- declare_diagnosands(\n  bias = mean(estimate - estimand),\n  rmse = sqrt(mean((estimate - estimand)^2)),\n  power = mean(p.value <= 0.05)\n)\n\nSecond, apply your diagnosand declaration to the simulations data frame with the diagnose_design function:\n\ndiagnose_design(simulation_df, diagnosands = study_diagnosands)\n\n\n\n\n\nDesign diagnosis.\n \n  \n    Bias \n    RMSE \n    Power \n  \n \n\n  \n    0.01 \n    0.27 \n    0.12 \n  \n  \n    (0.01) \n    (0.01) \n    (0.02) \n  \n\n\n\n\n\nWe can also do this in a single step by sending diagnose_design a design object. The function will first run the simulations for you, then calculate the diagnosands from the simulation data frame that results.\n\ndiagnose_design(design, diagnosands = study_diagnosands)\n\n\nRedesign\nAfter the declaration phase, you will often want to learn how the diagnosands change as design features change. We can do this using redesign:\n\nredesign(design, N = c(100, 200, 300, 400, 500))\n\nAn alternative way to do this is to write a “designer.” A designer is a function that makes designs based on a few design parameters. Designer help researchers flexibly explore design variations. Here’s a simple designer based on our running example:\n\nsimple_designer <- function(sample_size, effect_size) {\n  declare_model(\n    N = sample_size, \n    U = rnorm(N),\n    potential_outcomes(Y ~ effect_size * Z + U)\n  ) +\n  declare_inquiry(PATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N, n = 50)) +\n  declare_assignment(Z = complete_ra(N, prob = 0.5)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, .method = difference_in_means, estimand = \"PATE\")\n}\n\nTo create a single design, based on our original parameters of a 100-unit sample size and a treatment effect of 0.25, we can run:\n\ndesign <- simple_designer(sample_size = 100, effect_size = 0.25)\n\nNow to simulate multiple designs, we can use the DeclareDesign function expand_design. Here we examine our simple design under several possible sample sizes, which we might want to do to conduct a minimum power analysis. We hold the effect size constant.\n\ndesigns <- expand_design(\n  simple_designer, \n  sample_size = c(100, 500, 1000), \n  effect_size = 0.25\n)\n\nOur simulation and diagnosis tools can take a list of designs and simulate all of them at once, creating a column called design to keep track. For example:\n\ndiagnose_design(designs)\n\n\n\nComparing designs\nAlternatively, we can compare a pair of designs directly with the compare_designs function. This function is most useful for comparing the differences between a planned design and an implemented design.\n\ncompare_designs(planned_design, implemented_design)\n\nSimilarly, we can compare two designs on the basis of their diagnoses:\n\ncompare_diagnoses(planned_design, implemented_design)\n\n\n\n\n\n\nLibrary of designs\nIn our DesignLibrary package, we have created a set of common designs as designers (functions that create designs from just a few parameters), so you can get started quickly.\n\nlibrary(DesignLibrary)\n\nb_c_design <- block_cluster_two_arm_designer(N = 1000, N_blocks = 10)"
  },
  {
    "objectID": "DeclareDesign/articles/declaredesign_101.html#further-reading",
    "href": "DeclareDesign/articles/declaredesign_101.html#further-reading",
    "title": "DeclareDesign 101",
    "section": "Further Reading",
    "text": "Further Reading\nFor much more detail and help, we recommend the following resources.\n\nrandomizr cheatsheet\nestimatr cheatsheet\nDeclareDesign cheatsheet\nR for Data Science\nRStudio R primers\nComputational social science bootcamp"
  },
  {
    "objectID": "DeclareDesign/articles/design_declaration_in_other_languages.html",
    "href": "DeclareDesign/articles/design_declaration_in_other_languages.html",
    "title": "Design Diagnosis in other languages",
    "section": "",
    "text": "Click on the declarations to download the code files; the figures to download the code that generated them; and the diagnosis to download a reproducible document that includes the diagnosis. You can also download the code for the reproducible documents for R, Stata, and Python.\n\nHow to compile the reproducible documents\nR: the .rmd is knit in Rstudio\nPython: compiled through pandoc using the following command:\nstitch two_arm_design_python.md -o two_arm_design_python.html\nStata: compiled from within Stata via the command:\ndyndoc two_arm_design_stata.txt, replace"
  },
  {
    "objectID": "DeclareDesign/articles/design_diagnosis_in_the_tidyverse.html",
    "href": "DeclareDesign/articles/design_diagnosis_in_the_tidyverse.html",
    "title": "Design Diagnosis in the tidy verse",
    "section": "",
    "text": "[to be written]"
  },
  {
    "objectID": "DeclareDesign/index.html",
    "href": "DeclareDesign/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "DeclareDesign is a system for describing research designs in code and simulating them in order to understand their properties. Because DeclareDesign employs a consistent grammar of designs, you can focus on the intellectually challenging part – designing good research studies – without having to code up simulations from scratch.\n\n\nTo install the latest stable release of DeclareDesign, please ensure that you are running version 3.5 or later of R and run the following code:\ninstall.packages(\"DeclareDesign\")\n\n\n\nDesigns are declared by adding together design elements. Here’s a minimal example that describes a 100 unit randomized controlled trial with a binary outcome. Half the units are assigned to treatment and the remainder to control. The true value of the average treatment effect is 0.05 and it will be estimated with the difference-in-means estimator. The diagnosis shows that the study is unbiased but underpowered.\nlibrary(DeclareDesign)\n\ndesign <-\n  declare_model(\n    N = 100, \n    potential_outcomes(Y ~ rbinom(N, size = 1, prob = 0.5 + 0.05 * Z))\n  ) +\n  declare_inquiry(ATE = 0.05) +\n  declare_assignment(Z = complete_ra(N, m = 50)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) + \n  declare_estimator(Y ~ Z, .method = lm_robust, inquiry = \"ATE\")\n\ndiagnosands <-\n  declare_diagnosands(bias = mean(estimate - estimand),\n                      power = mean(p.value <= 0.05))\n\ndiagnosis <- diagnose_design(design, diagnosands = diagnosands)\ndiagnosis\n\n\n\nInquiry\nEstimator\nBias\nSE(Bias)\nPower\nSE(Power)\nn sims\n\n\n\n\nATE\nestimator\n-0.004\n0.004\n0.076\n0.011\n500\n\n\n\n\n\n\nThe core DeclareDesign package relies on four companion packages, each of which is useful in its own right.\n\nrandomizr: Easy to use tools for common forms of random assignment and sampling.\nfabricatr: Imagine your data before you collect it.\nestimatr: Fast estimators for social scientists.\nDesignLibrary: Templates to quickly adopt and adapt common research designs.\n\n\n\n\n\nTo get started, have a look at this vignette on the idea behind DeclareDesign, which covers the main functionality of the software.\nYou can also browse a library of already declared designs, which relies on the DesignLibrary package. The library includes canonical designs that you can download, modify, and deploy.\nA fuller description of the philosophy underlying the software is described in this paper.\n\n\n\n\nEach of these declare_*() functions returns a function.\n\ndeclare_model() (describes dimensions and distributions over the variables, including potential outcomes)\ndeclare_inquiry() (takes variables in the model and calculates estimand value)\ndeclare_sampling() (takes a population and selects a sample)\ndeclare_assignment() (takes a population or sample and adds treatment assignments)\ndeclare_measurement() (takes data and adds measured values)\ndeclare_estimator() (takes data produced by sampling, assignment, and measurement and returns estimates linked to inquiries)\ndeclare_test() (takes data produced by sampling, assignment, and measurement and returns the result of a test)\n\nTo declare a design, connect the components of your design with the + operator.\nOnce you have declared your design, there are four core post-design-declaration commands used to modify or diagnose your design:\n\ndiagnose_design() (takes a design and returns simulations and diagnosis)\ndraw_data() (takes a design and returns a single draw of the data)\ndraw_estimates() (takes a design and returns a single simulation of estimates)\ndraw_estimands() (takes a design and returns a single simulation of estimands)\n\nA few other features:\n\nA designer is a function that takes parameters (e.g., N) and returns a design. expand_design() is a function of a designer and parameters that return a design.\nYou can change the diagnosands with declare_diagnosands().\n\n\nThis project was generously supported by a grant from the Laura and John Arnold Foundation and seed funding from EGAP."
  },
  {
    "objectID": "DeclareDesign/reference/simulate_design.html#description",
    "href": "DeclareDesign/reference/simulate_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nRuns many simulations of a design and returns a simulations data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/simulate_design.html#usage",
    "href": "DeclareDesign/reference/simulate_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsimulate_design(..., sims = 500)\n\nsimulate_designs(..., sims = 500)"
  },
  {
    "objectID": "DeclareDesign/reference/simulate_design.html#arguments",
    "href": "DeclareDesign/reference/simulate_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nA design created using the + operator, or a set of designs. You can also provide a single list of designs, for example one created by expand_design.\n\n\nsims\nThe number of simulations, defaulting to 500. If sims is a vector of the form c(10, 1, 2, 1) then different steps of a design will be simulated different numbers of times."
  },
  {
    "objectID": "DeclareDesign/reference/simulate_design.html#details",
    "href": "DeclareDesign/reference/simulate_design.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nDifferent steps of a design may each be simulated different a number of times, as specified by sims. In this case simulations are grouped into “fans”. The nested structure of simulations is recorded in the dataset using a set of variables named “step_x_draw.” For example if sims = c(2,1,1,3) is passed to simulate_design, then there will be two distinct draws of step 1, indicated in variable “step_1_draw” (with values 1 and 2) and there will be three draws for step 4 within each of the step 1 draws, recorded in “step_4_draw” (with values 1 to 6)."
  },
  {
    "objectID": "DeclareDesign/reference/simulate_design.html#examples",
    "href": "DeclareDesign/reference/simulate_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nmy_model <- \n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    Y_Z_0 = U, \n    Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n  )\n\nmy_assignment <- declare_assignment(Z = complete_ra(N))\n\nmy_inquiry <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\n\nmy_estimator <- declare_estimator(Y ~ Z, inquiry = my_inquiry)\n\nmy_reveal <- declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\ndesign <- my_model +\n  my_inquiry +\n  my_assignment +\n  my_reveal +\n  my_estimator\n\nlist(\"\\n\", \"simulations <- simulate_design(designs, sims = 2)\\n\", \"diagnosis <- diagnose_design(simulations_df = simulations)\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"simulations <- simulate_design(designs, sims = 2)\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(simulations_df = simulations)\\n\"\n\nlist(\"\\n\", \"# A fixed population with simulations over assignment only\\n\", \"head(simulate_design(design, sims = c(1, 1, 1, 100, 1)))\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"# A fixed population with simulations over assignment only\\n\"\n\n[[3]]\n[1] \"head(simulate_design(design, sims = c(1, 1, 1, 100, 1)))\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/post_design.html#description",
    "href": "DeclareDesign/reference/post_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nExplore your design\nPrint code to recreate a design"
  },
  {
    "objectID": "DeclareDesign/reference/post_design.html#usage",
    "href": "DeclareDesign/reference/post_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nprint_code(design)\nprintdesign(x, verbose = FALSE, …)\nsummarydesign(object, verbose = TRUE, …)"
  },
  {
    "objectID": "DeclareDesign/reference/post_design.html#arguments",
    "href": "DeclareDesign/reference/post_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nA design object, typically created using the + operator\n\n\nx\na design object, typically created using the + operator\n\n\nverbose\nan indicator for printing a long summary of the design, defaults to TRUE\n\n\n…\noptional arguments to be sent to summary function\n\n\nobject\na design object created using the + operator"
  },
  {
    "objectID": "DeclareDesign/reference/post_design.html#examples",
    "href": "DeclareDesign/reference/post_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <-\n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    potential_outcomes(Y ~ U + Z * rnorm(N, 2, 2))\n  ) +\n  declare_sampling(S = complete_rs(N, n = 250)) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N, m = 25)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"my_inquiry\")\n\ndesign\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, U = rnorm(N), potential_outcomes(Y ~ U + Z * rnorm(N, 2, 2))) \n\nStep 2 (sampling): declare_sampling(S = complete_rs(N, n = 250)) ---------------\n\nStep 3 (inquiry): declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) -------------------\n\nStep 4 (assignment): declare_assignment(Z = complete_ra(N, m = 25)) ------------\n\nStep 5 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 6 (estimator): declare_estimator(Y ~ Z, inquiry = \"my_inquiry\") -----------\n\nRun of the design:\n\n\nWarning in simulate_single_design(design, sims = 1, low_simulations_warning =\nFALSE): Estimators lack inquiry/term labels for matching, a many-to-many merge\nwas performed.\n\nWarning in simulate_single_design(design, sims = 1, low_simulations_warning =\nFALSE): Estimators lack inquiry/term labels for matching, a many-to-many merge\nwas performed.\n\n\n    inquiry estimand estimator term estimate std.error statistic p.value\n        ATE     1.92      <NA> <NA>       NA        NA        NA      NA\n my_inquiry       NA estimator    Z    0.707     0.576      1.23   0.221\n conf.low conf.high  df outcome\n       NA        NA  NA    <NA>\n   -0.427      1.84 248       Y\n\ndf <- draw_data(design)\n\nestimates <- draw_estimates(design)\ninquiries <- draw_estimands(design)\n\nprint_code(design)\n\nmodel <- declare_model(N = 500, U = rnorm(N), potential_outcomes(Y ~ U + Z * rnorm(N, 2, 2))) \n\nsampling <- declare_sampling(S = complete_rs(N, n = 250)) \n\nATE <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) \n\nassignment <- declare_assignment(Z = complete_ra(N, m = 25)) \n\nmeasurement <- declare_measurement(Y = reveal_outcomes(Y ~ Z)) \n\nestimator <- declare_estimator(Y ~ Z, inquiry = \"my_inquiry\") \n\nmy_design <- construct_design(steps = steps) \n\nmy_population <- declare_model(N = 100)\n\nmy_assignment <- declare_assignment(Z = complete_ra(N, m = 50))\n\nmy_design <- my_population + my_assignment\n\nprint_code(my_design)\n\nmy_population <- declare_model(N = 100) \n\nmy_assignment <- declare_assignment(Z = complete_ra(N, m = 50)) \n\nmy_design <- construct_design(steps = steps) \n\nmy_model <- \n  declare_model(\n    N = 500, \n    noise = rnorm(N),\n    Y_Z_0 = noise, \n    Y_Z_1 = noise + rnorm(N, mean = 2, sd = 2)\n  )\n\nmy_sampling <- declare_sampling(S = complete_rs(N, n = 250))\n\nmy_assignment <- declare_assignment(Z = complete_ra(N, m = 25))\n\nmy_inquiry <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\n\nmy_estimator <- declare_estimator(Y ~ Z, inquiry = my_inquiry)\n\nmy_reveal <- declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\ndesign <- my_model +\n  my_sampling +\n  my_inquiry +\n  my_assignment +\n  my_reveal +\n  my_estimator\n\nsummary(design)\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, noise = rnorm(N), Y_Z_0 = noise, Y_Z_1 = noise + rnorm(N, mean = 2, sd = 2)) \n\nN = 500 \n\nAdded variable: ID \n N_missing N_unique     class\n         0      500 character\n\nAdded variable: noise \n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 3.09 1.02         0      500\n\nAdded variable: Y_Z_0 \n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 3.09 1.02         0      500\n\nAdded variable: Y_Z_1 \n   min median mean max   sd N_missing N_unique\n -4.86   1.95 1.99 9.6 2.39         0      500\n\nStep 2 (sampling): declare_sampling(S = complete_rs(N, n = 250)) ---------------\n\nN = 250 (250 subtracted) \n\nAdded variable: S \n    1\n  250\n 1.00\n\nAltered variable: ID \n  Before: \n N_missing N_unique     class\n         0      500 character\n\n  After:\n N_missing N_unique     class\n         0      250 character\n\nAltered variable: noise \n  Before: \n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 3.09 1.02         0      500\n\n  After:\n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 2.35 0.97         0      250\n\nAltered variable: Y_Z_0 \n  Before: \n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 3.09 1.02         0      500\n\n  After:\n   min median mean  max   sd N_missing N_unique\n -3.11   0.07 0.06 2.35 0.97         0      250\n\nAltered variable: Y_Z_1 \n  Before: \n   min median mean max   sd N_missing N_unique\n -4.86   1.95 1.99 9.6 2.39         0      500\n\n  After:\n   min median mean  max   sd N_missing N_unique\n -4.86   1.85  1.9 9.02 2.52         0      250\n\nStep 3 (inquiry): declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) -------------------\n\nA single draw of the inquiry:\n inquiry estimand\n     ATE  1.84558\n\nStep 4 (assignment): declare_assignment(Z = complete_ra(N, m = 25)) ------------\n\nAdded variable: Z \n    0    1\n  225   25\n 0.90 0.10\n\nStep 5 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nAdded variable: Y \n   min median mean  max   sd N_missing N_unique\n -3.21   0.12 0.17 6.17 1.26         0      250\n\nStep 6 (estimator): declare_estimator(Y ~ Z, inquiry = my_inquiry) -------------\n\nFormula: Y ~ Z \n\nA single draw of the estimator:\n estimator term estimate std.error statistic    p.value  conf.low conf.high  df\n estimator    Z 1.190902 0.4926473  2.417353 0.01635592 0.2205963  2.161209 248\n outcome inquiry\n       Y     ATE"
  },
  {
    "objectID": "DeclareDesign/reference/tidy.diagnosis.html#description",
    "href": "DeclareDesign/reference/tidy.diagnosis.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nTidy diagnosis"
  },
  {
    "objectID": "DeclareDesign/reference/tidy.diagnosis.html#usage",
    "href": "DeclareDesign/reference/tidy.diagnosis.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ntidydiagnosis(x, conf.int = TRUE, conf.level = 0.95, …)"
  },
  {
    "objectID": "DeclareDesign/reference/tidy.diagnosis.html#arguments",
    "href": "DeclareDesign/reference/tidy.diagnosis.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA diagnosis object generated by diagnose_design.\n\n\nconf.int\nLogical indicating whether or not to include a confidence interval in the tidied output. Defaults to ‘TRUE’.\n\n\nconf.level\nThe confidence level to use for the confidence interval if ‘conf.int = TRUE’. Must be strictly greater than 0 and less than 1. Defaults to 0.95, which corresponds to a 95 percent confidence interval.\n\n\n…\nextra arguments (not used)"
  },
  {
    "objectID": "DeclareDesign/reference/tidy.diagnosis.html#value",
    "href": "DeclareDesign/reference/tidy.diagnosis.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA data.frame with columns for diagnosand names, estimated diagnosand values, bootstrapped standard errors and confidence intervals"
  },
  {
    "objectID": "DeclareDesign/reference/tidy.diagnosis.html#examples",
    "href": "DeclareDesign/reference/tidy.diagnosis.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\neffect_size <- 0.1\ndesign <-\n  declare_model(\n    N = 100,\n    U = rnorm(N),\n    X = rnorm(N),\n    potential_outcomes(Y ~ effect_size * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\", label = \"unadjusted\") + \n  declare_estimator(Y ~ Z + X, inquiry = \"ATE\", label = \"adjusted\")\n\ndiagnosis <- diagnose_design(design, sims = 100)\n\ntidy(diagnosis)\n\n   design inquiry  estimator outcome term    diagnosand   estimate  std.error\n1  design     ATE   adjusted       Y    Z mean_estimand 0.10000000 0.00000000\n2  design     ATE   adjusted       Y    Z mean_estimate 0.12851272 0.02041573\n3  design     ATE   adjusted       Y    Z          bias 0.02851272 0.02041573\n4  design     ATE   adjusted       Y    Z   sd_estimate 0.19048871 0.01196233\n5  design     ATE   adjusted       Y    Z          rmse 0.19166654 0.01109053\n6  design     ATE   adjusted       Y    Z         power 0.07000000 0.02206510\n7  design     ATE   adjusted       Y    Z      coverage 0.95000000 0.02166690\n8  design     ATE unadjusted       Y    Z mean_estimand 0.10000000 0.00000000\n9  design     ATE unadjusted       Y    Z mean_estimate 0.16727898 0.02968000\n10 design     ATE unadjusted       Y    Z          bias 0.06727898 0.02968000\n11 design     ATE unadjusted       Y    Z   sd_estimate 0.29228338 0.02229964\n12 design     ATE unadjusted       Y    Z          rmse 0.29849914 0.02142553\n13 design     ATE unadjusted       Y    Z         power 0.11000000 0.03031551\n14 design     ATE unadjusted       Y    Z      coverage 0.92000000 0.02716857\n       conf.low  conf.high\n1   0.100000000 0.10000000\n2   0.090951235 0.17180156\n3  -0.009048765 0.07180156\n4   0.169192224 0.21321944\n5   0.171263413 0.21462272\n6   0.030000000 0.11000000\n7   0.910000000 0.99000000\n8   0.100000000 0.10000000\n9   0.114542697 0.21862912\n10  0.014542697 0.11862912\n11  0.246885383 0.33207388\n12  0.253293656 0.33844101\n13  0.060000000 0.16525000\n14  0.880000000 0.98000000"
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#description",
    "href": "DeclareDesign/reference/diagnose_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nGenerates diagnosands from a design or simulations of a design."
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#usage",
    "href": "DeclareDesign/reference/diagnose_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndiagnose_design(\n  ...,\n  diagnosands = NULL,\n  sims = 500,\n  bootstrap_sims = 100,\n  make_groups = NULL,\n  add_grouping_variables = NULL\n)\n\ndiagnose_designs(\n  ...,\n  diagnosands = NULL,\n  sims = 500,\n  bootstrap_sims = 100,\n  make_groups = NULL,\n  add_grouping_variables = NULL\n)\n\nvars(...)"
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#arguments",
    "href": "DeclareDesign/reference/diagnose_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nA design or set of designs typically created using the + operator, or a data.frame of simulations, typically created by simulate_design.\n\n\ndiagnosands\nA set of diagnosands created by declare_diagnosands. By default, these include bias, root mean-squared error, power, frequentist coverage, the mean and standard deviation of the estimate(s), the “type S” error rate (Gelman and Carlin 2014), and the mean of the inquiry(s).\n\n\nsims\nThe number of simulations, defaulting to 500. sims may also be a vector indicating the number of simulations for each step in a design, as described for simulate_design\n\n\nbootstrap_sims\nNumber of bootstrap replicates for the diagnosands to obtain the standard errors of the diagnosands, defaulting to 100. Set to FALSE to turn off bootstrapping.\n\n\nmake_groups\nAdd group variables within which diagnosand values will be calculated. New variables can be created or variables already in the simulations data frame selected. Type name-value pairs within the function vars, i.e. vars(significant = p.value <= 0.05).\n\n\nadd_grouping_variables\nDeprecated. Please use make_groups instead. Variables used to generate groups of simulations for diagnosis. Added to default list: c(“design”, “estimand_label”, “estimator”, “outcome”, “term”)"
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#details",
    "href": "DeclareDesign/reference/diagnose_design.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nIf the diagnosand function contains a group_by attribute, it will be used to split-apply-combine diagnosands rather than the intersecting column names.\nIf sims is named, or longer than one element, a fan-out strategy is created and used instead.\nIf the packages future and future.apply are installed, you can set plan to run multiple simulations in parallel."
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#value",
    "href": "DeclareDesign/reference/diagnose_design.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na list with a data frame of simulations, a data frame of diagnosands, a vector of diagnosand names, and if calculated, a data frame of bootstrap replicates."
  },
  {
    "objectID": "DeclareDesign/reference/diagnose_design.html#examples",
    "href": "DeclareDesign/reference/diagnose_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    Y_Z_0 = U, \n    Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n  ) + \n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) + \n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) + \n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\nlist(\"\\n\", \"# using built-in defaults:\\n\", \"diagnosis <- diagnose_design(design)\\n\", \"reshape_diagnosis(diagnosis, select = \\\"Power\\\")\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"# using built-in defaults:\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(design)\\n\"\n\n[[4]]\n[1] \"reshape_diagnosis(diagnosis, select = \\\"Power\\\")\\n\"\n\nlist(\"\\n\", \"# Adding a group for within group diagnosis:\\n\", \"diagnosis <- diagnose_design(design, \\n\", \"  make_groups = vars(significant = p.value <= 0.05),\\n\", \"  )\\n\", \"diagnosis\\n\", \"\\n\", \"diagnosis <- diagnose_design(design, \\n\", \"  make_groups = \\n\", \"    vars(effect_size = \\n\", \"      cut(estimand, quantile(estimand, (0:4)/4), \\n\", \"          include.lowest = TRUE)),\\n\", \"  )\\n\", \"diagnosis\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"# Adding a group for within group diagnosis:\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(design, \\n\"\n\n[[4]]\n[1] \"  make_groups = vars(significant = p.value <= 0.05),\\n\"\n\n[[5]]\n[1] \"  )\\n\"\n\n[[6]]\n[1] \"diagnosis\\n\"\n\n[[7]]\n[1] \"\\n\"\n\n[[8]]\n[1] \"diagnosis <- diagnose_design(design, \\n\"\n\n[[9]]\n[1] \"  make_groups = \\n\"\n\n[[10]]\n[1] \"    vars(effect_size = \\n\"\n\n[[11]]\n[1] \"      cut(estimand, quantile(estimand, (0:4)/4), \\n\"\n\n[[12]]\n[1] \"          include.lowest = TRUE)),\\n\"\n\n[[13]]\n[1] \"  )\\n\"\n\n[[14]]\n[1] \"diagnosis\\n\"\n\n# using a user-defined diagnosand\nmy_diagnosand <- declare_diagnosands(absolute_error = mean(abs(estimate - estimand)))\n\nlist(\"\\n\", \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosand)\\n\", \"diagnosis\\n\", \"\\n\", \"get_diagnosands(diagnosis)\\n\", \"\\n\", \"get_simulations(diagnosis)\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosand)\\n\"\n\n[[3]]\n[1] \"diagnosis\\n\"\n\n[[4]]\n[1] \"\\n\"\n\n[[5]]\n[1] \"get_diagnosands(diagnosis)\\n\"\n\n[[6]]\n[1] \"\\n\"\n\n[[7]]\n[1] \"get_simulations(diagnosis)\\n\"\n\n[[8]]\n[1] \"\\n\"\n\n# Using an existing data frame of simulations\nlist(\"\\n\", \"simulations <- simulate_design(designs, sims = 2)\\n\", \"diagnosis   <- diagnose_design(simulations_df = simulations_df)\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"simulations <- simulate_design(designs, sims = 2)\\n\"\n\n[[3]]\n[1] \"diagnosis   <- diagnose_design(simulations_df = simulations_df)\\n\"\n\n[[4]]\n[1] \"\\n\"\n\n# If you do not specify diagnosands, the function default_diagnosands() is used, \n#   which is reproduced below.\n\nalpha <- 0.05\n\ndefault_diagnosands <- \n  declare_diagnosands(\n   mean_estimand = mean(estimand),\n   mean_estimate = mean(estimate),\n   bias = mean(estimate - estimand),\n   sd_estimate = sqrt(pop.var(estimate)),\n   rmse = sqrt(mean((estimate - estimand) ^ 2)),\n   power = mean(p.value <= alpha),\n   coverage = mean(estimand <= conf.high & estimand >= conf.low)\n  )\n\n# A longer list of useful diagnosands might include:\n\nextended_diagnosands <- \n  declare_diagnosands(\n    mean_estimand = mean(estimand),\n    mean_estimate = mean(estimate),\n    bias = mean(estimate - estimand),\n    sd_estimate = sd(estimate),\n    rmse = sqrt(mean((estimate - estimand) ^ 2)),\n    power = mean(p.value <= alpha),\n    coverage = mean(estimand <= conf.high & estimand >= conf.low),\n    mean_se = mean(std.error),\n    type_s_rate = mean((sign(estimate) != sign(estimand))[p.value <= alpha]),\n    exaggeration_ratio = mean((estimate/estimand)[p.value <= alpha]),\n    var_estimate = pop.var(estimate),\n    mean_var_hat = mean(std.error^2),\n    prop_pos_sig = estimate > 0 & p.value <= alpha,\n    mean_ci_length = mean(conf.high - conf.low)\n  )"
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#description",
    "href": "DeclareDesign/reference/declare_diagnosands.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare diagnosands"
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#usage",
    "href": "DeclareDesign/reference/declare_diagnosands.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndiagnosand_handler(data, ..., subset = NULL, alpha = 0.05, label)\n\ndeclare_diagnosands(..., handler = diagnosand_handler, label = NULL)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#arguments",
    "href": "DeclareDesign/reference/declare_diagnosands.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata\nA data.frame.\n\n\n…\nA set of new diagnosands.\n\n\nsubset\nA subset of the simulations data frame within which to calculate diagnosands e.g. subset = p.value < .05.\n\n\nalpha\nAlpha significance level. Defaults to .05.\n\n\nlabel\nLabel for the set of diagnosands.\n\n\nhandler\na tidy-in, tidy-out function"
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#details",
    "href": "DeclareDesign/reference/declare_diagnosands.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nIf term is TRUE, the names of … will be returned in a term column, and inquiry will contain the step label. This can be used as an additional dimension for use in diagnosis.\nDiagnosands summarize the simulations generated by diagnose_design or simulate_design. Typically, the columns of the resulting simulations data.frame include the following variables: estimate, std.error, p.value, conf.low, conf.high, and inquiry. Many diagnosands will be a function of these variables."
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#value",
    "href": "DeclareDesign/reference/declare_diagnosands.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na function that returns a data.frame"
  },
  {
    "objectID": "DeclareDesign/reference/declare_diagnosands.html#examples",
    "href": "DeclareDesign/reference/declare_diagnosands.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    Y_Z_0 = U, \n    Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n  ) + \n  declare_assignment(Z = complete_ra(N)) + \n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) + \n  declare_estimator(Y ~ Z, inquiry = my_inquiry) + \n  declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\nlist(\"\\n\", \"# using built-in defaults:\\n\", \"diagnosis <- diagnose_design(design)\\n\", \"diagnosis\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"# using built-in defaults:\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(design)\\n\"\n\n[[4]]\n[1] \"diagnosis\\n\"\n\n# You can choose your own diagnosands instead of the defaults e.g.,\n\nmy_diagnosands <-\n  declare_diagnosands(median_bias = median(estimate - inquiry))\nlist(\"\\n\", \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosands)\\n\", \"diagnosis\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosands)\\n\"\n\n[[3]]\n[1] \"diagnosis\\n\"\n\nlist(\"\\n\", \"design <- set_diagnosands(design, diagnosands = my_diagnosands)\\n\", \"diagnosis <- diagnose_design(design)\\n\", \"diagnosis\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"design <- set_diagnosands(design, diagnosands = my_diagnosands)\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(design)\\n\"\n\n[[4]]\n[1] \"diagnosis\\n\"\n\n# If you do not specify diagnosands in diagnose_design, \n#   the function default_diagnosands() is used, \n#   which is reproduced below.\n\nalpha <- 0.05\n\ndefault_diagnosands <- \n  declare_diagnosands(\n   mean_estimand = mean(estimand),\n   mean_estimate = mean(estimate),\n   bias = mean(estimate - estimand),\n   sd_estimate = sqrt(pop.var(estimate)),\n   rmse = sqrt(mean((estimate - estimand) ^ 2)),\n   power = mean(p.value <= alpha),\n   coverage = mean(estimand <= conf.high & estimand >= conf.low)\n  )\n\n# A longer list of potentially useful diagnosands might include:\n\nextended_diagnosands <- \n  declare_diagnosands(\n    mean_estimand = mean(estimand),\n    mean_estimate = mean(estimate),\n    bias = mean(estimate - estimand),\n    sd_estimate = sd(estimate),\n    rmse = sqrt(mean((estimate - estimand) ^ 2)),\n    power = mean(p.value <= alpha),\n    coverage = mean(estimand <= conf.high & estimand >= conf.low),\n    mean_se = mean(std.error),\n    type_s_rate = mean((sign(estimate) != sign(estimand))[p.value <= alpha]),\n    exaggeration_ratio = mean((estimate/estimand)[p.value <= alpha]),\n    var_estimate = pop.var(estimate),\n    mean_var_hat = mean(std.error^2),\n    prop_pos_sig = estimate > 0 & p.value <= alpha,\n    mean_ci_length = mean(conf.high - conf.low)\n  )"
  },
  {
    "objectID": "DeclareDesign/reference/diagnosis_helpers.html#description",
    "href": "DeclareDesign/reference/diagnosis_helpers.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nExplore your design diagnosis"
  },
  {
    "objectID": "DeclareDesign/reference/diagnosis_helpers.html#usage",
    "href": "DeclareDesign/reference/diagnosis_helpers.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nget_diagnosands(diagnosis)\n\nget_simulations(diagnosis)"
  },
  {
    "objectID": "DeclareDesign/reference/diagnosis_helpers.html#arguments",
    "href": "DeclareDesign/reference/diagnosis_helpers.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\ndiagnosis\nA design diagnosis created by diagnose_design."
  },
  {
    "objectID": "DeclareDesign/reference/diagnosis_helpers.html#examples",
    "href": "DeclareDesign/reference/diagnosis_helpers.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    Y_Z_0 = U, \n    Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n  ) + \n  declare_assignment(Z = complete_ra(N)) + \n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) + \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\") \n\nlist(\"\\n\", \"# using built-in defaults:\\n\", \"diagnosis <- diagnose_design(design)\\n\", \"diagnosis\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"# using built-in defaults:\\n\"\n\n[[3]]\n[1] \"diagnosis <- diagnose_design(design)\\n\"\n\n[[4]]\n[1] \"diagnosis\\n\"\n\n# using a user-defined diagnosand\nmy_diagnosand <- declare_diagnosands(\n  absolute_error = mean(abs(estimate - estimand)))\n\nlist(\"\\n\", \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosand)\\n\", \"diagnosis\\n\", \"\\n\", \"get_diagnosands(diagnosis)\\n\", \"\\n\", \"get_simulations(diagnosis)\\n\", \"\\n\", \"reshape_diagnosis(diagnosis)\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(design, diagnosands = my_diagnosand)\\n\"\n\n[[3]]\n[1] \"diagnosis\\n\"\n\n[[4]]\n[1] \"\\n\"\n\n[[5]]\n[1] \"get_diagnosands(diagnosis)\\n\"\n\n[[6]]\n[1] \"\\n\"\n\n[[7]]\n[1] \"get_simulations(diagnosis)\\n\"\n\n[[8]]\n[1] \"\\n\"\n\n[[9]]\n[1] \"reshape_diagnosis(diagnosis)\\n\"\n\n[[10]]\n[1] \"\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/set_citation.html#description",
    "href": "DeclareDesign/reference/set_citation.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nSet the citation of a design"
  },
  {
    "objectID": "DeclareDesign/reference/set_citation.html#usage",
    "href": "DeclareDesign/reference/set_citation.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nset_citation(\n  design,\n  title = NULL,\n  author = NULL,\n  year = NULL,\n  description = \"Unpublished research design declaration\",\n  citation = NULL\n)"
  },
  {
    "objectID": "DeclareDesign/reference/set_citation.html#arguments",
    "href": "DeclareDesign/reference/set_citation.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nA design typically created using the + operator\n\n\ntitle\nThe title of the design, as a character string.\n\n\nauthor\nThe author(s) of the design, as a character string.\n\n\nyear\nThe year of the design, as a character string.\n\n\ndescription\nA description of the design in words, as a character string.\n\n\ncitation\n(optional) The preferred citation for the design, as a character string, in which case title, author, year, and description may be left unspecified."
  },
  {
    "objectID": "DeclareDesign/reference/set_citation.html#value",
    "href": "DeclareDesign/reference/set_citation.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na design object with a citation attribute"
  },
  {
    "objectID": "DeclareDesign/reference/set_citation.html#examples",
    "href": "DeclareDesign/reference/set_citation.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <-\ndeclare_model(data = sleep) +\n  declare_sampling(S = complete_rs(N, n = 10))\n\ndesign <-\n  set_citation(design,\n               author = \"Lovelace, Ada\",\n               title = \"Notes\",\n               year = 1953,\n               description = \"This is a text description of a design\")\n\ncite_design(design)\n\n@Unpublished{,\n  title = {Notes},\n  author = {{Lovelace} and {Ada}},\n  note = {This is a text description of a design},\n  year = {1953},\n}"
  },
  {
    "objectID": "DeclareDesign/reference/pop.var.html#description",
    "href": "DeclareDesign/reference/pop.var.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nPopulation variance function"
  },
  {
    "objectID": "DeclareDesign/reference/pop.var.html#usage",
    "href": "DeclareDesign/reference/pop.var.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\npop.var(x, na.rm = FALSE)"
  },
  {
    "objectID": "DeclareDesign/reference/pop.var.html#arguments",
    "href": "DeclareDesign/reference/pop.var.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\nx\na numeric vector, matrix or data frame.\n\n\nna.rm\nlogical. Should missing values be removed?"
  },
  {
    "objectID": "DeclareDesign/reference/pop.var.html#value",
    "href": "DeclareDesign/reference/pop.var.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nnumeric scalar of the population variance"
  },
  {
    "objectID": "DeclareDesign/reference/pop.var.html#examples",
    "href": "DeclareDesign/reference/pop.var.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nx <- 1:4\nvar(x) # divides by (n-1)\n\n[1] 1.666667\n\npop.var(x) # divides by n\n\n[1] 1.25"
  },
  {
    "objectID": "DeclareDesign/reference/declaredesign-deprecated.html#description",
    "href": "DeclareDesign/reference/declaredesign-deprecated.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThe functions listed below are deprecated and will be defunct in the near future. When possible, alternative functions with similar functionality are also mentioned. Help pages for deprecated functions are available at help(\"-deprecated\")."
  },
  {
    "objectID": "DeclareDesign/reference/declaredesign-deprecated.html#usage",
    "href": "DeclareDesign/reference/declaredesign-deprecated.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ntidy_estimator(estimator_function)\n\nmodel_handler(...)"
  },
  {
    "objectID": "DeclareDesign/reference/get_functions.html#description",
    "href": "DeclareDesign/reference/get_functions.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nGet estimates, inquiries, assignment vectors, or samples from a design given data"
  },
  {
    "objectID": "DeclareDesign/reference/get_functions.html#usage",
    "href": "DeclareDesign/reference/get_functions.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nget_estimates(design, data = NULL, start = 1, end = length(design))"
  },
  {
    "objectID": "DeclareDesign/reference/get_functions.html#arguments",
    "href": "DeclareDesign/reference/get_functions.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nA design object, typically created using the + operator\n\n\ndata\nA data.frame object with sufficient information to get the data, estimates, inquiries, an assignment vector, or a sample.\n\n\nstart\n(Defaults to 1) a scalar indicating which step in the design to begin with. By default all data steps are drawn, from step 1 to the last step of the design.\n\n\nend\n(Defaults to length(design)) a scalar indicating which step in the design to finish with."
  },
  {
    "objectID": "DeclareDesign/reference/get_functions.html#examples",
    "href": "DeclareDesign/reference/get_functions.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 100, \n    U = rnorm(N),\n    potential_outcomes(Y ~ Z + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N, n = 75)) +\n  declare_assignment(Z = complete_ra(N, m = 50)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\ndat <- draw_data(design)\n\ndraw_data(design, data = dat, start = 2)\n\n    ID            U        Y_Z_0       Y_Z_1 S Z           Y\n1  001  0.383805044  0.383805044  1.38380504 1 0  0.38380504\n2  002 -0.066555435 -0.066555435  0.93344457 1 1  0.93344457\n3  003 -0.872276092 -0.872276092  0.12772391 1 1  0.12772391\n4  006  0.500123007  0.500123007  1.50012301 1 0  0.50012301\n5  007  1.240662722  1.240662722  2.24066272 1 1  2.24066272\n6  008  0.223219464  0.223219464  1.22321946 1 1  1.22321946\n7  010 -2.132828188 -2.132828188 -1.13282819 1 0 -2.13282819\n8  011 -0.169427810 -0.169427810  0.83057219 1 1  0.83057219\n9  013 -0.258894512 -0.258894512  0.74110549 1 1  0.74110549\n10 015  2.835116190  2.835116190  3.83511619 1 0  2.83511619\n11 016  1.271624225  1.271624225  2.27162422 1 1  2.27162422\n12 017 -0.841311036 -0.841311036  0.15868896 1 1  0.15868896\n13 019  1.429624647  1.429624647  2.42962465 1 1  2.42962465\n14 020 -0.986909406 -0.986909406  0.01309059 1 0 -0.98690941\n15 021  0.450877240  0.450877240  1.45087724 1 0  0.45087724\n16 022  0.036296260  0.036296260  1.03629626 1 1  1.03629626\n17 024 -0.047801646 -0.047801646  0.95219835 1 1  0.95219835\n18 025  0.555921563  0.555921563  1.55592156 1 1  1.55592156\n19 026 -1.500338558 -1.500338558 -0.50033856 1 0 -1.50033856\n20 027  0.780369740  0.780369740  1.78036974 1 1  1.78036974\n21 029  0.542492497  0.542492497  1.54249250 1 1  1.54249250\n22 030  1.519464166  1.519464166  2.51946417 1 1  2.51946417\n23 034  0.394147179  0.394147179  1.39414718 1 1  1.39414718\n24 035  0.333798044  0.333798044  1.33379804 1 1  1.33379804\n25 036  0.272633975  0.272633975  1.27263398 1 1  1.27263398\n26 037 -0.701040685 -0.701040685  0.29895932 1 1  0.29895932\n27 039  1.542521128  1.542521128  2.54252113 1 0  1.54252113\n28 041  0.040241388  0.040241388  1.04024139 1 0  0.04024139\n29 042  1.469412650  1.469412650  2.46941265 1 1  2.46941265\n30 043  1.446280480  1.446280480  2.44628048 1 1  2.44628048\n31 044 -0.663345855 -0.663345855  0.33665415 1 1  0.33665415\n32 046 -0.312450331 -0.312450331  0.68754967 1 1  0.68754967\n33 047  0.547979055  0.547979055  1.54797906 1 0  0.54797906\n34 049 -0.741448478 -0.741448478  0.25855152 1 1  0.25855152\n35 050 -0.330609714 -0.330609714  0.66939029 1 0 -0.33060971\n36 051  0.533173869  0.533173869  1.53317387 1 0  0.53317387\n37 052 -1.083807008 -1.083807008 -0.08380701 1 0 -1.08380701\n38 053 -1.834669783 -1.834669783 -0.83466978 1 1 -0.83466978\n39 055  0.520122178  0.520122178  1.52012218 1 1  1.52012218\n40 056  0.423891215  0.423891215  1.42389121 1 1  1.42389121\n41 057 -0.094049047 -0.094049047  0.90595095 1 1  0.90595095\n42 058 -0.651764666 -0.651764666  0.34823533 1 0 -0.65176467\n43 059 -2.174603268 -2.174603268 -1.17460327 1 1 -1.17460327\n44 060  0.125937840  0.125937840  1.12593784 1 1  1.12593784\n45 061  0.673421412  0.673421412  1.67342141 1 0  0.67342141\n46 062 -1.148140517 -1.148140517 -0.14814052 1 1 -0.14814052\n47 063  0.266390901  0.266390901  1.26639090 1 1  1.26639090\n48 065  0.488359029  0.488359029  1.48835903 1 1  1.48835903\n49 066 -0.635346395 -0.635346395  0.36465360 1 0 -0.63534640\n50 067  0.160621605  0.160621605  1.16062161 1 1  1.16062161\n51 068 -1.270037540 -1.270037540 -0.27003754 1 0 -1.27003754\n52 069  0.116107350  0.116107350  1.11610735 1 1  1.11610735\n53 070  0.218076302  0.218076302  1.21807630 1 1  1.21807630\n54 071  0.402258976  0.402258976  1.40225898 1 0  0.40225898\n55 073  1.684485669  1.684485669  2.68448567 1 0  1.68448567\n56 075  0.487288506  0.487288506  1.48728851 1 0  0.48728851\n57 076  0.651001323  0.651001323  1.65100132 1 1  1.65100132\n58 077 -0.051998823 -0.051998823  0.94800118 1 0 -0.05199882\n59 078 -0.770380960 -0.770380960  0.22961904 1 0 -0.77038096\n60 079 -0.772388385 -0.772388385  0.22761161 1 1  0.22761161\n61 080  1.649681112  1.649681112  2.64968111 1 1  2.64968111\n62 081 -0.609866989 -0.609866989  0.39013301 1 0 -0.60986699\n63 082 -0.249189665 -0.249189665  0.75081033 1 1  0.75081033\n64 083 -0.784116349 -0.784116349  0.21588365 1 1  0.21588365\n65 084 -0.529613754 -0.529613754  0.47038625 1 1  0.47038625\n66 087 -0.624191541 -0.624191541  0.37580846 1 0 -0.62419154\n67 090 -0.215978349 -0.215978349  0.78402165 1 1  0.78402165\n68 091  0.794497902  0.794497902  1.79449790 1 1  1.79449790\n69 092  0.539722353  0.539722353  1.53972235 1 1  1.53972235\n70 093 -0.239199855 -0.239199855  0.76080014 1 1  0.76080014\n71 094 -1.924130580 -1.924130580 -0.92413058 1 1 -0.92413058\n72 096 -0.925376698 -0.925376698  0.07462330 1 1  0.07462330\n73 097 -0.843359255 -0.843359255  0.15664074 1 0 -0.84335926\n74 098  0.892764397  0.892764397  1.89276440 1 1  1.89276440\n75 100  0.009840187  0.009840187  1.00984019 1 1  1.00984019\n\nget_estimates(design, data = dat)\n\n  estimator term  estimate std.error statistic      p.value  conf.low conf.high\n1 estimator    Z 0.8728471  0.245697  3.552535 0.0006729279 0.3831737  1.362521\n  df outcome inquiry\n1 73       Y     ATE"
  },
  {
    "objectID": "DeclareDesign/reference/declare_step.html#description",
    "href": "DeclareDesign/reference/declare_step.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nWith declare_step, you can include any function that takes data as one of its arguments and returns data in a design declaration. The first argument is always a “handler”, which is the name of the data-in, data-out function. For handy data manipulations use declare_step(fabricate, ...)."
  },
  {
    "objectID": "DeclareDesign/reference/declare_step.html#usage",
    "href": "DeclareDesign/reference/declare_step.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_step(\n  ...,\n  handler = function(data, ...f, ...) ...f(data, ...),\n  label = NULL\n)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_step.html#arguments",
    "href": "DeclareDesign/reference/declare_step.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step"
  },
  {
    "objectID": "DeclareDesign/reference/declare_step.html#value",
    "href": "DeclareDesign/reference/declare_step.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that returns a data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/declare_step.html#examples",
    "href": "DeclareDesign/reference/declare_step.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\npopulation <- declare_model(N = 5, noise = rnorm(N))\nmanipulate <- declare_step(fabricate, noise_squared = noise^2, zero = 0)\n\ndesign <- population + manipulate\ndraw_data(design)\n\n  ID      noise noise_squared zero\n1  1 -0.3391185    0.11500139    0\n2  2  0.6812867    0.46415151    0\n3  3 -0.3073039    0.09443569    0\n4  4 -0.2868762    0.08229794    0\n5  5 -0.2549128    0.06498051    0"
  },
  {
    "objectID": "DeclareDesign/reference/declare_assignment.html#description",
    "href": "DeclareDesign/reference/declare_assignment.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare Data Strategy: Assignment"
  },
  {
    "objectID": "DeclareDesign/reference/declare_assignment.html#usage",
    "href": "DeclareDesign/reference/declare_assignment.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_assignment(..., handler = assignment_handler, label = NULL)\n\nassignment_handler(data, ..., legacy = FALSE)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_assignment.html#arguments",
    "href": "DeclareDesign/reference/declare_assignment.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\ndata\nA data.frame.\n\n\nlegacy\nUse the legacy randomizr functionality. This will be disabled in future; please use legacy = FALSE."
  },
  {
    "objectID": "DeclareDesign/reference/declare_assignment.html#value",
    "href": "DeclareDesign/reference/declare_assignment.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that takes a data.frame as an argument and returns a data.frame with assignment columns appended."
  },
  {
    "objectID": "DeclareDesign/reference/declare_assignment.html#examples",
    "href": "DeclareDesign/reference/declare_assignment.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# declare_assignment in use\n## Two-arm randomized experiment\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ 0.2 * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N = N, n = 200)) +\n  declare_assignment(Z = complete_ra(N = N, m = 100)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\n# Set up population to assign\nmodel <- declare_model(\n  villages = add_level(\n    N = 30, \n    N_households = sample(c(50:100), N, replace = TRUE)\n  ),\n  households = add_level(\n    N = N_households, \n    N_members = sample(c(1, 2, 3, 4), N, \n                       prob = c(0.2, 0.3, 0.25, 0.25), replace = TRUE)\n  ),\n  individuals = add_level(\n    N = N_members, \n    age = sample(18:90, N, replace = TRUE),\n    gender = rbinom(n = N, size = 1, prob = .5)\n  )\n)\n\n# Assignment procedures\n## Complete random assignment\ndesign <-\n  model +\n  declare_assignment(Z = complete_ra(N = N, m = 1000))\n\n## Cluster random assignment\ndesign <-\n  model +\n  declare_assignment(Z = cluster_ra(clusters = villages,\n                                    n = 15))\n\n## Block and cluster random assignment\ndesign <-\n  model +\n  declare_assignment(Z  = block_and_cluster_ra(\n    blocks = villages,\n    clusters = households,\n    block_m = rep(20, 30)\n  ))\n\n## Block random assignment\ndesign <-\n  model +\n  declare_assignment(Z = block_ra(blocks = gender, m = 100))\n\n## Block random assignment using probabilities\ndesign <-\n  model +\n  declare_assignment(Z = block_ra(blocks = gender,\n                                  block_prob = c(1 / 3, 2 / 3)))\n\n## Factorial assignment\ndesign <-\n  model +\n  declare_assignment(Z1 = complete_ra(N = N, m = 100),\n                     Z2 = block_ra(blocks = Z1))\n\n## Assignment using functions outside of randomizr\ndesign <-\n  model +\n  declare_assignment(Z = rbinom(n = N, size = 1, prob = 0.35))"
  },
  {
    "objectID": "DeclareDesign/reference/cite_design.html#description",
    "href": "DeclareDesign/reference/cite_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nObtain the preferred citation for a design"
  },
  {
    "objectID": "DeclareDesign/reference/cite_design.html#usage",
    "href": "DeclareDesign/reference/cite_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncite_design(design, ...)"
  },
  {
    "objectID": "DeclareDesign/reference/cite_design.html#arguments",
    "href": "DeclareDesign/reference/cite_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\na design object created using the + operator\n\n\n…\noptions for printing the citation if it is a BibTeX entry"
  },
  {
    "objectID": "DeclareDesign/reference/expand_conditions.html#description",
    "href": "DeclareDesign/reference/expand_conditions.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInternal helper to eagerly build assignment conditions for potential outcomes."
  },
  {
    "objectID": "DeclareDesign/reference/expand_conditions.html#usage",
    "href": "DeclareDesign/reference/expand_conditions.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nexpand_conditions(\n  formula,\n  conditions = c(0, 1),\n  assignment_variables = \"Z\",\n  data,\n  level = NULL,\n  label = NULL\n)"
  },
  {
    "objectID": "DeclareDesign/reference/expand_conditions.html#arguments",
    "href": "DeclareDesign/reference/expand_conditions.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nconditions\nthe conditions\n\n\nassignment_variables\nthe name of assignment variables, if conditions is not already named."
  },
  {
    "objectID": "DeclareDesign/reference/expand_conditions.html#details",
    "href": "DeclareDesign/reference/expand_conditions.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nIf conditions is a data.frame, it is returned unchanged\nOtherwise, if conditions is a list, it is passed to expand.grid for expansion to a data.frame\nOtherwise, if condition is something else, box it in a list with assignment_variables for names, and pass that to expand.grid."
  },
  {
    "objectID": "DeclareDesign/reference/expand_conditions.html#value",
    "href": "DeclareDesign/reference/expand_conditions.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na data.frame of potential outcome conditions"
  },
  {
    "objectID": "DeclareDesign/reference/set_diagnosands.html#description",
    "href": "DeclareDesign/reference/set_diagnosands.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nA researcher often has a set of diagnosands in mind to appropriately assess the quality of a design. set_diagnosands sets the default diagnosands for a design, so that later readers can assess the design on the same terms as the original author. Readers can also use diagnose_design to diagnose the design using any other set of diagnosands."
  },
  {
    "objectID": "DeclareDesign/reference/set_diagnosands.html#usage",
    "href": "DeclareDesign/reference/set_diagnosands.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nset_diagnosands(x, diagnosands = default_diagnosands)"
  },
  {
    "objectID": "DeclareDesign/reference/set_diagnosands.html#arguments",
    "href": "DeclareDesign/reference/set_diagnosands.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA design typically created using the + operator, or a simulations data.frame created by simulate_design.\n\n\ndiagnosands\nA set of diagnosands created by declare_diagnosands"
  },
  {
    "objectID": "DeclareDesign/reference/set_diagnosands.html#value",
    "href": "DeclareDesign/reference/set_diagnosands.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na design object with a diagnosand attribute"
  },
  {
    "objectID": "DeclareDesign/reference/set_diagnosands.html#examples",
    "href": "DeclareDesign/reference/set_diagnosands.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <-\ndeclare_model(data = sleep) +\n  declare_inquiry(mean_outcome = mean(extra)) +\n  declare_sampling(S = complete_rs(N, n = 10)) +\n  declare_estimator(extra ~ 1, inquiry = \"mean_outcome\",\n     term = '(Intercept)', .method = lm_robust)\n\ndiagnosands <- declare_diagnosands(\n  median_bias = median(estimate - inquiry))\n\ndesign <- set_diagnosands(design, diagnosands)\n\nlist(\"\\n\", \"diagnose_design(design)\\n\", \"\\n\", \"simulations_df <- simulate_design(design)\\n\", \"\\n\", \"simulations_df <- set_diagnosands(simulations_df, design)\\n\", \"\\n\", \"diagnose_design(simulations_df)\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnose_design(design)\\n\"\n\n[[3]]\n[1] \"\\n\"\n\n[[4]]\n[1] \"simulations_df <- simulate_design(design)\\n\"\n\n[[5]]\n[1] \"\\n\"\n\n[[6]]\n[1] \"simulations_df <- set_diagnosands(simulations_df, design)\\n\"\n\n[[7]]\n[1] \"\\n\"\n\n[[8]]\n[1] \"diagnose_design(simulations_df)\\n\"\n\n[[9]]\n[1] \"\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/run_design.html#description",
    "href": "DeclareDesign/reference/run_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nRun a design one time"
  },
  {
    "objectID": "DeclareDesign/reference/run_design.html#usage",
    "href": "DeclareDesign/reference/run_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nrun_design(design)"
  },
  {
    "objectID": "DeclareDesign/reference/run_design.html#arguments",
    "href": "DeclareDesign/reference/run_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\na DeclareDesign object"
  },
  {
    "objectID": "DeclareDesign/reference/run_design.html#examples",
    "href": "DeclareDesign/reference/run_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <-\n  declare_model(\n    N = 100, X = rnorm(N),\n    potential_outcomes(Y ~ (.25 + X) * Z + rnorm(N))\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N, m = 50)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) + \n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\nrun_design(design)\n\n  inquiry   estimand estimator term  estimate std.error statistic   p.value\n1     ATE 0.09169418 estimator    Z 0.3012257 0.2497031  1.206336 0.2305922\n    conf.low conf.high df outcome\n1 -0.1943019 0.7967533 98       Y"
  },
  {
    "objectID": "DeclareDesign/reference/declare_model.html#description",
    "href": "DeclareDesign/reference/declare_model.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare the size and features of the population"
  },
  {
    "objectID": "DeclareDesign/reference/declare_model.html#usage",
    "href": "DeclareDesign/reference/declare_model.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_model(..., handler = fabricate, label = NULL)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_model.html#arguments",
    "href": "DeclareDesign/reference/declare_model.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step"
  },
  {
    "objectID": "DeclareDesign/reference/declare_model.html#value",
    "href": "DeclareDesign/reference/declare_model.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that returns a data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/declare_model.html#examples",
    "href": "DeclareDesign/reference/declare_model.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# declare_model is usually used when concatenating\n# design elements with `+`\n\n## Example: Two-arm randomized experiment\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ 0.2 * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N = N, m = 250)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\n# declare_model returns a function:\nM <- declare_model(N = 100)\nM()\n\n     ID\n1   001\n2   002\n3   003\n4   004\n5   005\n6   006\n7   007\n8   008\n9   009\n10  010\n11  011\n12  012\n13  013\n14  014\n15  015\n16  016\n17  017\n18  018\n19  019\n20  020\n21  021\n22  022\n23  023\n24  024\n25  025\n26  026\n27  027\n28  028\n29  029\n30  030\n31  031\n32  032\n33  033\n34  034\n35  035\n36  036\n37  037\n38  038\n39  039\n40  040\n41  041\n42  042\n43  043\n44  044\n45  045\n46  046\n47  047\n48  048\n49  049\n50  050\n51  051\n52  052\n53  053\n54  054\n55  055\n56  056\n57  057\n58  058\n59  059\n60  060\n61  061\n62  062\n63  063\n64  064\n65  065\n66  066\n67  067\n68  068\n69  069\n70  070\n71  071\n72  072\n73  073\n74  074\n75  075\n76  076\n77  077\n78  078\n79  079\n80  080\n81  081\n82  082\n83  083\n84  084\n85  085\n86  086\n87  087\n88  088\n89  089\n90  090\n91  091\n92  092\n93  093\n94  094\n95  095\n96  096\n97  097\n98  098\n99  099\n100 100\n\n# Declare a population from existing data\nM <- declare_model(data = mtcars)\n\n# Resample from existing data\nM <- declare_model(N = 100, data = mtcars, handler = resample_data)\n\n# Declare a model with covariates: \n# observed covariates X1 and X2 and \n# unobserved heterogeneity U that each affect \n# outcome Y\nM <- declare_model(\n  N = 100,\n  U = rnorm(N),\n  X1 = rbinom(N, size = 1, prob = 0.5),\n  X2 = X1 + rnorm(N),\n  Y = 0.1 * X1 + 0.2 * X2 + 0.1 * X1 * X2 + U\n)\n\n# We can draw correlated variables using draw_multivariate\nM <-\ndeclare_model(\n  draw_multivariate(c(X1, X2) ~ MASS::mvrnorm(\n    N = 1000,\n    mu = c(0, 0),\n    Sigma = matrix(c(1, 0.3, 0.3, 1), nrow = 2)\n  )))\n  \n# Declare potential outcomes model dependent on assignment Z\n## Manually\nM <- \n  declare_model(N = 100, \n                Y_Z_0 = rbinom(N, size = 1, prob = 0.5),\n                Y_Z_1 = rbinom(N, size = 1, prob = 0.6)\n  )\n\n## Using potential_outcomes\nM <- \n  declare_model(N = 100, \n                potential_outcomes(Y ~ rbinom(N, size = 1, prob = 0.1 * Z + 0.5))\n  )\n  \n \n## we can draw from a distribution of effect sizes \n M <-\ndeclare_model(\n  N = 100, \n  tau = runif(1, min = 0, max = 1), \n  U = rnorm(N), \n  potential_outcomes(Y ~ tau * Z + U)\n)\n\n## we can simulate treatment-by-covariate effect heterogeneity:\nM <- \ndeclare_model(\n  N = 100, \n  U = rnorm(N), \n  X = rbinom(N, 1, prob = 0.5),\n  potential_outcomes(Y ~  0.3 * Z + 0.2*X + 0.1*Z*X + U)\n)\n\n\n## potential outcomes can respond to two treatments:\nM <- declare_model(\n  N = 6,\n  U = rnorm(N),\n  potential_outcomes(Y ~ Z1 + Z2 + U, \n                     conditions = list(Z1 = c(0, 1), Z2 = c(0, 1))))\n\n# Declare a two-level hierarchical population\n# containing varying numbers of individuals within\n# households and an age variable defined at the individual\n# level\nM <- declare_model(\n  households = add_level(\n    N = 100, \n    N_members = sample(c(1, 2, 3, 4), N, \n                       prob = c(0.2, 0.3, 0.25, 0.25), \n                       replace = TRUE)\n  ),\n  individuals = add_level(\n    N = N_members, \n    age = sample(18:90, N, replace = TRUE)\n  )\n)\n\n\n## Panel data have a more complex structure:\nM <- declare_model(\ncountries = add_level(\n  N = 196, \n  country_shock = rnorm(N)\n),\nyears = add_level(\n  N = 100, \n  time_trend = 1:N,\n  year_shock = runif(N, 1, 10), \n  nest = FALSE\n),\nobservation = cross_levels(\n  by = join_using(countries, years),\n  observation_shock = rnorm(N),\n  Y = 0.01 * time_trend + country_shock + year_shock + observation_shock \n)\n)\n\n\n\n\n# Declare a population using a custom function\n# the default handler is fabricatr::fabricate,\n# but you can supply any function that returns a data.frame\nmy_model_function <- function(N) {\n  data.frame(u = rnorm(N))\n}\n\nM <- declare_model(N = 10, handler = my_model_function)"
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#description",
    "href": "DeclareDesign/reference/modify_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nInsert, delete and replace steps in an (already declared) design object."
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#usage",
    "href": "DeclareDesign/reference/modify_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ninsert_step(design, new_step, before, after)\n\ndelete_step(design, step)\n\nreplace_step(design, step, new_step)"
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#arguments",
    "href": "DeclareDesign/reference/modify_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nA design object, usually created using the + operator, expand_design, or the design library.\n\n\nnew_step\nThe new step; Either a function or a partial call.\n\n\nbefore\nThe step before which to add steps.\n\n\nafter\nThe step after which to add steps.\n\n\nstep\nThe quoted label of the step to be deleted or replaced."
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#details",
    "href": "DeclareDesign/reference/modify_design.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nSee modify_design for details."
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#value",
    "href": "DeclareDesign/reference/modify_design.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA new design object."
  },
  {
    "objectID": "DeclareDesign/reference/modify_design.html#examples",
    "href": "DeclareDesign/reference/modify_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n my_model <- \n   declare_model(\n     N = 100, \n     U = rnorm(N),\n     Y_Z_0 = U,\n     Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n   )\n\n my_assignment <- declare_assignment(Z = complete_ra(N, m = 50))\n my_assignment_2 <- declare_assignment(Z = complete_ra(N, m = 25))\n\n design <- my_model + my_assignment\n\n design\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 100, U = rnorm(N), Y_Z_0 = U, Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N, m = 50)) ------------\n\nRun of the design:\n\nError : No estimates or inquiries were declared, so design cannot be simulated.\n\n list(\"\\n\", \" insert_step(design, declare_step(dplyr::mutate, income = noise^2), \\n\", \"             after = my_assignment)\\n\", \" insert_step(design, declare_step(dplyr::mutate, income = noise^2), \\n\", \"             before = my_assignment)\\n\", \" \\n\", \"\\n\", \" # If you are using a design created by a designer, for example from\\n\", \" #   the DesignLibrary package, you will not have access to the step\\n\", \" #   objects. Instead, you can always use the label of the step.\\n\", \" \\n\", \" # get the labels for the steps\\n\", \n    \" names(design)\\n\", \" \\n\", \" insert_step(design, \\n\", \"   declare_sampling(S = complete_rs(N, n = 50), \\n\", \"   legacy = FALSE),\\n\", \"   after = \\\"my_pop\\\")\\n\", \" \")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \" insert_step(design, declare_step(dplyr::mutate, income = noise^2), \\n\"\n\n[[3]]\n[1] \"             after = my_assignment)\\n\"\n\n[[4]]\n[1] \" insert_step(design, declare_step(dplyr::mutate, income = noise^2), \\n\"\n\n[[5]]\n[1] \"             before = my_assignment)\\n\"\n\n[[6]]\n[1] \" \\n\"\n\n[[7]]\n[1] \"\\n\"\n\n[[8]]\n[1] \" # If you are using a design created by a designer, for example from\\n\"\n\n[[9]]\n[1] \" #   the DesignLibrary package, you will not have access to the step\\n\"\n\n[[10]]\n[1] \" #   objects. Instead, you can always use the label of the step.\\n\"\n\n[[11]]\n[1] \" \\n\"\n\n[[12]]\n[1] \" # get the labels for the steps\\n\"\n\n[[13]]\n[1] \" names(design)\\n\"\n\n[[14]]\n[1] \" \\n\"\n\n[[15]]\n[1] \" insert_step(design, \\n\"\n\n[[16]]\n[1] \"   declare_sampling(S = complete_rs(N, n = 50), \\n\"\n\n[[17]]\n[1] \"   legacy = FALSE),\\n\"\n\n[[18]]\n[1] \"   after = \\\"my_pop\\\")\\n\"\n\n[[19]]\n[1] \" \"\n\n delete_step(design, my_assignment)\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 100, U = rnorm(N), Y_Z_0 = U, Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)) \n\nRun of the design:\n\nError : No estimates or inquiries were declared, so design cannot be simulated.\n\n replace_step(design, my_assignment, declare_step(dplyr::mutate, words = \"income\"))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 100, U = rnorm(N), Y_Z_0 = U, Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)) \n\nStep 2 (custom): declare_step(dplyr::mutate, words = \"income\") -----------------\n\nRun of the design:\n\nError : No estimates or inquiries were declared, so design cannot be simulated."
  },
  {
    "objectID": "DeclareDesign/reference/declare_design.html#description",
    "href": "DeclareDesign/reference/declare_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare a design"
  },
  {
    "objectID": "DeclareDesign/reference/declare_design.html#usage",
    "href": "DeclareDesign/reference/declare_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\n+dd(lhs, rhs)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_design.html#arguments",
    "href": "DeclareDesign/reference/declare_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlhs\nA step in a research design, beginning with a function that defines the model. Steps are evaluated sequentially. With the exception of the first step, all steps must be functions that take a data.frame as an argument and return a data.frame. Steps are declared using the declare_ functions, i.e., declare_model, declare_inquiry, declare_sampling, declare_assignment, declare_measurement, declare_estimator, and declare_test.\n\n\nrhs\nA second step in a research design"
  },
  {
    "objectID": "DeclareDesign/reference/declare_design.html#value",
    "href": "DeclareDesign/reference/declare_design.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na design"
  },
  {
    "objectID": "DeclareDesign/reference/declare_design.html#examples",
    "href": "DeclareDesign/reference/declare_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <-\n  declare_model(\n    N = 500, \n    U = rnorm(N),\n    potential_outcomes(Y ~ Z + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N, n = 250)) +\n  declare_assignment(Z = complete_ra(N, m = 25)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\") \n\ndat <- draw_data(design)\nhead(dat)\n\n   ID          U      Y_Z_0      Y_Z_1 S Z          Y\n1 001  0.8911101  0.8911101 1.89111009 1 0  0.8911101\n2 006  0.7591403  0.7591403 1.75914029 1 0  0.7591403\n3 007  0.3428156  0.3428156 1.34281564 1 1  1.3428156\n4 009 -0.9654680 -0.9654680 0.03453204 1 0 -0.9654680\n5 012  0.2354873  0.2354873 1.23548735 1 0  0.2354873\n6 013 -0.1105056 -0.1105056 0.88949442 1 0 -0.1105056\n\nrun_design(design)\n\n  inquiry estimand estimator term estimate std.error statistic      p.value\n1     ATE        1 estimator    Z 1.191338 0.2412547  4.938093 1.450389e-06\n   conf.low conf.high  df outcome\n1 0.7161686  1.666507 248       Y\n\n# You may wish to have a design with only one step:\n\ndesign <- declare_model(N = 500, noise = rnorm(N)) + NULL\n\nlist(\"\\n\", \"diagnosis <- diagnose_design(design)\\n\", \"\\n\", \"summary(diagnosis)\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(design)\\n\"\n\n[[3]]\n[1] \"\\n\"\n\n[[4]]\n[1] \"summary(diagnosis)\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/index.html",
    "href": "DeclareDesign/reference/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\ndeclare_model()\nDeclare the size and features of the population\n\n\ndeclare_inquiry() declare_inquiries() declare_estimand() declare_estimands() inquiry_handler()\nDeclare inquiry\n\n\ndeclare_inquiry() declare_inquiries() declare_estimand() declare_estimands() inquiry_handler()\nDeclare inquiry\n\n\ndeclare_sampling() sampling_handler()\nDeclare sampling procedure\n\n\ndeclare_assignment() assignment_handler()\nDeclare Data Strategy: Assignment\n\n\ndeclare_measurement() measurement_handler()\nDeclare measurement procedure\n\n\ndeclare_estimator() declare_estimators() label_estimator() method_handler()\nDeclare estimator\n\n\ndeclare_estimator() declare_estimators() label_estimator() method_handler()\nDeclare estimator\n\n\ndeclare_test() label_test()\nDeclare test\n\n\ndeclare_step()\nDeclare a custom step\n\n\nset_citation()\nSet the citation of a design\n\n\ndeclare_estimator() declare_estimators() label_estimator() method_handler()\nDeclare estimator\n\n\ndeclare_test() label_test()\nDeclare test\n\n\ntidy_try()\nTidy Model Results and Filter to Relevant Coefficients\n\n\n+(<dd>)\nDeclare a design"
  },
  {
    "objectID": "DeclareDesign/reference/index.html#post-declaration-functions",
    "href": "DeclareDesign/reference/index.html#post-declaration-functions",
    "title": "**Declare**Design",
    "section": "Post-declaration functions",
    "text": "Post-declaration functions\n\n\n\nFunction(s)\nDescription\n\n\n\n\ncite_design()\nObtain the preferred citation for a design\n\n\ndraw_data() draw_estimand() draw_estimands() draw_estimates()\nDraw data, estimates, and inquiries from a design\n\n\ndraw_data() draw_estimand() draw_estimands() draw_estimates()\nDraw data, estimates, and inquiries from a design\n\n\ndraw_data() draw_estimand() draw_estimands() draw_estimates()\nDraw data, estimates, and inquiries from a design\n\n\nrun_design()\nRun a design one time\n\n\nget_estimates()\nGet estimates, inquiries, assignment vectors, or samples from a design given data\n\n\nprint_code() print(<design>) summary(<design>)\nExplore your design\n\n\nprint_code() print(<design>) summary(<design>)\nExplore your design\n\n\nprint_code() print(<design>) summary(<design>)\nExplore your design"
  },
  {
    "objectID": "DeclareDesign/reference/index.html#diagnose",
    "href": "DeclareDesign/reference/index.html#diagnose",
    "title": "**Declare**Design",
    "section": "Diagnose",
    "text": "Diagnose\n\n\n\nFunction(s)\nDescription\n\n\n\n\ndiagnosand_handler() declare_diagnosands()\nDeclare diagnosands\n\n\ndiagnose_design() diagnose_designs() vars()\nDiagnose the design\n\n\ndiagnose_design() diagnose_designs() vars()\nDiagnose the design\n\n\nget_diagnosands() get_simulations()\nExplore your design diagnosis\n\n\nget_diagnosands() get_simulations()\nExplore your design diagnosis\n\n\nsimulate_design() simulate_designs()\nSimulate a design\n\n\nsimulate_design() simulate_designs()\nSimulate a design\n\n\nset_diagnosands()\nSet the diagnosands for a design\n\n\nreshape_diagnosis()\nClean up a diagnosis object for printing\n\n\ntidy(<diagnosis>)\nTidy diagnosis\n\n\npop.var()\nPopulation variance function"
  },
  {
    "objectID": "DeclareDesign/reference/index.html#redesign",
    "href": "DeclareDesign/reference/index.html#redesign",
    "title": "**Declare**Design",
    "section": "Redesign",
    "text": "Redesign\n\n\n\nFunction(s)\nDescription\n\n\n\n\ninsert_step() delete_step() replace_step()\nModify a design after the fact\n\n\ninsert_step() delete_step() replace_step()\nModify a design after the fact\n\n\ninsert_step() delete_step() replace_step()\nModify a design after the fact\n\n\nexpand_design()\nDeclare a design via a designer\n\n\nredesign()\nRedesign"
  },
  {
    "objectID": "DeclareDesign/reference/index.html#comparison",
    "href": "DeclareDesign/reference/index.html#comparison",
    "title": "**Declare**Design",
    "section": "Comparison",
    "text": "Comparison\n\n\n\nFunction(s)\nDescription\n\n\n\n\ncompare_diagnoses()\nCompare Diagnoses\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs\n\n\ncompare_designs() compare_design_code() compare_design_summaries() compare_design_data() compare_design_estimates() compare_design_inquiries()\nCompare two designs"
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#description",
    "href": "DeclareDesign/reference/redesign.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nredesign quickly generates a design from an existing one by resetting symbols used in design handler parameters in a step’s environment (Advanced)."
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#usage",
    "href": "DeclareDesign/reference/redesign.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nredesign(design, ..., expand = TRUE)"
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#arguments",
    "href": "DeclareDesign/reference/redesign.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nAn object of class design.\n\n\n…\nArguments to redesign e.g., n = 100. If redesigning multiple arguments, they must be specified as a named list.\n\n\nexpand\nIf TRUE, redesign using the crossproduct of ..., otherwise recycle them."
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#details",
    "href": "DeclareDesign/reference/redesign.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nWarning: redesign will edit any symbol in your design, but if the symbol you attempt to change does not exist in a step’s environment no changes will be made and no error or warning will be issued.\nPlease note that redesign functionality is experimental and may be changed in future versions."
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#value",
    "href": "DeclareDesign/reference/redesign.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA design, or, in the case of multiple values being passed onto ..., a by-list of designs."
  },
  {
    "objectID": "DeclareDesign/reference/redesign.html#examples",
    "href": "DeclareDesign/reference/redesign.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nn <- 500\npopulation <- declare_model(N = 1000)\nsampling <- declare_sampling(S = complete_rs(N, n = n), \n                             legacy = FALSE)\ndesign <- population + sampling\n\n# returns a single, modified design\nmodified_design <- redesign(design, n = 200)\n\n# returns a list of six modified designs\ndesign_vary_N <- redesign(design, n = seq(400, 900, 100))\n\n# When redesigning with arguments that are vectors,\n# use list() in redesign, with each list item\n# representing a design you wish to create\n\nprob_each <- c(.1, .5, .4)\n\nassignment <- declare_assignment(\n  Z = complete_ra(prob_each = prob_each), \n  legacy = FALSE)\n\ndesign <- population + assignment\n\n# returns two designs\n\ndesigns_vary_prob_each <- redesign(\n  design,\n  prob_each = list(c(.2, .5, .3), c(0, .5, .5)))\n\n\n# To illustrate what does and does not get edited by redesign, \n# consider the following three designs. In the first two, argument\n# X is called from the step's environment; in the third it is not.\n# Using redesign will alter the role of X in the first two designs\n# but not the third one.\n\nX <- 3\nf <- function(b, X) b*X\ng <- function(b) b*X\n\ndesign1 <- declare_model(N = 1, A = X)       + NULL\ndesign2 <- declare_model(N = 1, A = f(2, X)) + NULL\ndesign3 <- declare_model(N = 1, A = g(2))    + NULL\n\ndraw_data(design1)\n\n  ID A\n1  1 3\n\ndraw_data(design2)\n\n  ID A\n1  1 6\n\ndraw_data(design3)\n\n  ID A\n1  1 6\n\ndraw_data(redesign(design1, X=0))\n\n  ID A\n1  1 0\n\ndraw_data(redesign(design2, X=0))\n\n  ID A\n1  1 0\n\ndraw_data(redesign(design3, X=0))\n\n  ID A\n1  1 6"
  },
  {
    "objectID": "DeclareDesign/reference/declare_reveal.html#description",
    "href": "DeclareDesign/reference/declare_reveal.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeprecated. Please use the reveal_outcomes function within a declare_measurement declaration."
  },
  {
    "objectID": "DeclareDesign/reference/declare_reveal.html#usage",
    "href": "DeclareDesign/reference/declare_reveal.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_reveal(..., handler = declare_reveal_handler, label = NULL)\n\ndeclare_reveal_handler(\n  data = NULL,\n  outcome_variables = Y,\n  assignment_variables = Z,\n  attrition_variables = NULL,\n  ...\n)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_reveal.html#arguments",
    "href": "DeclareDesign/reference/declare_reveal.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\ndata\nA data.frame containing columns for assignment and potential outcomes.\n\n\noutcome_variables\nThe outcome prefix(es) of the potential outcomes.\n\n\nassignment_variables\nUnquoted name(s) of the assignment variable(s).\n\n\nattrition_variables\nUnquoted name of the attrition variable."
  },
  {
    "objectID": "DeclareDesign/reference/declare_reveal.html#details",
    "href": "DeclareDesign/reference/declare_reveal.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nPotential outcomes declarations indicate what outcomes would obtain for different possible values of assignment variables. But realized outcomes need to be “revealed.” declare_reveal generates these realized outcomes using information on potential outcomes (for instance generated via declare_potential_outcomes) and the relevant assignment variables (for example created by declare_assignment). Revelation steps are usefully included after declaration of all assignments of conditions required to determine the realized outcome. If a revelation is not declared, DeclareDesign will try to guess appropriate revelations. Explicit revelation is recommended however.\ndeclare_reveal declares how outcomes should be realized.\nA “revelation” uses the random assignment to pluck out the correct potential outcomes (Gerber and Green 2012, Chapter 2). Revelation requires that every named outcome variable is a function of every named assignment variable within a step. Thus if multiple outcome variables depend on different assignment variables, multiple revelations are needed."
  },
  {
    "objectID": "DeclareDesign/reference/declare_reveal.html#examples",
    "href": "DeclareDesign/reference/declare_reveal.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 100, \n    U = rnorm(N), \n    Y_Z_0 = U, \n    Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)\n  ) + \n  declare_assignment(Z = complete_ra(N, m = 50)) + \n  declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# Declaring multiple assignment variables or multiple outcome variables\n\ndesign   <- \n  declare_model(\n    N = 10,\n    potential_outcomes(Y1 ~ Z),\n    potential_outcomes(Y2 ~ 1 + 2 * Z),\n    potential_outcomes(Y3 ~ 1 - X * Z, conditions = list(X = 0:1, Z = 0:1))\n  ) + \n  declare_assignment(Z = complete_ra(N)) + \n  declare_assignment(X = complete_ra(N)) + \n  declare_measurement(Y1 = reveal_outcomes(Y1 ~ Z), \n                      Y2 = reveal_outcomes(Y2 ~ Z),\n                      Y3 = reveal_outcomes(Y3 ~ X + Z))\n\ndesign <- \n  declare_model(\n    N = 100, \n    age = sample(18:95, N, replace = TRUE),\n    potential_outcomes(Y ~ .25 * Z + .01 * age * Z),\n    potential_outcomes(R ~ rbinom(n = N, size = 1, prob = pnorm(Y_Z_0)))\n  ) + \n  declare_assignment(Z = complete_ra(N, m = 25))\n  declare_measurement(R = reveal_outcomes(R ~ Z),\n                      Y = reveal_outcomes(Y ~ Z),\n                      Y = ifelse(R == 1, Y, NA))\n\ndeclare_measurement(R = reveal_outcomes(R ~ Z), Y = reveal_outcomes(Y ~ \n    Z), Y = ifelse(R == 1, Y, NA))"
  },
  {
    "objectID": "DeclareDesign/reference/draw_functions.html#description",
    "href": "DeclareDesign/reference/draw_functions.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDraw data, estimates, and inquiries from a design"
  },
  {
    "objectID": "DeclareDesign/reference/draw_functions.html#usage",
    "href": "DeclareDesign/reference/draw_functions.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_data(design, data = NULL, start = 1, end = length(design))\n\ndraw_estimand(...)\n\ndraw_estimands(...)\n\ndraw_estimates(...)"
  },
  {
    "objectID": "DeclareDesign/reference/draw_functions.html#arguments",
    "href": "DeclareDesign/reference/draw_functions.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign\nA design object, typically created using the + operator\n\n\ndata\nA data.frame object with sufficient information to get the data, estimates, inquiries, an assignment vector, or a sample.\n\n\nstart\n(Defaults to 1) a scalar indicating which step in the design to begin with. By default all data steps are drawn, from step 1 to the last step of the design.\n\n\nend\n(Defaults to length(design)) a scalar indicating which step in the design to finish drawing data by.\n\n\n…\nA design or set of designs typically created using the + operator"
  },
  {
    "objectID": "DeclareDesign/reference/draw_functions.html#examples",
    "href": "DeclareDesign/reference/draw_functions.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign <- \n  declare_model(\n    N = 100, \n    U = rnorm(N),\n    potential_outcomes(Y ~ Z + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N, n = 75)) +\n  declare_assignment(Z = complete_ra(N, m = 50)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\ndat <- draw_data(design)\n\ndat_no_sampling <- draw_data(design, end = 3)\n\ndraw_estimands(design)\n\n  inquiry estimand\n1     ATE        1\n\ndraw_estimates(design)\n\n  estimator term  estimate std.error statistic    p.value  conf.low conf.high\n1 estimator    Z 0.7387191 0.2404754  3.071911 0.00298815 0.2594523  1.217986\n  df outcome inquiry\n1 73       Y     ATE"
  },
  {
    "objectID": "DeclareDesign/reference/edit.html#description",
    "href": "DeclareDesign/reference/edit.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nOverride environment via shim"
  },
  {
    "objectID": "DeclareDesign/reference/edit.html#usage",
    "href": "DeclareDesign/reference/edit.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nclone_dot_edit_env(dot, ..., to_replace = list(...))\n\nclone_step_edit(step, ..., to_replace = list(...))\n\nclone_design_edit(design, ..., to_replace = list(...))"
  },
  {
    "objectID": "DeclareDesign/reference/edit.html#examples",
    "href": "DeclareDesign/reference/edit.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nlist(\"\\n\", \"here_i_am <- \\\"foo\\\"\\n\", \"dot <- quo(here_i_am)\\n\", \"dot2 <- clone_dot_edit_env(dot, here_i_am = \\\"some_message\\\", xyxyx = \\\"bar\\\")\\n\", \"eval_tidy(dot)\\n\", \"eval_tidy(dot2)\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"here_i_am <- \\\"foo\\\"\\n\"\n\n[[3]]\n[1] \"dot <- quo(here_i_am)\\n\"\n\n[[4]]\n[1] \"dot2 <- clone_dot_edit_env(dot, here_i_am = \\\"some_message\\\", xyxyx = \\\"bar\\\")\\n\"\n\n[[5]]\n[1] \"eval_tidy(dot)\\n\"\n\n[[6]]\n[1] \"eval_tidy(dot2)\\n\"\n\nlist(\"\\n\", \"N <- 50\\n\", \"\\n\", \"pop50 <- declare_model(N=N, noise=rnorm(N))\\n\", \"nrow(pop50())\\n\", \"\\n\", \"pop100 <- DeclareDesign:::clone_step_edit(pop50, N=100)\\n\", \"nrow(pop100())\\n\", \"nrow(pop50())\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"N <- 50\\n\"\n\n[[3]]\n[1] \"\\n\"\n\n[[4]]\n[1] \"pop50 <- declare_model(N=N, noise=rnorm(N))\\n\"\n\n[[5]]\n[1] \"nrow(pop50())\\n\"\n\n[[6]]\n[1] \"\\n\"\n\n[[7]]\n[1] \"pop100 <- DeclareDesign:::clone_step_edit(pop50, N=100)\\n\"\n\n[[8]]\n[1] \"nrow(pop100())\\n\"\n\n[[9]]\n[1] \"nrow(pop50())\\n\"\n\n[[10]]\n[1] \"\\n\"\n\nN <- 50\n\nlist(\"\\n\", \"\\n\", \"my_design <- declare_model(N=N, noise=rnorm(N)) + NULL\\n\", \"my_design2 <- DeclareDesign:::clone_design_edit(my_design, N=100)\\n\", \"\\n\", \"nrow(draw_data(my_design))\\n\", \"nrow(draw_data(my_design2))\\n\", \"\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"\\n\"\n\n[[3]]\n[1] \"my_design <- declare_model(N=N, noise=rnorm(N)) + NULL\\n\"\n\n[[4]]\n[1] \"my_design2 <- DeclareDesign:::clone_design_edit(my_design, N=100)\\n\"\n\n[[5]]\n[1] \"\\n\"\n\n[[6]]\n[1] \"nrow(draw_data(my_design))\\n\"\n\n[[7]]\n[1] \"nrow(draw_data(my_design2))\\n\"\n\n[[8]]\n[1] \"\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#description",
    "href": "DeclareDesign/reference/declare_measurement.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThis function adds measured data columns that can be functions of unmeasured data columns."
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#usage",
    "href": "DeclareDesign/reference/declare_measurement.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_measurement(..., handler = measurement_handler, label = NULL)\n\nmeasurement_handler(data, ...)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#arguments",
    "href": "DeclareDesign/reference/declare_measurement.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\ndata\nA data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#details",
    "href": "DeclareDesign/reference/declare_measurement.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nIt is also possible to include measured variables in your declare_model call or to add variables using declare_step. However, putting latent variables in declare_model and variables-as-measured in declare_measurement helps communicate which parts of your research design are in M and which parts are in D."
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#value",
    "href": "DeclareDesign/reference/declare_measurement.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that returns a data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/declare_measurement.html#examples",
    "href": "DeclareDesign/reference/declare_measurement.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# declare_measurement in use\n## Two-arm randomized experiment\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ 0.2 * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N = N, n = 200)) +\n  declare_assignment(Z = complete_ra(N = N, m = 100)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\n# Reveal potential outcomes according to treatment assignment\ndesign <-\n  declare_model(N = 100,\n                potential_outcomes(Y ~ rbinom(\n                  N, size = 1, prob = 0.1 * Z + 0.5\n                ))) +\n  declare_assignment(Z = complete_ra(N, m = 50)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# Generate observed measurement from a latent value\ndesign <- \n  declare_model(N = 100, latent = runif(N)) +\n  declare_measurement(observed = rbinom(N, 1, prob = latent))\n\n# Index creation\nlibrary(psych)\n\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    Y_1 = 0.2 * X + rnorm(N, sd = 0.25),\n    Y_2 = 0.3 * X + 0.5 * rnorm(N, sd = 0.50),\n    Y_3 = 0.1 * X + 0.4 * rnorm(N, sd = 0.75)) +\n  declare_measurement(\n    index = fa(\n      r = cbind(Y_1, Y_2, Y_3),\n      nfactors = 1,\n      rotate = \"varimax\"\n    )$scores\n  )\n\ndraw_data(design)\n\n     ID X          Y_1          Y_2          Y_3           MR1\n1   001 0 -0.163694858  0.125646692  0.319006832 -0.4469170006\n2   002 0 -0.315354484  0.283813089 -0.002632932 -0.6257969722\n3   003 0 -0.011716603  0.280239096  0.021550507 -0.0688814861\n4   004 0 -0.147267947 -0.082370328  0.350502303 -0.6104072929\n5   005 0  0.403007947 -0.089369831  0.041860569  0.3413542850\n6   006 0  0.021878159  0.151765883  0.447840328 -0.0610630397\n7   007 0 -0.118545475  0.285523111 -0.293000645 -0.3104883358\n8   008 0 -0.107908994  0.022905854 -0.555991022 -0.5843848118\n9   009 0  0.029131082  0.210356047 -0.346981376 -0.1204003083\n10  010 0  0.337569133  0.226622670  0.079846308  0.5294044331\n11  011 0 -0.083664706 -0.044164105 -0.146259418 -0.5377304820\n12  012 0 -0.013241860 -0.327253058 -0.301216826 -0.7041438071\n13  013 0  0.386630876 -0.046834619 -0.041365338  0.3385061693\n14  014 0  0.083315881  0.112437935 -0.592001141 -0.1542741387\n15  015 0  0.137725194  0.253563330 -0.042302280  0.1691608101\n16  016 0 -0.074992668 -0.026542930  0.154226794 -0.4563936490\n17  017 0 -0.484357466 -0.098214075 -0.154334255 -1.3249326871\n18  018 0  0.113379520  0.274546721 -0.602368690  0.0539789211\n19  019 0 -0.199564069 -0.352415298 -0.024730514 -1.0248816479\n20  020 0 -0.327142269 -0.060979621 -0.318106562 -1.0277671306\n21  021 0 -0.143797965  0.045161127  0.480616990 -0.4611857550\n22  022 0 -0.146312571  0.093258470 -0.236483379 -0.5358700754\n23  023 0  0.115832631 -0.265815256  0.513329651 -0.2771501501\n24  024 0 -0.270992228 -0.132429247 -0.473867590 -1.0183173974\n25  025 0 -0.405036325  0.182245789  0.150116769 -0.8624386282\n26  026 0  0.006630824  0.253296440 -0.193168598 -0.0957326728\n27  027 0 -0.353999165 -0.145392262 -0.367576788 -1.1656130037\n28  028 0 -0.266901190 -0.234154581 -0.190194780 -1.0620896293\n29  029 0 -0.019884126 -0.002218228  0.249896522 -0.3166953818\n30  030 0  0.304236760  0.087315932  0.230732127  0.3596747225\n31  031 0 -0.126543964 -0.274303744  0.100299688 -0.7962356334\n32  032 0 -0.374091904  0.226430593 -0.112313884 -0.8059872376\n33  033 0 -0.241662644  0.094647567  0.252120805 -0.6302231535\n34  034 0  0.158804180  0.214476924 -0.084852498  0.1635705400\n35  035 0 -0.251389139 -0.056770432  0.135352821 -0.8115657613\n36  036 0  0.542780705  0.106269022  0.203657711  0.8105295438\n37  037 0  0.012521405  0.107547987 -0.041555290 -0.1996214154\n38  038 0  0.298510089 -0.181253433  0.081982317  0.0685900798\n39  039 0  0.028211310 -0.022332107  0.501665290 -0.2070396901\n40  040 0  0.323936397  0.136820755 -0.198397874  0.3736318888\n41  041 0  0.021363679  0.131024491  0.028854626 -0.1496029595\n42  042 0 -0.187156222 -0.430397220 -0.148728165 -1.0966900036\n43  043 0  0.031630875 -0.428307959  0.049723404 -0.6616602689\n44  044 0  0.356827730 -0.148456480 -0.578606219  0.0999094972\n45  045 0  0.438713613  0.102171838  0.078014113  0.5955857301\n46  046 0  0.031353158 -0.178386259 -0.211014560 -0.4656393447\n47  047 0  0.188014306 -0.308115881  0.068433895 -0.2572585556\n48  048 0  0.398719708 -0.300697270  0.328404774  0.1780047632\n49  049 0 -0.366265286  0.193541819  0.195120769 -0.7733202216\n50  050 0 -0.027917751  0.211971916  0.154759548 -0.1422243946\n51  051 0  0.014511549  0.148109109  0.174570792 -0.1222662616\n52  052 0  0.147731026  0.137910120  0.003403186  0.0844244557\n53  053 0 -0.434613280 -0.641576823  0.399929949 -1.6630990764\n54  054 0  0.086893309 -0.478546157  0.364361249 -0.5574730667\n55  055 0  0.211397599  0.048466126  0.114784136  0.1336806310\n56  056 0  0.326485415  0.068407264 -0.328663928  0.2918824018\n57  057 0  0.017893475 -0.143804592 -0.238650648 -0.4617445577\n58  058 0 -0.382677076 -0.216501224 -0.450348316 -1.2994765109\n59  059 0 -0.378728386  0.030090139 -0.386585243 -1.0463920267\n60  060 0 -0.069922661  0.104621226 -0.356194604 -0.4043999022\n61  061 0  0.469055831  0.057198925 -0.884469308  0.4525157212\n62  062 0 -0.171764491  0.272030788 -0.571040211 -0.4658823078\n63  063 0  0.008455333 -0.113295256  0.345943484 -0.3553198551\n64  064 0 -0.030054693 -0.046223232 -0.012929002 -0.4198859085\n65  065 0  0.151874172 -0.473517777  0.521221297 -0.4082149844\n66  066 0 -0.047185522 -0.042672132  0.411909875 -0.3791534350\n67  067 0  0.133752307  0.045475061 -0.293561281 -0.0775258340\n68  068 0  0.090187136 -0.095956540  0.229491512 -0.2078254022\n69  069 0  0.053432609  0.077144014 -0.310634945 -0.1972253166\n70  070 0  0.102038215  0.354750593 -0.661427582  0.1002480736\n71  071 0 -0.160686523  0.015100398  0.438558314 -0.5276511518\n72  072 0 -0.092326922  0.293301330  0.521492478 -0.1232400266\n73  073 0  0.087924309  0.295364931  0.295717453  0.1725143664\n74  074 0 -0.034095698 -0.016692981  0.028508657 -0.3923811126\n75  075 0 -0.279326367 -0.129277554  0.265936263 -0.9108896264\n76  076 0  0.158426706  0.466599641 -0.349006938  0.3609582285\n77  077 0 -0.050198924 -0.154432208  0.241358793 -0.5190162380\n78  078 0 -0.239217989 -0.148341987 -0.414231342 -0.9656418886\n79  079 0 -0.072256745 -0.167117791  0.322852810 -0.5583693176\n80  080 0  0.072203503  0.049703461  0.225798992 -0.1022501937\n81  081 0 -0.325761321  0.095253016  0.366345694 -0.7652757888\n82  082 0 -0.243231199  0.117583941  0.315943328 -0.6008642043\n83  083 0  0.144250987  0.097485853 -0.059091204  0.0293252074\n84  084 0  0.134762048 -0.111572149 -0.048461264 -0.1860259444\n85  085 0 -0.070591909  0.081692440 -0.428362861 -0.4392026022\n86  086 0 -0.171415670  0.027073617  0.417402624 -0.5392987520\n87  087 0 -0.444526779 -0.226194150  0.133906964 -1.3275501812\n88  088 0  0.160367606 -0.106118114 -0.398232283 -0.1904822730\n89  089 0 -0.302024698  0.221834065  0.040571749 -0.6535796937\n90  090 0 -0.032181946 -0.125378838 -0.120504108 -0.5167939598\n91  091 0 -0.160149509  0.357776028  0.423034602 -0.2018708351\n92  092 0  0.111475832  0.137377701  0.319474742  0.0686141227\n93  093 0  0.233511176 -0.271618454  0.339841847 -0.0951149228\n94  094 0  0.070653075 -0.089013191 -0.293416766 -0.3215887414\n95  095 0 -0.022450500 -0.079226812 -0.036340476 -0.4412623381\n96  096 0  0.154457628 -0.322947452  0.121430143 -0.3243435800\n97  097 0 -0.151595212 -0.114623886 -0.019172103 -0.7089521605\n98  098 0 -0.152152929  0.251657680 -0.377000139 -0.4180106219\n99  099 0  0.105118061 -0.298361722  0.152118502 -0.3863102964\n100 100 0  0.099562898 -0.003302651 -0.114308164 -0.1577675399\n101 101 0  0.033775024  0.047419120  0.104287294 -0.1945111718\n102 102 0 -0.246831006  0.168332451  0.340501230 -0.5550151288\n103 103 0 -0.318035954 -0.130960542 -0.297083363 -1.0745210517\n104 104 0  0.144342476 -0.031618227 -0.283731802 -0.1301649761\n105 105 0  0.118965755  0.306208115 -0.226945717  0.1551952806\n106 106 0  0.134337824 -0.553423873 -0.260977047 -0.6432214895\n107 107 0  0.258913298  0.088199279 -0.134443159  0.2183830086\n108 108 0 -0.342679816  0.080665197  0.014091037 -0.8672023402\n109 109 0 -0.228117459  0.049997724 -0.264991837 -0.7317105040\n110 110 0  0.187263306 -0.190185686  0.338671120 -0.1022728130\n111 111 0 -0.229023422 -0.013333240 -0.278861861 -0.7961054327\n112 112 0  0.106316618 -0.018363550 -0.167687231 -0.1684127834\n113 113 0 -0.194496271  0.052501757 -0.496963331 -0.7052376015\n114 114 0  0.006130135 -0.522896699 -0.066669676 -0.8175678844\n115 115 0 -0.060645787 -0.080381941  0.330076312 -0.4530775351\n116 116 0  0.156622854 -0.011599397 -0.298670252 -0.0909569508\n117 117 0 -0.404720944  0.287044269  0.178032729 -0.7572456753\n118 118 0 -0.048482939 -0.139360643 -0.305916757 -0.5900174374\n119 119 0  0.180115271 -0.124162935 -0.086482832 -0.1210936062\n120 120 0  0.471981206  0.026752733 -0.249195827  0.5315739019\n121 121 0  0.552429145  0.152938297 -0.169128727  0.8124750884\n122 122 0  0.227132634 -0.061779445  0.037359018  0.0446873937\n123 123 0 -0.012377364 -0.181356033  0.123681958 -0.4944630165\n124 124 0  0.411899666 -0.046003791 -0.018583368  0.3892906128\n125 125 0  0.426244596  0.077846925 -0.302889713  0.4878774068\n126 126 0  0.239652901 -0.246446080  0.320574428 -0.0629339255\n127 127 0  0.258544744 -0.241608585 -0.205432194 -0.1087944455\n128 128 0  0.080137774  0.175934966 -0.347201933 -0.0598435955\n129 129 0  0.170478498  0.165901939  0.378091325  0.2134649040\n130 130 0  0.052536373 -0.006254470  0.278185592 -0.1832632190\n131 131 0  0.235636838  0.088743162 -0.063655454  0.1877008124\n132 132 0  0.154608699  0.265193155 -0.397798170  0.1536939345\n133 133 0 -0.180145752  0.151295429 -0.246714943 -0.5440905361\n134 134 0  0.001120191  0.228189500  0.285997647 -0.0522896077\n135 135 0  0.363825271  0.266027125  0.206031107  0.6355710259\n136 136 0 -0.062942155  0.247222884 -0.005112020 -0.1986015104\n137 137 0 -0.044017982  0.218476277  0.334521093 -0.1364325595\n138 138 0 -0.401295172 -0.206809606  0.105817600 -1.2343574754\n139 139 0  0.183250238  0.337020437  0.070292035  0.3505159762\n140 140 0 -0.214151416  0.084067930 -0.353266778 -0.6878570796\n141 141 0  0.038230554  0.137920850  0.242470894 -0.0775472439\n142 142 0 -0.574086580  0.129286281 -0.116161395 -1.2658878236\n143 143 0  0.098734371 -0.091237944 -0.422785240 -0.2931847022\n144 144 0 -0.153797774 -0.395907635  0.173223824 -0.9505305293\n145 145 0 -0.068240205  0.003732048  0.431882666 -0.3701817412\n146 146 0 -0.043520359  0.149079128 -0.026190204 -0.2601635359\n147 147 0 -0.115561411 -0.134059927 -0.045038113 -0.6656693413\n148 148 0 -0.106740668  0.264871972  0.083191437 -0.2477184944\n149 149 0 -0.002983469 -0.085606638  0.329801674 -0.3524461104\n150 150 0 -0.375345390 -0.250673494  0.448862410 -1.1732014463\n151 151 0 -0.108679645 -0.404788049  0.143369562 -0.8811636732\n152 152 0 -0.014408371  0.203822814 -0.309051657 -0.2002901416\n153 153 0 -0.046192187  0.072251743  0.246275740 -0.2943604787\n154 154 0 -0.211802754 -0.035484126  0.025534593 -0.7364590206\n155 155 0 -0.159538924 -0.045364387 -0.051943416 -0.6626575134\n156 156 0 -0.111540991 -0.416741501 -0.036333487 -0.9268978669\n157 157 0  0.196757708 -0.021727241  0.314967374  0.0721943933\n158 158 0  0.114417049  0.012551048 -0.300018244 -0.1454498316\n159 159 0 -0.011380228 -0.343991367  0.091154163 -0.6532399713\n160 160 0  0.404397596 -0.167844668 -0.326809036  0.2092998229\n161 161 0 -0.136934190  0.181649361  0.002181707 -0.3956447192\n162 162 0 -0.355921852 -0.240083205 -0.359685620 -1.2583040144\n163 163 0  0.064855516 -0.523110364  0.249453780 -0.6590133830\n164 164 0 -0.153389122  0.053338573 -0.068126581 -0.5597297467\n165 165 0 -0.158320508 -0.059473488 -0.110904424 -0.6834401719\n166 166 0  0.019655442 -0.453405986  0.670594339 -0.6071296388\n167 167 0  0.016519905 -0.081275339  0.046221349 -0.3584483688\n168 168 0 -0.303553123  0.152792247  0.087655656 -0.7147085458\n169 169 0 -0.097521318  0.448926215 -0.095882954 -0.0839957019\n170 170 0  0.140641512  0.169549403  0.024599370  0.1050825222\n171 171 0  0.647001230  0.580757841 -0.076523415  1.4093939740\n172 172 0 -0.294556312  0.335864141  0.128066745 -0.5168222244\n173 173 0 -0.533849479  0.172326558  0.423902162 -1.0636686422\n174 174 0  0.103937723 -0.587815336 -0.374403438 -0.7501295943\n175 175 0  0.009816331 -0.450639727  0.413580925 -0.6640987285\n176 176 0 -0.240777340 -0.380936928 -0.263699069 -1.1663092408\n177 177 0 -0.139300354  0.546079642 -0.328791632 -0.1054407142\n178 178 0 -0.287068517 -0.208080211 -0.026270070 -1.0476205672\n179 179 0 -0.214642118 -0.092523949  0.140941005 -0.7774728170\n180 180 0  0.171886332 -0.219926892 -0.181692312 -0.2430459390\n181 181 0  0.099548764 -0.187425658  0.529371731 -0.2295208860\n182 182 0  0.240258039  0.235811414  0.085003784  0.3606928402\n183 183 0  0.389655920 -0.003062065 -0.126990825  0.3720060789\n184 184 0  0.156441153 -0.504257692 -0.278373978 -0.5585704575\n185 185 0 -0.220625860 -0.024038604 -0.092687871 -0.7608218549\n186 186 0 -0.224511790  0.181515879  0.162136503 -0.5303798262\n187 187 0  0.039511253 -0.131018093  0.000265320 -0.3712636927\n188 188 0  0.016150319  0.106738483  0.043262901 -0.1800222515\n189 189 0  0.008603336  0.044814363 -0.461622257 -0.3346823658\n190 190 0  0.506086501  0.246785838 -0.072749505  0.8327837299\n191 191 0  0.121138392 -0.200005000 -0.323567897 -0.3399665728\n192 192 0 -0.191143567 -0.142868700  0.018170073 -0.8023612476\n193 193 0  0.159779710  0.094325289 -0.191075933  0.0334095299\n194 194 0 -0.050702181  0.197796029 -0.147002914 -0.2463378999\n195 195 0 -0.014591005 -0.025872597  0.317222884 -0.3186968342\n196 196 0  0.448163823 -0.062966236  0.036015215  0.4483762493\n197 197 0 -0.091603653  0.375012494  0.148462584 -0.1042188788\n198 198 0 -0.487579521 -0.257819802  0.004635182 -1.4575660456\n199 199 0 -0.001692214 -0.241917227 -0.443861045 -0.6245480776\n200 200 0 -0.069679179  0.124986552 -0.245969383 -0.3666688419\n201 201 0 -0.353514350  0.096073559  0.357774200 -0.8167362398\n202 202 0  0.194622063  0.092360686  0.102833480  0.1429320346\n203 203 0  0.272794771  0.206134003  0.212427248  0.4125852534\n204 204 0  0.060590451 -0.039215779 -0.182350223 -0.2744953597\n205 205 0 -0.564616587 -0.322064334 -0.474123827 -1.7375563023\n206 206 0  0.344311692  0.339001700  0.245529895  0.6759046234\n207 207 0 -0.292198285 -0.073804578  0.113465601 -0.9061598159\n208 208 0  0.544842481 -0.068806687  0.346443383  0.6701843031\n209 209 0  0.415284148 -0.152625228 -0.085305422  0.2828581861\n210 210 0 -0.373240737 -0.023641439  0.261061342 -0.9828777960\n211 211 0  0.149389816 -0.412535638 -0.082166011 -0.4521397599\n212 212 0  0.452502291 -0.216466010  0.085295014  0.3176834529\n213 213 0  0.183102571 -0.110433459 -0.040938982 -0.0951372747\n214 214 0 -0.083935986  0.119107754 -0.549095829 -0.4474511497\n215 215 0  0.077850293  0.164717385  0.065804987 -0.0079312716\n216 216 0  0.193395735 -0.534273935 -0.022307635 -0.4780933785\n217 217 0  0.124937046  0.027075591  0.111800048 -0.0456724251\n218 218 0 -0.568970226 -0.040608936  0.355194067 -1.3425294672\n219 219 0  0.070627704  0.071802230  0.193050845 -0.0893283184\n220 220 0  0.070219325  0.106872384 -0.467813608 -0.1634977671\n221 221 0  0.037212028  0.079906645 -0.281142829 -0.2195394018\n222 222 0  0.779033694 -0.017216183  0.197868891  1.1245794889\n223 223 0 -0.080856784  0.100298073  0.010944293 -0.3691681161\n224 224 0  0.156973131  0.189799786  0.441059518  0.2217297723\n225 225 0  0.320049764 -0.494409639 -0.141094353 -0.2271412564\n226 226 0  0.117534443  0.017932540  0.055327341 -0.0771071967\n227 227 0  0.423512314  0.060463665  0.262402173  0.5577230038\n228 228 0 -0.099900341  0.186011930 -0.649768661 -0.4290895317\n229 229 0 -0.419856257 -0.306116481  0.239695998 -1.3415643466\n230 230 0 -0.284211547  0.130054695  0.409642894 -0.6488899870\n231 231 0 -0.753222275 -0.030027693 -0.223669200 -1.7637166252\n232 232 0 -0.247972082  0.065570081  0.141595253 -0.6874401224\n233 233 0  0.101270509  0.381821766 -0.104310845  0.2148319323\n234 234 0  0.345045876  0.088648704 -0.027981049  0.3938743509\n235 235 0 -0.099278562  0.029809705 -0.382797888 -0.5339551160\n236 236 0  0.088408397 -0.350926503  0.322046544 -0.4396462517\n237 237 0  0.110297425  0.311836172 -0.170862216  0.1537597280\n238 238 0  0.248984943  0.161615683  0.196971735  0.3239314241\n239 239 0  0.090957757 -0.040349070 -0.257588251 -0.2321021567\n240 240 0 -0.403839766 -0.103068287 -0.252484109 -1.1978997040\n241 241 0 -0.028127495  0.339990059  0.029926952 -0.0405279405\n242 242 0 -0.067838483  0.071731286 -0.032579651 -0.3796392831\n243 243 0 -0.212198209  0.208118598 -0.024119936 -0.5125391470\n244 244 0 -0.125330026 -0.059893424  0.080428088 -0.5924313124\n245 245 0 -0.115473423 -0.063191791 -0.124217736 -0.6106283083\n246 246 0 -0.131957862 -0.165328652  0.019157384 -0.7151963582\n247 247 0  0.059267148 -0.135648280  0.249634274 -0.2991391875\n248 248 0  0.045621998  0.182745661  0.017056692 -0.0576566635\n249 249 0 -0.068261783  0.063549948 -0.196734737 -0.4147873697\n250 250 0  0.372831037  0.429248243  0.192102452  0.8057218274\n251 251 1  0.260840189  0.391927579 -0.203455239  0.5008559483\n252 252 1  0.154505781  0.152239539  0.191155069  0.1409015747\n253 253 1  0.018972282  0.528751618  0.216926661  0.2563325533\n254 254 1  0.335842273  0.684713506  0.062343807  0.9609552698\n255 255 1  0.390251644  0.156979043 -0.219496481  0.5109954332\n256 256 1  0.541779979  0.272348305  0.094484746  0.9496642528\n257 257 1  0.160558110  0.322781417 -0.170288028  0.2564097569\n258 258 1  0.015180608  0.408955052  0.203484543  0.1327854813\n259 259 1 -0.101448943  0.363471213  0.209166240 -0.1234630848\n260 260 1  0.161003119  0.509864988  0.100377941  0.4797086259\n261 261 1  0.135112835  0.747066607  0.461453543  0.7172454585\n262 262 1 -0.094273187  0.342733444 -0.109456810 -0.1816699307\n263 263 1 -0.012253533  0.334975602 -0.069425449 -0.0323022722\n264 264 1  0.265832450  0.280631819  0.178922007  0.4655629573\n265 265 1 -0.294945300  0.219588046  0.459490071 -0.5749769597\n266 266 1 -0.077656550  0.276937535  0.276701238 -0.1515902306\n267 267 1  0.432711992  0.528959290  0.342624236  1.0350453426\n268 268 1  0.482165717  0.109661988  0.035401091  0.6754718053\n269 269 1  0.532752579  0.282084789  0.108037340  0.9446139871\n270 270 1 -0.386269155  0.837702993  0.182259382 -0.1967854586\n271 271 1  0.232615302  0.561907246 -0.309763647  0.5942912681\n272 272 1  0.641159127  0.246807591  0.224361912  1.1283936032\n273 273 1 -0.278499729  0.528901717  0.241129277 -0.2847261394\n274 274 1  0.379272298  0.169919492  0.471080119  0.6149613527\n275 275 1  0.422354968  0.244500070 -0.412669477  0.6221681535\n276 276 1  0.255332877  0.669224395 -0.423249740  0.7200651341\n277 277 1  0.087623181  0.123376533  0.372444953  0.0201006844\n278 278 1  0.005423188  0.366976402 -0.238997163  0.0032217123\n279 279 1  0.043931753  0.330437399  0.376258562  0.1384279618\n280 280 1  0.249070234  0.238714154 -0.102274065  0.3493148641\n281 281 1  0.646319667  0.260705326 -0.106158394  1.0976512806\n282 282 1  0.157799440  0.298906541  0.201498555  0.2887001046\n283 283 1  0.393390851  0.132806972 -0.181571551  0.4997957137\n284 284 1  0.168337512  0.632363928 -0.087031068  0.5798340589\n285 285 1  0.112494083  0.194093082  0.200734486  0.1054414655\n286 286 1  0.369127280  0.095280327  0.485892181  0.5274751374\n287 287 1  0.352346028  0.182468763  0.444770468  0.5733488915\n288 288 1  0.009271300  0.225830352  0.484111550 -0.0075540311\n289 289 1  0.593637477  0.754669419  0.512442131  1.5730033127\n290 290 1  0.644560347  0.526515458 -0.422479882  1.2971404283\n291 291 1  0.202268478  0.057415550  0.244632149  0.1465071422\n292 292 1  0.286446728  0.221295558  0.156642880  0.4430589677\n293 293 1  0.121142824  0.066875849  0.433541111  0.0374431337\n294 294 1  0.403113422  0.611020437  0.245836625  1.0435280552\n295 295 1  0.327312576  0.810685854 -0.144119003  1.0322447500\n296 296 1  0.522004098 -0.347092555  0.161950070  0.3326788933\n297 297 1  0.297817828  0.153557763 -0.008519953  0.3724755450\n298 298 1  0.108479304  0.803271319 -0.167961000  0.6202932892\n299 299 1  0.135996902  0.373202552  0.262983329  0.3296583777\n300 300 1  0.567180632 -0.034872649  0.358015336  0.7454033668\n301 301 1  0.122133840  0.648690175  0.177362708  0.5535350138\n302 302 1  0.110249245  0.673280503  0.142292316  0.5495701255\n303 303 1  0.131600481  0.498920265  0.016263128  0.4017657998\n304 304 1  0.403829925  0.488826113  0.443097573  0.9600407522\n305 305 1  0.185085259 -0.121693606 -0.527416102 -0.1809642410\n306 306 1 -0.060063418  0.554536414  0.043438277  0.1080600507\n307 307 1  0.353760762  0.145531555  0.334032741  0.5227449089\n308 308 1  0.179680695  0.305907189 -0.008990424  0.3014300922\n309 309 1  0.024377087  0.555631185 -0.144793255  0.2333898337\n310 310 1  0.051216043  0.083013753 -0.536592129 -0.2322373313\n311 311 1 -0.357349496  0.037210871 -0.309991516 -0.9880220276\n312 312 1  0.125369232  0.538324518  0.419322906  0.4931934688\n313 313 1  0.213277694 -0.326583086  0.348042068 -0.1833657649\n314 314 1  0.304211170  0.299976928  0.023132873  0.5291650708\n315 315 1  0.307184900  0.420839800 -0.135087045  0.6244592711\n316 316 1  0.166016041  0.033166434  0.410845967  0.0838039295\n317 317 1 -0.007065267  0.639264054 -0.555512026  0.1892054519\n318 318 1  0.520772180  1.090092985 -0.276684484  1.6321890587\n319 319 1 -0.401441199 -0.219662872  0.510674865 -1.1814017653\n320 320 1 -0.136616813 -0.145959451  0.748009206 -0.5873154811\n321 321 1 -0.173071926  0.591584786 -0.404040790 -0.1360370032\n322 322 1  0.652619280  0.125360613  0.159044081  1.0228263664\n323 323 1  0.124151354 -0.109565657 -0.147158084 -0.2195212825\n324 324 1 -0.100230637  0.062244001  0.458727703 -0.3685732036\n325 325 1 -0.220798175  0.067417369 -0.153442208 -0.6836123370\n326 326 1  0.029514274  0.327698942 -0.007757564  0.0472639287\n327 327 1  0.354253544 -0.045699825  0.112965854  0.3052271762\n328 328 1  0.231924947  0.318710558 -0.094388190  0.3955807629\n329 329 1 -0.055083778  0.009964335 -0.046502101 -0.4175156382\n330 330 1 -0.436145395  0.025269629  0.669629649 -0.9853325265\n331 331 1 -0.284175373  0.022955950  0.616444668 -0.7176618312\n332 332 1  0.281832179  0.788743666 -0.298122450  0.9030281673\n333 333 1  0.242582384  0.394433233  0.471663728  0.5790164317\n334 334 1  0.669893746  0.517898861  0.108002567  1.4211582452\n335 335 1 -0.075420104  0.180053356  0.039870371 -0.2783470466\n336 336 1  0.509538999  0.389506766 -0.046565513  0.9796669939\n337 337 1  0.522647195  0.437632662  0.478135203  1.1345444924\n338 338 1 -0.347563132  0.333572961  0.059501368 -0.6272385934\n339 339 1  0.388787693  0.664010673  0.140319504  1.0508187741\n340 340 1  0.165070449  0.669487059 -0.017676263  0.6205260650\n341 341 1 -0.467717803 -0.237954622  0.276030264 -1.3582872770\n342 342 1  0.378535931  0.142368979  0.106487212  0.5283110522\n343 343 1  0.049483293  0.236810919 -0.231732508 -0.0391907811\n344 344 1  0.348130068  0.321868749 -0.242360650  0.5876034585\n345 345 1  0.158875622  0.680300861  0.196323968  0.6541250699\n346 346 1  0.052367863  0.427723655 -0.483061242  0.1077847098\n347 347 1  0.212740824  0.594838557  0.191368328  0.6704017446\n348 348 1  0.157677699  0.331862894  0.264769294  0.3301916885\n349 349 1  0.094015046  0.424826335 -0.289304722  0.2126828702\n350 350 1  0.151151321 -0.003197520  0.107805675 -0.0271964377\n351 351 1 -0.236860827  0.308458258 -0.234253940 -0.4958903506\n352 352 1 -0.049369436  0.252396464 -0.192747717 -0.1991447174\n353 353 1  0.245033977  0.287372830  0.197844159  0.4369497718\n354 354 1  0.267402476  0.117481978  0.535288688  0.3702619847\n355 355 1  0.204512014  0.273773854  0.545833795  0.4060039074\n356 356 1  0.099857385  0.302316542 -0.317892427  0.1017482454\n357 357 1  0.314323043  0.408651897  0.266442534  0.6908603806\n358 358 1  0.043924794  0.156172414  0.222558012 -0.0529011245\n359 359 1  0.297150963  0.123490373 -0.084703793  0.3302090872\n360 360 1  0.065247197  0.482683459  0.164832478  0.2887011228\n361 361 1  0.436579086  0.242595269  0.465602550  0.7885064028\n362 362 1  0.372555682  0.711162418  0.408529387  1.1095032872\n363 363 1  0.096348410  0.014621496  0.224790143 -0.0916765031\n364 364 1  0.100068582  0.074777916  0.166547136 -0.0368235738\n365 365 1  0.264974548  0.443842146 -0.198424491  0.5588324361\n366 366 1 -0.056866627  0.149096944 -0.676466349 -0.3898089934\n367 367 1  0.186936099  0.583476366  0.079546297  0.5941707168\n368 368 1  0.455635221  0.315602044 -0.263165403  0.7752551595\n369 369 1  0.045688889  0.585065893  0.068646767  0.3350899441\n370 370 1  0.335436747  0.306682253 -0.402284793  0.5239640554\n371 371 1  0.085727364  0.363653820 -0.774584905  0.0605551283\n372 372 1  0.037102012 -0.061572016  0.024232771 -0.3054693870\n373 373 1  0.040558364  0.370491471  0.349513137  0.1661769726\n374 374 1  0.536202228  0.570273297  0.203012747  1.2415653395\n375 375 1  0.100534737  0.465566869 -0.151696300  0.2858067482\n376 376 1  0.089954018  0.298591119  0.571790745  0.2239800445\n377 377 1  0.076227999  0.343912248  0.276704927  0.1943750431\n378 378 1  0.418122584  0.284300575 -0.011938455  0.7172604672\n379 379 1  0.353052818  0.971850317  0.735846165  1.3757163725\n380 380 1 -0.032198518  0.880522997 -0.005666744  0.4625451629\n381 381 1  0.389179189  0.593493731 -0.013672206  0.9592680346\n382 382 1  0.123674103  0.737788540  0.577492618  0.7061954692\n383 383 1  0.047495977  0.247052141 -0.104682229 -0.0124956747\n384 384 1  0.159003010  0.228619827 -0.119845530  0.1717821612\n385 385 1  0.129780628  0.190818086  0.055176817  0.1104417909\n386 386 1 -0.143471971  1.019056532  0.280813905  0.4373057230\n387 387 1 -0.001521468  0.492464724  0.201163940  0.1815680108\n388 388 1  0.362682527  0.338591626  0.102191183  0.6859873464\n389 389 1  0.491640344  0.581822909  0.131530396  1.1593724747\n390 390 1  0.422713025 -0.397320793  0.298526693  0.1248484112\n391 391 1  0.256676244  0.247471203  0.505771709  0.4699903631\n392 392 1  0.424840111  0.437116049  0.140935272  0.9002653368\n393 393 1  0.063700321  0.424467048 -0.136448513  0.1815178970\n394 394 1  0.380622868  0.534793352 -0.331773193  0.8360564966\n395 395 1 -0.045101393  0.428774600 -0.225020579 -0.0280766596\n396 396 1  0.112461551 -0.076824792  0.268850287 -0.1423660764\n397 397 1  0.582582570  0.661821141  0.369633053  1.4409563718\n398 398 1  0.112657744  0.237808165  0.054723129  0.1238734207\n399 399 1  0.642134723  0.552179832  0.337772504  1.4402069003\n400 400 1  0.395209490 -0.038605590 -0.153471043  0.3439493623\n401 401 1  0.276610324  0.330743226  0.229602990  0.5413769561\n402 402 1  0.101975031  0.708883886 -0.052129496  0.5369596277\n403 403 1  0.421930799 -0.038536542 -0.051800294  0.4094310151\n404 404 1  1.127186241  0.240926561  0.272173017  2.0211565511\n405 405 1  0.026420383  0.141005952 -0.246598860 -0.1753671757\n406 406 1  0.064328682  0.426875661 -0.072361623  0.1953383100\n407 407 1 -0.009419496  0.591480940  0.721657079  0.3458789155\n408 408 1  0.032437387  0.451814867 -0.576714098  0.0791211974\n409 409 1  0.150574357  0.336178056  0.017888031  0.2813545739\n410 410 1  0.247060749  0.050552329 -0.378135592  0.1212786278\n411 411 1  0.119288225  0.033353274  0.247803617 -0.0280243021\n412 412 1  0.333435788  0.242491334 -0.085098172  0.5103014109\n413 413 1 -0.225129399  0.117246340  0.050240289 -0.6110020722\n414 414 1  0.186459329  0.173171123 -0.235244595  0.1504639488\n415 415 1  0.278748422  0.751900272 -0.302438667  0.8614877888\n416 416 1  0.388630092  0.196941294  0.249449422  0.6220627867\n417 417 1  1.088407717  0.134808251  0.197661691  1.8366807490\n418 418 1  0.661044265  0.044481835  0.042619311  0.9421776567\n419 419 1  0.281260837  0.312266083  0.365336369  0.5542102513\n420 420 1 -0.124455880  0.478161841 -0.344351859 -0.1456275377\n421 421 1  0.150287324  0.296201421 -0.314527095  0.1888647341\n422 422 1  0.084744273  0.535836761  0.487001706  0.4273214766\n423 423 1 -0.331289475  0.343976075  0.393587976 -0.5334300779\n424 424 1 -0.181584546  0.695954955  0.185237318  0.0433899359\n425 425 1  0.196249230  0.429334896  0.029512750  0.4559135910\n426 426 1  0.394114511  0.157591690  0.134154689  0.5758750393\n427 427 1  0.121754426  0.124695454  0.229387128  0.0607612709\n428 428 1  0.203156016  0.242085530  0.505939617  0.3667975238\n429 429 1  0.035107984 -0.142648012  0.386277123 -0.3279898237\n430 430 1  0.263737921  0.301792845 -0.344685981  0.3972244325\n431 431 1  0.131809451 -0.019445801  0.236183334 -0.0573903521\n432 432 1  0.260127784  0.002035735  0.250904740  0.2006529714\n433 433 1  0.136395006  0.502700574  0.228402888  0.4484837404\n434 434 1  0.029129068 -0.072831362  0.256321438 -0.2932855720\n435 435 1  0.029691815  0.098380545  0.600611889 -0.0730194250\n436 436 1 -0.359212070  0.392588210  0.349676437 -0.5452704770\n437 437 1  0.386428488  0.761117310 -0.264707209  1.0737196932\n438 438 1  0.176658323  0.392081438  0.180470706  0.4088533258\n439 439 1  0.121928663  0.317852040  1.186321524  0.4003930746\n440 440 1  0.201158301  0.563006350 -0.352769894  0.5307383024\n441 441 1 -0.146601716  0.488953215  0.531926923 -0.0341329464\n442 442 1  0.394207456  0.355854912  0.259004120  0.7856159889\n443 443 1  0.236197460  0.263463121  0.319192564  0.4175518574\n444 444 1  0.598593654  0.034874922  0.625514766  0.9128649790\n445 445 1  0.045886769  0.715211385  0.056705754  0.4578295680\n446 446 1 -0.009705017  0.326929159  0.147251829 -0.0002624003\n447 447 1 -0.003728883  0.480870579 -0.167233241  0.1068473132\n448 448 1  0.132547350  0.601585662  0.431088620  0.5686749914\n449 449 1  0.299823074  0.119284379  0.483165155  0.4229614795\n450 450 1  0.049189350  0.687183572  0.555585745  0.5178223769\n451 451 1  0.252301213  0.179821953  0.129962816  0.3365571798\n452 452 1 -0.112981368  0.555174304  0.397798583  0.0690276026\n453 453 1 -0.062685601  0.545901155 -0.096175323  0.0724194071\n454 454 1  0.113353040  0.329720149 -0.093530417  0.1889522694\n455 455 1  0.296705149  0.170957952  0.293747055  0.4359589068\n456 456 1  0.270506530  0.086528902  0.431293671  0.3295603185\n457 457 1  0.513429207  0.266309116  0.454633253  0.9502099934\n458 458 1 -0.010120146  0.178706369  0.246466366 -0.1265471072\n459 459 1 -0.626358340  0.307937983  0.337122349 -1.1177012450\n460 460 1  0.246039283  0.552125086  0.061326390  0.6695843513\n461 461 1  0.005986818 -0.122718556 -0.210054412 -0.4587966570\n462 462 1  0.256804276  0.588580628  0.246376820  0.7540703653\n463 463 1  0.092784992  0.008839523  0.151801915 -0.1155375969\n464 464 1  0.593052833  0.414754929  0.187486496  1.1946883124\n465 465 1  0.079828416  0.553882040  0.054159689  0.3655214935\n466 466 1  0.274536936  0.024711225 -0.125065214  0.1878897331\n467 467 1 -0.121844352  0.035230428  0.297948110 -0.4599943087\n468 468 1  0.017321122  0.429796103  0.768768800  0.2480693218\n469 469 1  0.631977745  0.270425488 -0.733156679  0.9792145409\n470 470 1  0.239343972  0.556166904 -0.174949249  0.6229497067\n471 471 1  0.755016698  0.197002484  0.461793515  1.3278792364\n472 472 1  0.158784187  0.418554141 -0.499860394  0.2913165539\n473 473 1  0.464583873  0.569157805 -0.041640722  1.0696777306\n474 474 1 -0.029018615  0.573144337 -0.312428604  0.1251488983\n475 475 1  0.054398432  0.799214105  0.307232970  0.5941944096\n476 476 1  0.012280607  0.283568519 -0.053216593 -0.0338227229\n477 477 1 -0.111497464  0.451839467  0.156332791 -0.0660194798\n478 478 1  0.457534007  0.322730189  0.145415848  0.8516457909\n479 479 1 -0.099603398  0.238362348  0.336531372 -0.2189733991\n480 480 1 -0.037102750  0.099890659  0.609334966 -0.1925668594\n481 481 1 -0.031174516  0.632088643  0.350837992  0.2848061519\n482 482 1  0.154673787 -0.014586454  0.421231358  0.0190881204\n483 483 1 -0.058721934  0.087922457 -0.205325369 -0.3754159501\n484 484 1  0.081368836 -0.037170925  0.378350821 -0.1437523528\n485 485 1  0.579636577  0.302097311 -0.255913021  0.9907619864\n486 486 1 -0.218816363  0.033823814  0.465305538 -0.6119630775\n487 487 1  0.516028659 -0.017279330  0.375900517  0.6713652195\n488 488 1  0.210652039  0.323472455  0.516914406  0.4600465442\n489 489 1  0.356843971  0.398048146  0.779670444  0.8416847822\n490 490 1  0.077146544  0.220601398 -0.158939399  0.0077964614\n491 491 1  0.265691779  0.474960506  0.179601222  0.6510287488\n492 492 1  0.160804851  0.168673344 -0.032850017  0.1319005929\n493 493 1 -0.291538245  0.365521521  0.066971712 -0.4928485768\n494 494 1 -0.091159274  0.763174977  0.228859817  0.2803572447\n495 495 1  0.445357981  0.010258312  0.117116621  0.5262962628\n496 496 1  0.094678315  0.561159369 -0.438603557  0.3199628276\n497 497 1  0.369369292  0.224132356 -0.243174477  0.5330394507\n498 498 1  0.458870717 -0.199810182  0.720044930  0.4479559721\n499 499 1 -0.095216928 -0.567473138 -0.217737050 -1.0703043416\n500 500 1  0.510454387  0.139014181 -0.108936456  0.7319948988"
  },
  {
    "objectID": "DeclareDesign/reference/reshape_diagnosis.html#description",
    "href": "DeclareDesign/reference/reshape_diagnosis.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nTake a diagnosis object and returns a pretty output table. If diagnosands are bootstrapped, se’s are put in parentheses on a second line and rounded to digits."
  },
  {
    "objectID": "DeclareDesign/reference/reshape_diagnosis.html#usage",
    "href": "DeclareDesign/reference/reshape_diagnosis.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nreshape_diagnosis(diagnosis, digits = 2, select = NULL, exclude = NULL)"
  },
  {
    "objectID": "DeclareDesign/reference/reshape_diagnosis.html#arguments",
    "href": "DeclareDesign/reference/reshape_diagnosis.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\ndiagnosis\nA diagnosis object generated by diagnose_design.\n\n\ndigits\nNumber of digits.\n\n\nselect\nList of columns to include in output. Defaults to all.\n\n\nexclude\nSet of columns to exclude from output. Defaults to none."
  },
  {
    "objectID": "DeclareDesign/reference/reshape_diagnosis.html#value",
    "href": "DeclareDesign/reference/reshape_diagnosis.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA formatted text table with bootstrapped standard errors in parentheses."
  },
  {
    "objectID": "DeclareDesign/reference/reshape_diagnosis.html#examples",
    "href": "DeclareDesign/reference/reshape_diagnosis.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\neffect_size <- 0.1\ndesign <-\n  declare_model(\n    N = 100,\n    U = rnorm(N),\n    X = rnorm(N),\n    potential_outcomes(Y ~ effect_size * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\", label = \"unadjusted\") + \n  declare_estimator(Y ~ Z + X, inquiry = \"ATE\", label = \"adjusted\")\n\ndiagnosis <- diagnose_design(design, sims = 100)\n\nreshape_diagnosis(diagnosis)\n\n  Design Inquiry  Estimator Outcome Term N Sims Mean Estimand Mean Estimate\n1 design     ATE   adjusted       Y    Z    100          0.10          0.11\n2                                                      (0.00)        (0.02)\n3 design     ATE unadjusted       Y    Z    100          0.10          0.11\n4                                                      (0.00)        (0.03)\n    Bias SD Estimate   RMSE  Power Coverage\n1   0.01        0.22   0.22   0.10     0.93\n2 (0.02)      (0.01) (0.01) (0.03)   (0.02)\n3   0.01        0.32   0.32   0.12     0.94\n4 (0.03)      (0.02) (0.02) (0.03)   (0.02)\n\nreshape_diagnosis(diagnosis, select = c(\"Bias\", \"Power\"))\n\n  Design Inquiry  Estimator Outcome Term N Sims   Bias  Power\n1 design     ATE   adjusted       Y    Z    100   0.01   0.10\n2                                               (0.02) (0.03)\n3 design     ATE unadjusted       Y    Z    100   0.01   0.12\n4                                               (0.03) (0.03)"
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#description",
    "href": "DeclareDesign/reference/compare_diagnoses.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDiagnose and compare designs."
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#usage",
    "href": "DeclareDesign/reference/compare_diagnoses.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncompare_diagnoses(\n  design1,\n  design2,\n  sims = 500,\n  bootstrap_sims = 100,\n  merge_by_estimator = TRUE,\n  alpha = 0.05\n)"
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#arguments",
    "href": "DeclareDesign/reference/compare_diagnoses.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesign1\nA design or a diagnosis.\n\n\ndesign2\nA design or a diagnosis.\n\n\nsims\nThe number of simulations, defaulting to 1000. sims may also be a vector indicating the number of simulations for each step in a design, as described for simulate_design. Used for both designs.\n\n\nbootstrap_sims\nNumber of bootstrap replicates for the diagnosands to obtain the standard errors of the diagnosands, defaulting to 1000. Set to FALSE to turn off bootstrapping. Used for both designs. Must be greater or equal to 100.\n\n\nmerge_by_estimator\nA logical. Whether to include estimator in the set of columns used for merging. Defaults to TRUE.\n\n\nalpha\nThe significance level, 0.05 by default."
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#details",
    "href": "DeclareDesign/reference/compare_diagnoses.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nThe function compare_diagnoses runs a many-to-many merge matching by inquiry and term (if present). If merge_by_estimator equals TRUE, estimator is also included in the merging condition. Any diagnosand that is not included in both designs will be dropped from the merge."
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#value",
    "href": "DeclareDesign/reference/compare_diagnoses.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA list with a data.frame of compared diagnoses and both diagnoses."
  },
  {
    "objectID": "DeclareDesign/reference/compare_diagnoses.html#examples",
    "href": "DeclareDesign/reference/compare_diagnoses.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\ndesign_a <- declare_model(N  = 100, \n                          U = rnorm(N),\n                          Y_Z_0 = U,\n                          Y_Z_1 = U + rnorm(N, mean = 2, sd = 2)) +\ndeclare_assignment(Z = complete_ra(N, prob = 0.5)) +\ndeclare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\ndeclare_measurement(Y = reveal_outcomes(Y ~ Z)) +\ndeclare_estimator(Y ~ Z, inquiry = \"ATE\")\n\ndesign_b <- replace_step(\n  design_a, step = \"assignment\", \n  declare_assignment(Z = complete_ra(N, prob = 0.3)) )\n\ncomparison <- compare_diagnoses(design_a, design_b, sims = 40)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#description",
    "href": "DeclareDesign/reference/declare_inquiry.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclares inquiries, or the inferential target of interest. Conceptually very close to “estimand” or “quantity of interest”."
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#usage",
    "href": "DeclareDesign/reference/declare_inquiry.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_inquiry(..., handler = inquiry_handler, label = \"inquiry\")\n\ndeclare_inquiries(..., handler = inquiry_handler, label = \"inquiry\")\n\ndeclare_estimand(...)\n\ndeclare_estimands(...)\n\ninquiry_handler(data, ..., subset = NULL, term = FALSE, label)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#arguments",
    "href": "DeclareDesign/reference/declare_inquiry.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\ndata\na data.frame\n\n\nsubset\na subset expression\n\n\nterm\nTRUE/FALSE"
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#details",
    "href": "DeclareDesign/reference/declare_inquiry.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nFor the default diagnosands, the return value of the handler should have inquiry and estimand columns.\nIf term is TRUE, the names of … will be returned in a term column, and inquiry will contain the step label. This can be used as an additional dimension for use in diagnosis."
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#value",
    "href": "DeclareDesign/reference/declare_inquiry.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na function, I(), that accepts a data.frame as an argument and returns a data.frame containing the value of the inquiry, a^m."
  },
  {
    "objectID": "DeclareDesign/reference/declare_inquiry.html#examples",
    "href": "DeclareDesign/reference/declare_inquiry.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# Set up a design for use in examples:\n## Two-arm randomized experiment\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ 0.2 * Z + X + U)\n  ) +\n  declare_assignment(Z = complete_ra(N = N, m = 250)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# Some common inquiries\ndesign +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) -------------------\n\nRun of the design:\n\n inquiry estimand\n     ATE      0.2\n\ndesign +\n  declare_inquiry(difference_in_var = var(Y_Z_1) - var(Y_Z_0))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(difference_in_var = var(Y_Z_1) - var(Y_Z_0)) -\n\nRun of the design:\n\n           inquiry  estimand\n difference_in_var -5.55e-17\n\ndesign +\n  declare_inquiry(mean_Y = mean(Y))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(mean_Y = mean(Y)) ----------------------------\n\nRun of the design:\n\n inquiry estimand\n  mean_Y    0.613\n\n# Inquiries among a subset\ndesign +\n  declare_inquiry(ATT = mean(Y_Z_1 - Y_Z_0),\n                  subset = (Z == 1))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(ATT = mean(Y_Z_1 - Y_Z_0), subset = (Z == 1)) \n\nRun of the design:\n\n inquiry estimand\n     ATT      0.2\n\ndesign +\n  declare_inquiry(CATE = mean(Y_Z_1 - Y_Z_0),\n                  subset = X == 1)\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(CATE = mean(Y_Z_1 - Y_Z_0), subset = X == 1) -\n\nRun of the design:\n\n inquiry estimand\n    CATE      0.2\n\n# equivalently\ndesign +\n  declare_inquiry(CATE = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1]))\n\n\nResearch design declaration summary\n\nStep 1 (model): declare_model(N = 500, X = rep(c(0, 1), each = N/2), U = rnorm(N, sd = 0.25), potential_outcomes(Y ~ 0.2 * Z + X + U)) \n\nStep 2 (assignment): declare_assignment(Z = complete_ra(N = N, m = 250)) -------\n\nStep 3 (measurement): declare_measurement(Y = reveal_outcomes(Y ~ Z)) ----------\n\nStep 4 (inquiry): declare_inquiry(CATE = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1])) --\n\nRun of the design:\n\n inquiry estimand\n    CATE      0.2\n\n# Add inquiries to a design along with estimators that\n# reference them\ndiff_in_variances <-\n  function(data) {\n    data.frame(estimate = with(data, var(Y[Z == 1]) - var(Y[Z == 0])))\n  }\n\ndesign_1 <-\n  design +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0),\n                  difference_in_var = var(Y_Z_1) - var(Y_Z_0)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, \n                    inquiry = \"ATE\",\n                    label = \"DIM\") +\n  declare_estimator(handler =\n                      label_estimator(diff_in_variances),\n                    inquiry = \"difference_in_var\",\n                    label = \"DIV\")\n\nrun_design(design_1)\n\n            inquiry estimand estimator term   estimate  std.error statistic\n1               ATE      0.2       DIM    Z  0.2129575 0.04957697  4.295493\n2 difference_in_var      0.0       DIV <NA> -0.0147119         NA        NA\n       p.value  conf.low conf.high  df outcome\n1 2.096531e-05 0.1155517 0.3103633 498       Y\n2           NA        NA        NA  NA    <NA>\n\n# Two inquiries using one estimator\n\ndesign_2 <-\n  design +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_inquiry(ATT = mean(Y_Z_1 - Y_Z_0), subset = (Z == 1)) +\n  declare_estimator(Y ~ Z, inquiry = c(\"ATE\", \"ATT\"))\n\nrun_design(design_2)\n\n  inquiry estimand estimator term  estimate  std.error statistic      p.value\n1     ATE      0.2 estimator    Z 0.1947629 0.04942835  3.940308 9.300673e-05\n2     ATT      0.2 estimator    Z 0.1947629 0.04942835  3.940308 9.300673e-05\n    conf.low conf.high  df outcome\n1 0.09764912 0.2918767 498       Y\n2 0.09764912 0.2918767 498       Y\n\n# Two inquiries using different coefficients from one estimator\n\ndesign_3 <-\n  design +\n  declare_inquiry(intercept = mean(Y_Z_0),\n                  slope = mean(Y_Z_1 - Y_Z_0)) +\n  declare_estimator(\n    Y ~ Z,\n    .method = lm_robust,\n    term = TRUE,\n    inquiry = c(\"intercept\", \"slope\")\n  )\n\nrun_design(design_3)\n\n    inquiry  estimand estimator        term  estimate  std.error statistic\n1 intercept 0.5153216 estimator (Intercept) 0.4940114 0.03490608 14.152590\n2     slope 0.2000000 estimator           Z 0.2426205 0.04940141  4.911206\n       p.value  conf.low conf.high  df outcome\n1 1.846911e-38 0.4254301 0.5625927 498       Y\n2 1.229495e-06 0.1455596 0.3396814 498       Y\n\n# declare_inquiries usage\ndesign_4 <- design +\n  declare_inquiries(\n    ATE = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1]),\n    CATE_X0 = mean(Y_Z_1[X == 0] - Y_Z_0[X == 0]),\n    CATE_X1 = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1]),\n    Difference_in_CATEs = CATE_X1 - CATE_X0,\n    mean_Y = mean(Y))"
  },
  {
    "objectID": "DeclareDesign/reference/declare_population.html#description",
    "href": "DeclareDesign/reference/declare_population.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeprecated. Please use declare_model instead."
  },
  {
    "objectID": "DeclareDesign/reference/declare_population.html#usage",
    "href": "DeclareDesign/reference/declare_population.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_population(..., handler = fabricate, label = NULL)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_population.html#arguments",
    "href": "DeclareDesign/reference/declare_population.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step"
  },
  {
    "objectID": "DeclareDesign/reference/declare_population.html#value",
    "href": "DeclareDesign/reference/declare_population.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA potential outcomes declaration, which is a function that returns a data.frame."
  },
  {
    "objectID": "DeclareDesign/reference/tidy_try.html#description",
    "href": "DeclareDesign/reference/tidy_try.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nTidy function that returns a tidy data.frame of model results and allows filtering to relevant coefficients. The function will attempt to tidy model objects even when they do not have a tidy method available. For best results, first load the broom package via library(broom)."
  },
  {
    "objectID": "DeclareDesign/reference/tidy_try.html#usage",
    "href": "DeclareDesign/reference/tidy_try.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ntidy_try(fit, term = FALSE)"
  },
  {
    "objectID": "DeclareDesign/reference/tidy_try.html#arguments",
    "href": "DeclareDesign/reference/tidy_try.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nfit\nA model fit, as returned by a modeling function like lm, glm, or estimatr::lm_robust.\n\n\nterm\nA character vector of the terms that represent quantities of interest, i.e., “Z”. If FALSE, return the first non-intercept term; if TRUE return all terms."
  },
  {
    "objectID": "DeclareDesign/reference/tidy_try.html#value",
    "href": "DeclareDesign/reference/tidy_try.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA data.frame with coefficient estimates and associated statistics."
  },
  {
    "objectID": "DeclareDesign/reference/tidy_try.html#examples",
    "href": "DeclareDesign/reference/tidy_try.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nfit <- lm(mpg ~ hp + disp + cyl, data = mtcars)\n\ntidy_try(fit)\n\n         term    estimate  std.error statistic      p.value    conf.low\n1 (Intercept) 34.18491917 2.59077758 13.194849 1.537198e-13 28.87795186\n2          hp -0.01467933 0.01465087 -1.001943 3.249519e-01 -0.04469028\n3        disp -0.01883809 0.01040369 -1.810711 8.092901e-02 -0.04014908\n4         cyl -1.22741994 0.79727631 -1.539516 1.349044e-01 -2.86056643\n     conf.high\n1 39.491886473\n2  0.015331608\n3  0.002472913\n4  0.405726550"
  },
  {
    "objectID": "DeclareDesign/reference/declaredesign.html#description",
    "href": "DeclareDesign/reference/declaredesign.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThe four main types of functions are to declare a step, to combine steps into designs, and to manipulate designs and designers (functions that return designs)."
  },
  {
    "objectID": "DeclareDesign/reference/declare_sampling.html#description",
    "href": "DeclareDesign/reference/declare_sampling.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclare sampling procedure"
  },
  {
    "objectID": "DeclareDesign/reference/declare_sampling.html#usage",
    "href": "DeclareDesign/reference/declare_sampling.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_sampling(..., handler = sampling_handler, label = NULL)\n\nsampling_handler(data, ..., legacy = FALSE)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_sampling.html#arguments",
    "href": "DeclareDesign/reference/declare_sampling.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\ndata\nA data.frame.\n\n\nlegacy\nUse the legacy randomizr functionality. This will be disabled in future; please use legacy = FALSE."
  },
  {
    "objectID": "DeclareDesign/reference/declare_sampling.html#value",
    "href": "DeclareDesign/reference/declare_sampling.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA sampling declaration, which is a function that takes a data.frame as an argument and returns a data.frame subsetted to sampled observations and (optionally) augmented with inclusion probabilities and other quantities."
  },
  {
    "objectID": "DeclareDesign/reference/declare_sampling.html#examples",
    "href": "DeclareDesign/reference/declare_sampling.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# declare_sampling in use\n## Two-arm randomized experiment\ndesign <-\n  declare_model(\n    N = 500,\n    X = rep(c(0, 1), each = N / 2),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ 0.2 * Z + X + U)\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N = N, n = 200)) +\n  declare_assignment(Z = complete_ra(N = N, m = 100)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\n# Set up population to sample from\nmodel <- declare_model(\n  villages = add_level(\n    N = 30, \n    N_households = sample(c(50:100), N, replace = TRUE)\n  ),\n  households = add_level(\n    N = N_households, \n    N_members = sample(c(1, 2, 3, 4), N, \n                       prob = c(0.2, 0.3, 0.25, 0.25), replace = TRUE)\n  ),\n  individuals = add_level(\n    N = N_members, \n    age = sample(18:90, N, replace = TRUE),\n    gender = rbinom(n = N, size = 1, prob = .5)\n  )\n)\n\n# Sampling procedures\n## Complete random sampling\ndesign <- model +\n  declare_sampling(S = complete_rs(N = N, n = 1000))\n\n## Cluster random sampling\ndesign <- model +\n  declare_sampling(S = cluster_rs(clusters = villages, \n                                  n = 15))\n\n## Strata and cluster random sampling\ndesign <- model +\n  declare_sampling(S  = strata_and_cluster_rs(\n    strata = villages,\n    clusters = households,\n    strata_n = rep(20, 30)))\n\n## Stratified random sampling\ndesign <- model +\n  declare_sampling(S = strata_rs(strata = gender, n = 100))"
  },
  {
    "objectID": "DeclareDesign/reference/expand_design.html#description",
    "href": "DeclareDesign/reference/expand_design.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nexpand_design easily generates a set of design from a designer function."
  },
  {
    "objectID": "DeclareDesign/reference/expand_design.html#usage",
    "href": "DeclareDesign/reference/expand_design.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nexpand_design(designer, ..., expand = TRUE, prefix = \"design\")"
  },
  {
    "objectID": "DeclareDesign/reference/expand_design.html#arguments",
    "href": "DeclareDesign/reference/expand_design.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndesigner\na function which yields a design\n\n\n…\nOptions sent to the designer\n\n\nexpand\nboolean - if true, form the crossproduct of the …, otherwise recycle them\n\n\nprefix\nprefix for the names of the designs, i.e. if you create two designs they would be named prefix_1, prefix_2"
  },
  {
    "objectID": "DeclareDesign/reference/expand_design.html#value",
    "href": "DeclareDesign/reference/expand_design.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nif set of designs is size one, the design, otherwise a by-list of designs. Designs are given a parameters attribute with the values of parameters assigned by expand_design."
  },
  {
    "objectID": "DeclareDesign/reference/expand_design.html#examples",
    "href": "DeclareDesign/reference/expand_design.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\nlist(\"\\n\", \"\\n\", \"# in conjunction with DesignLibrary\\n\", \"\\n\", \"library(DesignLibrary)\\n\", \"\\n\", \"designs <- expand_design(multi_arm_designer, outcome_means = list(c(3,2,4), c(1,4,1)))\\n\", \"\\n\", \"# with a custom designer function\\n\", \"\\n\", \"designer <- function(N) {\\n\", \"  pop <- \\n\", \"    declare_model(\\n\", \"      N = N, \\n\", \"      U = rnorm(N),\\n\", \"      potential_outcomes(Y ~ 0.20 * Z + U)\\n\", \"    )\\n\", \"  assgn <- declare_assignment(Z = complete_ra(N, m = N/2))\\n\", \"  inquiry <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\\n\", \n    \"  estimator <- declare_estimator(Y ~ Z, inquiry = inquiry)\\n\", \"  pop + pos + assgn + inquiry + estimator\\n\", \"}\\n\", \"\\n\", \"# returns list of eight designs\\n\", \"designs <- expand_design(designer, N = seq(30, 100, 10))\\n\", \"\\n\", \" # diagnose a list of designs created by expand_design or redesign\\n\", \" diagnosis <- diagnose_design(designs, sims = 50)\\n\", \"\\n\", \"# returns a single design\\n\", \"large_design <- expand_design(designer, N = 200)\\n\", \"\\n\", \" diagnose_large_design <- diagnose_design(large_design, sims = 50)\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"\\n\"\n\n[[3]]\n[1] \"# in conjunction with DesignLibrary\\n\"\n\n[[4]]\n[1] \"\\n\"\n\n[[5]]\n[1] \"library(DesignLibrary)\\n\"\n\n[[6]]\n[1] \"\\n\"\n\n[[7]]\n[1] \"designs <- expand_design(multi_arm_designer, outcome_means = list(c(3,2,4), c(1,4,1)))\\n\"\n\n[[8]]\n[1] \"\\n\"\n\n[[9]]\n[1] \"# with a custom designer function\\n\"\n\n[[10]]\n[1] \"\\n\"\n\n[[11]]\n[1] \"designer <- function(N) {\\n\"\n\n[[12]]\n[1] \"  pop <- \\n\"\n\n[[13]]\n[1] \"    declare_model(\\n\"\n\n[[14]]\n[1] \"      N = N, \\n\"\n\n[[15]]\n[1] \"      U = rnorm(N),\\n\"\n\n[[16]]\n[1] \"      potential_outcomes(Y ~ 0.20 * Z + U)\\n\"\n\n[[17]]\n[1] \"    )\\n\"\n\n[[18]]\n[1] \"  assgn <- declare_assignment(Z = complete_ra(N, m = N/2))\\n\"\n\n[[19]]\n[1] \"  inquiry <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\\n\"\n\n[[20]]\n[1] \"  estimator <- declare_estimator(Y ~ Z, inquiry = inquiry)\\n\"\n\n[[21]]\n[1] \"  pop + pos + assgn + inquiry + estimator\\n\"\n\n[[22]]\n[1] \"}\\n\"\n\n[[23]]\n[1] \"\\n\"\n\n[[24]]\n[1] \"# returns list of eight designs\\n\"\n\n[[25]]\n[1] \"designs <- expand_design(designer, N = seq(30, 100, 10))\\n\"\n\n[[26]]\n[1] \"\\n\"\n\n[[27]]\n[1] \" # diagnose a list of designs created by expand_design or redesign\\n\"\n\n[[28]]\n[1] \" diagnosis <- diagnose_design(designs, sims = 50)\\n\"\n\n[[29]]\n[1] \"\\n\"\n\n[[30]]\n[1] \"# returns a single design\\n\"\n\n[[31]]\n[1] \"large_design <- expand_design(designer, N = 200)\\n\"\n\n[[32]]\n[1] \"\\n\"\n\n[[33]]\n[1] \" diagnose_large_design <- diagnose_design(large_design, sims = 50)\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/declare_potential_outcomes.html#description",
    "href": "DeclareDesign/reference/declare_potential_outcomes.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeprecated. Please use the potential_outcomes function within a declare_model declaration."
  },
  {
    "objectID": "DeclareDesign/reference/declare_potential_outcomes.html#usage",
    "href": "DeclareDesign/reference/declare_potential_outcomes.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_potential_outcomes(\n  ...,\n  handler = potential_outcomes_handler,\n  label = NULL\n)\n\npotential_outcomes_internal.formula(\n  formula,\n  conditions = c(0, 1),\n  assignment_variables = \"Z\",\n  data,\n  level = NULL,\n  label = outcome_variable\n)\n\npotential_outcomes_internal.NULL(\n  formula = stop(\"Not provided\"),\n  ...,\n  data,\n  level = NULL\n)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_potential_outcomes.html#arguments",
    "href": "DeclareDesign/reference/declare_potential_outcomes.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\nformula\na formula to calculate potential outcomes as functions of assignment variables.\n\n\nconditions\nsee expand_conditions. Provide values (e.g. conditions = 1:4) for a single assignment variable. If multiple assignment variables, provide named list (e.g. conditions = list(Z1 = 0:1, Z2 = 0:1)). Defaults to 0:1 if no conditions provided.\n\n\nassignment_variables\nThe name of the assignment variable. Generally not required as names are taken from conditions.\n\n\ndata\na data.frame\n\n\nlevel\na character specifying a level of hierarchy for fabricate to calculate at"
  },
  {
    "objectID": "DeclareDesign/reference/declare_potential_outcomes.html#value",
    "href": "DeclareDesign/reference/declare_potential_outcomes.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na function that returns a data.frame"
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#description",
    "href": "DeclareDesign/reference/declare_estimator.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclares an estimator which generates estimates and associated statistics.\nUse of declare_test is identical to use of declare_estimator. Use declare_test for hypothesis testing with no specific inquiry in mind; use declare_estimator for hypothesis testing when you can link each estimate to an inquiry. For example, declare_test could be used for a K-S test of distributional equality and declare_estimator for a difference-in-means estimate of an average treatment effect."
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#usage",
    "href": "DeclareDesign/reference/declare_estimator.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_estimator(\n  ...,\n  handler = label_estimator(method_handler),\n  label = \"estimator\"\n)\n\ndeclare_estimators(\n  ...,\n  handler = label_estimator(method_handler),\n  label = \"estimator\"\n)\n\nlabel_estimator(fn)\n\nmethod_handler(\n  data,\n  ...,\n  .method = estimatr::lm_robust,\n  .summary = tidy_try,\n  model,\n  model_summary,\n  term = FALSE\n)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#arguments",
    "href": "DeclareDesign/reference/declare_estimator.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\nfn\nA function that takes a data.frame as an argument and returns a data.frame with the estimates, summary statistics (i.e., standard error, p-value, and confidence interval), and a term column for labeling coefficient estimates.\n\n\ndata\na data.frame\n\n\n.method\nA method function, e.g. lm or glm. By default, the method is the lm_robust function from the estimatr package, which fits OLS regression and calculates robust and cluster-robust standard errors.\n\n\n.summary\nA method-in data-out function to extract coefficient estimates or method summary statistics, such as tidy or glance. By default, the DeclareDesign method summary function tidy_try is used, which first attempts to use the available tidy method for the method object sent to method, then if not attempts to summarize coefficients using the coef(summary()) and confint methods. If these do not exist for the method object, it fails.\n\n\nmodel\nDeprecated argument. Use .method instead.\n\n\nmodel_summary\nDeprecated argument. Use .summary instead.\n\n\nterm\nSymbols or literal character vector of term that represent quantities of interest, i.e. Z. If FALSE, return the first non-intercept term; if TRUE return all term. To escape non-standard-evaluation use !!."
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#details",
    "href": "DeclareDesign/reference/declare_estimator.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\ndeclare_estimator is designed to handle two main ways of generating parameter estimates from data.\nIn declare_estimator, you can optionally provide the name of an inquiry or an objected created by declare_inquiry to connect your estimate(s) to inquiry(s).\nThe first is through label_estimator(method_handler), which is the default value of the handler argument. Users can use standard method functions like lm, glm, or iv_robust. The methods are summarized using the function passed to the summary argument. This will usually be a “tidier” like broom::tidy. The default summary function is tidy_try, which applies a tidy method if available, and if not, tries to make one on the fly.\nAn example of this approach is:\ndeclare_estimator(Y ~ Z + X, .method = lm_robust, .summary = tidy, term = \"Z\", inquiry = \"ATE\")\nThe second approach is using a custom data-in, data-out function, usually first passed to label_estimator. The reason to pass the custom function to label_estimator first is to enable clean labeling and linking to inquiries.\nAn example of this approach is:\nmy_fun <- function(data){ with(data, median(Y[Z == 1]) - median(Y[Z == 0])) }\ndeclare_estimator(handler = label_estimator(my_fun), inquiry = \"ATE\")\nlabel_estimator takes a data-in-data out function to fn, and returns a data-in-data-out function that first runs the provided estimation function fn and then appends a label for the estimator and, if an inquiry is provided, a label for the inquiry."
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#value",
    "href": "DeclareDesign/reference/declare_estimator.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that accepts a data.frame as an argument and returns a data.frame containing the value of the estimator and associated statistics."
  },
  {
    "objectID": "DeclareDesign/reference/declare_estimator.html#examples",
    "href": "DeclareDesign/reference/declare_estimator.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# Setup for examples\ndesign <-\n  declare_model(\n    N = 500,\n    gender = rbinom(N, 1, 0.5),\n    U = rnorm(N, sd = 0.25),\n    potential_outcomes(Y ~ rbinom(\n      N, 1, prob = pnorm(0.2 * Z + 0.2 * gender + 0.1 * Z * gender + U)\n    ))\n  ) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_sampling(S = complete_rs(N = N, n = 200)) +\n  declare_assignment(Z = complete_ra(N = N, m = 100)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# default estimator is lm_robust with tidy summary\ndesign_0 <-\n  design +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\nrun_design(design_0)\n\n  inquiry estimand estimator term estimate  std.error statistic   p.value\n1     ATE     0.13 estimator    Z     0.08 0.06967457  1.148195 0.2522733\n     conf.low conf.high  df outcome\n1 -0.05739947 0.2173995 198       Y\n\n# Linear regression using lm_robust and tidy summary\ndesign_1 <-\n  design +\n  declare_estimator(\n    formula = Y ~ Z,\n    .method = lm_robust,\n    .summary = tidy,\n    term = \"Z\",\n    inquiry = \"ATE\",\n    label = \"lm_no_controls\"\n  )\n\nrun_design(design_1)\n\n  inquiry estimand term      estimator estimate  std.error statistic\n1     ATE     0.09    Z lm_no_controls      0.2 0.06869637  2.911362\n      p.value   conf.low conf.high  df outcome\n1 0.004011144 0.06452955 0.3354705 198       Y\n\n# Use glance summary function to view model fit statistics\ndesign_2 <-\n  design +\n  declare_estimator(.method = lm_robust,\n                    formula = Y ~ Z,\n                    .summary = glance)\n\nrun_design(design_2)\n\n  inquiry estimand estimator  r.squared adj.r.squared statistic    p.value\n1     ATE    0.134 estimator 0.03272727    0.02784206  6.699248 0.01036049\n  df.residual nobs se_type\n1         198  200     HC2\n\n# Use declare_estimator to implement custom answer strategies\nmy_estimator <- function(data) {\n  data.frame(estimate = mean(data$Y))\n}\n\ndesign_3 <-\n  design +\n  declare_inquiry(Y_bar = mean(Y)) +\n  declare_estimator(handler = label_estimator(my_estimator),\n                    label = \"mean\",\n                    inquiry = \"Y_bar\")\n\nrun_design(design_3)\n\n  inquiry estimand estimator estimate\n1   Y_bar    0.585      mean    0.585\n2     ATE    0.100      <NA>       NA\n\n# Use `term` to select particular coefficients\ndesign_4 <-\n  design +\n  declare_inquiry(difference_in_cates = mean(Y_Z_1[gender == 1] - Y_Z_0[gender == 1]) -\n                    mean(Y_Z_1[gender == 0] - Y_Z_0[gender == 0])) +\n  declare_estimator(Y ~ Z * gender,\n                    term = \"Z:gender\",\n                    inquiry = \"difference_in_cates\",\n                    .method = lm_robust)\n\nrun_design(design_4)\n\n              inquiry  estimand     term estimator   estimate std.error\n1 difference_in_cates 0.1438405 Z:gender estimator 0.03587435 0.1412734\n2                 ATE 0.0680000     <NA>      <NA>         NA        NA\n  statistic   p.value   conf.low conf.high  df outcome\n1 0.2539357 0.7998114 -0.2427367 0.3144854 196       Y\n2        NA        NA         NA        NA  NA    <NA>\n\n# Use glm from base R\ndesign_5 <-\n  design +\n  declare_estimator(Y ~ Z + gender,\n                    family = \"gaussian\",\n                    inquiry = \"ATE\",\n                    .method = glm)\n\nrun_design(design_5)\n\n  inquiry estimand estimator term    estimate std.error  statistic   p.value\n1     ATE     0.09 estimator    Z -0.03742684 0.0697923 -0.5362603 0.5923836\n    conf.low  conf.high\n1 -0.1742172 0.09936355\n\n# If we use logit, we'll need to estimate the average marginal effect with\n# margins::margins. We wrap this up in function we'll pass to model_summary\n\nlibrary(margins) # for margins\nlibrary(broom) # for tidy\n\ntidy_margins <- function(x) {\n  tidy(margins(x, data = x$data), conf.int = TRUE)\n}\n\ndesign_6 <-\n  design +\n  declare_estimator(\n    Y ~ Z + gender,\n    .method = glm,\n    family = binomial(\"logit\"),\n    .summary = tidy_margins,\n    term = \"Z\"\n  )\n\nrun_design(design_6)\n\n  inquiry estimand estimator term   estimate  std.error statistic   p.value\n1     ATE     0.09 estimator    Z 0.08129788 0.06943762  1.170805 0.2416773\n     conf.low conf.high\n1 -0.05479735 0.2173931\n\n# Multiple estimators for one inquiry\n\ndesign_7 <-\n  design +\n  declare_estimator(Y ~ Z,\n                    .method = lm_robust,\n                    inquiry = \"ATE\",\n                    label = \"OLS\") +\n  declare_estimator(\n    Y ~ Z + gender,\n    .method = glm,\n    family = binomial(\"logit\"),\n    .summary = tidy_margins,\n    inquiry = \"ATE\",\n    term = \"Z\",\n    label = \"logit\"\n  )\n\nrun_design(design_7)\n\n  inquiry estimand estimator term   estimate  std.error statistic   p.value\n1     ATE    0.036       OLS    Z 0.03000000 0.07103136 0.4223486 0.6732288\n2     ATE    0.036     logit    Z 0.02798436 0.06914018 0.4047481 0.6856627\n    conf.low conf.high  df outcome\n1 -0.1100751 0.1700751 198       Y\n2 -0.1075279 0.1634966  NA    <NA>"
  },
  {
    "objectID": "DeclareDesign/reference/reexports.html#description",
    "href": "DeclareDesign/reference/reexports.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThese objects are imported from other packages. Follow the links below to see their documentation."
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#description",
    "href": "DeclareDesign/reference/declare_test.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDeclares an test which generates a test statistic and associated inferential statistics.\nUse of declare_test is identical to use of declare_estimator. Use declare_test for hypothesis testing with no specific inquiry in mind; use declare_estimator for hypothesis testing when you can link each estimate to an inquiry. For example, declare_test could be used for a K-S test of distributional equality and declare_estimator for a difference-in-means estimate of an average treatment effect.\nSee declare_estimator help for an explanation of how to use method_handler, which is used identically in both declare_estimator and declare_test. The main difference between declare_estimator and declare_test is that declare_test does not link with an explicit inquiry."
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#usage",
    "href": "DeclareDesign/reference/declare_test.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndeclare_test(..., handler = label_test(method_handler), label = \"test\")\n\nlabel_test(fn)"
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#arguments",
    "href": "DeclareDesign/reference/declare_test.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\narguments to be captured, and later passed to the handler\n\n\nhandler\na tidy-in, tidy-out function\n\n\nlabel\na string describing the step\n\n\nfn\nA function that takes a data.frame as an argument and returns a data.frame with test statistics as columns."
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#details",
    "href": "DeclareDesign/reference/declare_test.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nlabel_test takes a data-in-data out function to fn, and returns a data-in-data-out function that first runs the provided test function fn and then appends a label for the test."
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#value",
    "href": "DeclareDesign/reference/declare_test.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA function that accepts a data.frame as an argument and returns a data.frame containing the value of the test statistic and other inferential statistics."
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#examples",
    "href": "DeclareDesign/reference/declare_test.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(DeclareDesign)\n\nLoading required package: randomizr\n\n\nLoading required package: fabricatr\n\n\nLoading required package: estimatr\n\n# Balance test F test\n\nbalance_test_design <-\n  declare_model(\n    N = 100, \n    cov1 = rnorm(N), \n    cov2 = rnorm(N), \n    cov3 = rnorm(N)\n  ) +\n  declare_assignment(Z = complete_ra(N, prob = 0.2)) +\n  declare_test(Z ~ cov1 + cov2 + cov3, .method = lm_robust, .summary = glance)\n  \nlist(\"\\n\", \"diagnosis <- diagnose_design(\\n\", \"  design = balance_test_design,\\n\", \"  diagnosands = declare_diagnosands(\\n\", \"  false_positive_rate = mean(p.value <= 0.05))\\n\", \")\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(\\n\"\n\n[[3]]\n[1] \"  design = balance_test_design,\\n\"\n\n[[4]]\n[1] \"  diagnosands = declare_diagnosands(\\n\"\n\n[[5]]\n[1] \"  false_positive_rate = mean(p.value <= 0.05))\\n\"\n\n[[6]]\n[1] \")\\n\"\n\n# K-S test of distributional equality\n\nks_test <- function(data) {\n  test <- with(data, ks.test(x = Y[Z == 1], y = Y[Z == 0]))\n  data.frame(statistic = test$statistic, p.value = test$p.value)\n}\n\ndistributional_equality_design <-\n  declare_model(\n    N = 100, \n    Y_Z_1 = rnorm(N), \n    Y_Z_0 = rnorm(N, sd = 1.5)\n  ) + \n  declare_assignment(Z = complete_ra(N, prob = 0.5)) + \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) + \n  declare_test(handler = label_test(ks_test), label = \"ks-test\")\n  \nlist(\"\\n\", \"diagnosis <- diagnose_design(\\n\", \"  design = distributional_equality_design,\\n\", \"  diagnosands = declare_diagnosands(power = mean(p.value <= 0.05))\\n\", \") \\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(\\n\"\n\n[[3]]\n[1] \"  design = distributional_equality_design,\\n\"\n\n[[4]]\n[1] \"  diagnosands = declare_diagnosands(power = mean(p.value <= 0.05))\\n\"\n\n[[5]]\n[1] \") \\n\"\n\n# Thanks to Jake Bowers for this example\n\nlibrary(coin) \n\nLoading required package: survival\n\nour_ttest <- function(data) {\n  res <- coin::oneway_test(\n    outcome ~ factor(Xclus),\n    data = data,\n    distribution = \"asymptotic\"\n  )\n  data.frame(p.value = pvalue(res)[[1]])\n}\n\nttest_design <- \n  declare_model(\n    N = 100, \n    Xclus = rbinom(n = N, size = 1, prob = 0.2), \n    outcome = 3 + rnorm(N)) +\n  declare_test(handler = label_test(our_ttest), label = \"t-test\")\n  \nlist(\"\\n\", \"diagnosis <- diagnose_design(\\n\", \"  design = ttest_design,\\n\", \"  diagnosands = declare_diagnosands(\\n\", \"    false_positive_rate = mean(p.value <= 0.05))\\n\", \")\\n\")\n\n[[1]]\n[1] \"\\n\"\n\n[[2]]\n[1] \"diagnosis <- diagnose_design(\\n\"\n\n[[3]]\n[1] \"  design = ttest_design,\\n\"\n\n[[4]]\n[1] \"  diagnosands = declare_diagnosands(\\n\"\n\n[[5]]\n[1] \"    false_positive_rate = mean(p.value <= 0.05))\\n\"\n\n[[6]]\n[1] \")\\n\""
  },
  {
    "objectID": "DeclareDesign/reference/declare_test.html#see-also",
    "href": "DeclareDesign/reference/declare_test.html#see-also",
    "title": "**Declare**Design",
    "section": "See Also",
    "text": "See Also\nSee declare_estimator for documentation of the method_handler function."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DeclareDesign",
    "section": "",
    "text": "DeclareDesign\n\n\n\nDeclare\n\n\n\n\nDiagnose\n\n\n\n\nRedesign\n\n\n\n\n\n\nDeclaring a design means writing down each component of a research design — the model, an inquiry about the model, a data strategy to generate data, and an answer strategy to take the data and return an answer to the inquiry.\n\n\ntwo_arm_trial_design <-\n  declare_model(N = 100,\n                U = rnorm(N),\n                potential_outcomes(Y ~ 0.2 * Z + U)) +\n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  declare_assignment(Z = complete_ra(N, prob = 0.5)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z, inquiry = \"ATE\")\n\n\n\n\n\n\n\nDiagnosing a design means simulating the design many times to learn about its properties. Is the design biased? Is there enough statistical power? How often will you get the sign of the effect wrong?\n\n\ndiagnose_design\n\n\n\n\n\n\n\nRedesigning means exploring how design choices like the number of clusters sampled change the diagnosands (properties) of the design.\n\n\nredesign()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic Documents\nGenerate dynamic output using Python, R, Julia, and Observable. Create reproducible documents that can be regenerated when underlying assumptions or data change.\n\nLearn more »\n\n\n\nBeautiful Publications\nPublish high-quality articles, reports, presentations, websites, and books in HTML, PDF, MS Word, ePub, and more. Use a single source document to target multiple formats.\n\nLearn more »\n\n\n\nScientific Markdown\nPandoc markdown has excellent support for LaTeX equations and citations. Quarto adds extensions for cross-references, figure panels, callouts, advanced page layout, and more.\n\nLearn more »\n\n\n\nAuthoring Tools\nUse your favorite tools including VS Code, RStudio, Jupyter Lab, or any text editor. Use the Quarto visual markdown editor for long-form documents.\n\nLearn more »\n\n\n\nInteractivity\nEngage readers by adding interactive data exploration to your documents using Jupyter Widgets, htmlwidgets for R, Observable JS, and Shiny.\n\nLearn more »\n\n\n\nWebsites and Books\nPublish collections of documents as a blog or full website. Create books and manuscripts in both print formats (PDF and MS Word) and online formats (HTML and ePub).\n\nLearn more »\n\n\n\n\n\n\nDeclare and diagnose your research design – to assess, improve, and communicate about your design\nGet Started"
  },
  {
    "objectID": "blog/declaredesign-blog.html",
    "href": "blog/declaredesign-blog.html",
    "title": "DeclareDesign: The Blog",
    "section": "",
    "text": "Our very first blog post is not here but over at the World Bank Development Impact blog. Big thanks to Berk Özler and colleagues for hosting us there and helping us to spread the word. The Development Impact post introduces the ideas behind design declaration and diagnosis.\nOur first post here will use DeclareDesign to shed light on what has been a point of disagreement between researchers trying to figure out whether there are ever risks of bias arising from taking account of control variables – even “pretreatment” variables – when assessing effects in observational research."
  },
  {
    "objectID": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html",
    "href": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html",
    "title": "You can’t speak meaningfully about spillovers without specifying an estimand",
    "section": "",
    "text": "A dangerous fact: it is quite possible to talk in a seemingly coherent way about strategies to answer a research question without ever properly specifying what the research question is. The risk is that you end up with the right solution to the wrong problem. The problem is particularly acute for studies where there are risks of “spillovers.”\nBy spillovers we mean situations where one unit’s outcome depends upon how another unit is assigned to treatment. You often hear worries that estimates of average treatment effects are biased in the presence of such spillovers. And in particular that when there are positive spillovers, estimates will be biased downwards. Sensible as these worries sound, try to state them formally and you can run into some difficulties. The key issue is that the assumption of no spillovers runs so deep that it is often invoked even prior to the definition of estimands. If you write the “average treatment effect” estimand using potential outcomes notation, as \\(E(Y(1) - Y(0))\\), you are already assuming that a unit’s outcomes depend only on its own assignment to treatment and not on how other units are assigned to treatment. The definition of the estimand leaves no space to even describe spillovers.\nIf there are in fact spillovers, then the estimand needs to be spelled out more carefully. In this case, the range of estimands to choose may be very wide and the appropriateness of different strategies is going to depend on which estimand you are shooting for.\nThis post shows how:\nAlong the way, we show how to modify designs by switching up steps at different points."
  },
  {
    "objectID": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#estimands-given-spillovers",
    "href": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#estimands-given-spillovers",
    "title": "You can’t speak meaningfully about spillovers without specifying an estimand",
    "section": "Estimands given spillovers",
    "text": "Estimands given spillovers\nThere are many different estimands that can take account of spillover effects, if there are any, but that correspond to the usual average treatment effects estimand when there are no spillovers. For instance, we can define the difference for a unit when it—and only it—is treated, compared to a situation in which no unit is treated. In potential outcomes notation that could be written, for unit 3, say, as:\n\\[\\tau_3 = Y(0,0,1,0,0,\\dots) -  Y(0,0,0,0,0,\\dots)\\]\nOne could then define a population estimand that is the average of all these differences over a population. Note that these differences specify different counterfactual assignment vectors for each individual. In the absence of spillovers, this estimand is equivalent to the usual average treatment effect. In the presence of spillovers, this estimand is well defined, whereas the usual average treatment effect estimand is not.\nThere are many other possibilities. For example, the difference in outcomes when no units are treated and all units are treated. Or the difference between not being treated when all others are, and being treated when all others are. Or, the difference a change in your own condition would make given that others are assigned to the value that they actually have (see e.g. Sävje, Aronow, and Hudgens (2017)). In fact, with \\(n\\) units and binary assignments, we can define \\(2^n\\times2^n\\) simple comparisons for each unit.\nBelow, we declare a design that allows for the possibility of spillovers. Diagnosing the design shows how severe the problem of spillovers can be for estimation. Modifying the design lets us explore different types of solutions."
  },
  {
    "objectID": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#how-spillovers-make-defining-and-estimating-average-effects-hard",
    "href": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#how-spillovers-make-defining-and-estimating-average-effects-hard",
    "title": "You can’t speak meaningfully about spillovers without specifying an estimand",
    "section": "How spillovers make defining and estimating average effects hard",
    "text": "How spillovers make defining and estimating average effects hard\nConsider a situation in which units are grouped into triplets, indexed \\(G\\). Suppose that there are 80 triplets. If any member of group \\(G\\) is treated, then all of its members receive some equal benefit (with marginal gains possibly increasing or decreasing in the numbers treated).\nWe can declare this design as follows:1\n\nN_groups <- 80\nN_i_group <- 3\nsd_i <- 0.2\ngamma <- 2\n\nmodel <- declare_model(G = add_level(N = N_groups,\n                                               n = N_i_group),\n                                 i = add_level(N = n, I = 1:N, zeros = 0, ones = 1))\n\ndgp <- function(i, Z, G, n) (sum(Z[G == G[i]])/n[i])^gamma + rnorm(1,0,sd_i)\n\ninquiry <- declare_inquiry(Treat_one = mean(\n                 sapply(I, function(i) dgp(i, I==i, G, n) - dgp(i, zeros, G, n))\n                 ))\n\nassign    <- declare_assignment(Z = complete_ra(N, prob = .5))\n\nmeasurement  <- declare_measurement(Y = sapply(1:N, function(i) dgp(i, Z, G, n)))\n\nestimator <- declare_estimator(Y ~ Z,  model = lm_robust,\n                               label = \"naive\", inquiry = \"Treat_one\")\n\nspillover_design <- model + inquiry + assign + measurement + estimator\n\nThe most complex part of this design declaration involves the specification of the estimand. We define a helper function, dgp, which reports an individual’s outcome given the full treatment assignment vector. We then apply that function to each unit separately and take the average.\nThis design produces data that looks like this:\n\ndraw_data(spillover_design)\n\n\n\n\n\n\nG\nn\ni\nI\nzeros\nones\nZ\nY\n\n\n\n\n01\n3\n001\n1\n0\n1\n1\n1.1426481\n\n\n01\n3\n002\n2\n0\n1\n1\n0.8914236\n\n\n01\n3\n003\n3\n0\n1\n1\n1.1771557\n\n\n02\n3\n004\n4\n0\n1\n0\n0.0413922\n\n\n02\n3\n005\n5\n0\n1\n0\n-0.0904998\n\n\n02\n3\n006\n6\n0\n1\n1\n0.4877476\n\n\n\n\n\nAnd we can diagnose the design like this:\n\ndiagnosis <- diagnose_design(spillover_design)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\n\n\n\n\n0.22\n0.23\n1.00\n0.00\n0.33\n0.05\n0.04\n0.00\n0.11\n\n\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n\n\n\n\n\nWe see considerable bias here because the difference-in-means estimator does not account for within-group spillovers. Many units in the control condition are affected by the treatments received by other members of their group.\nInterestingly, in this case, we have an overestimate of the effect, even though there are positive spillovers. In the assumed model, there are increasing returns to spillovers. Units that are treated are also likely to be in groups with a higher proportion of treated units (since, by definition, at least one member of their group is already treated). On average, treated units thus receive more positive spillover than untreated units, leading to exaggerated estimates."
  },
  {
    "objectID": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#whether-a-sparser-sample-helps-depends-on-the-estimand-of-interest",
    "href": "blog/you-cant-speak-meaningfully-about-spillovers-without-specifying-an-estimand.html#whether-a-sparser-sample-helps-depends-on-the-estimand-of-interest",
    "title": "You can’t speak meaningfully about spillovers without specifying an estimand",
    "section": "Whether a sparser sample helps depends on the estimand of interest",
    "text": "Whether a sparser sample helps depends on the estimand of interest\nThere are multiple solutions to this kind of problem. How well they work depends, however, on how well we understand the structure of spillover effects in the first place.\nOne approach is to alter assignment strategies (see, e.g., Bowers et al. (2018)). An even simpler one is to employ a sparser sample. This approach seems to go against one of the few near-universal principles of research design: study as many units as possible.\nBut here there may be some wisdom to it. Although more units generally means greater precision, there may be a cost to this when there are risks of spillovers. If a larger study means treating more units, and this means more units interfere with each other, you might end up with a spuriously precise, biased estimate.\nHere is an alternative design that implements the original data and analysis strategies on a sample of one subject per group:\n\nsparse_design <- insert_step(spillover_design, after = \"Treat_one\",\n                          declare_sampling(S = strata_rs(strata = G, prob = 1/3)))\n\nNote that it is important that the sampling takes place here after the definition of the estimand. Spillovers operate as a function of population characteristics, not just sample characteristics.\nOur narrower sampling strategy reduces the N by two-thirds (from 240 to 80). But the results are now unbiased. Note that we did not change our original assignment strategy, in which units are assigned to treatment or to control with .5 probability. Rather, we changed the sampling strategy. Before, we kept whole groups and assigned no members or several members to treatment. We now select one member per group and assign them to treatment or to control. Because we only select one member per group, and spillovers only go within and not between groups, there is no way for our treatment or control units to receive spillovers.\nHere is a diagnosis of this sparser design:\n\ndiagnosis <- diagnose_design(sparse_design, sims = sims)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\n\n\n\n\n0.00\n0.05\n0.70\n0.93\n0.11\n0.04\n0.04\n0.00\n0.11\n\n\n(0.00)\n(0.00)\n(0.01)\n(0.01)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n\n\n\n\n\nWe have an unbiased design. Here though getting an unbiased design depended on having a good understanding of the nature of spillovers. In this case, we made use of the fact there would be no spillovers between groups.\nHowever, how good this solution is also depends on what exactly the estimand is. What if the estimand were the average difference in outcomes between a world in which no unit is treated and one in which all units are treated?\nWe answer this question by declaring a new design that adds in the new estimand and links it to the estimator.\nWe first define the steps:\n\nnew_estimand  <- declare_inquiry(Treat_all = mean(\n                  sapply(I, function(i) dgp(i,ones,G,n) - dgp(i, zeros, G,n))\n                  ))\n\nnew_estimator <- declare_estimator(Y ~ Z, model = lm_robust,\n                                   estimand = list(\"Treat_one\", \"Treat_all\"))\n\nWe then splice the steps in where we want them (estimand before the sampling, estimator after the sampling):\n\nsparse_design <- insert_step(sparse_design, after = \"Treat_one\", new_estimand)\nsparse_design <- replace_step(sparse_design, \"naive\", new_estimator)\n\nThe diagnosis highlights how poorly the sampling solution works for this new estimand:\n\ndiagnose_design(sparse_design)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInquiry\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\n\n\n\n\nTreat_all\n-0.89\n0.89\n0.68\n0.00\n0.11\n0.05\n0.04\n0.00\n1.00\n\n\n\n(0.00)\n(0.00)\n(0.01)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n\n\nTreat_one\n0.00\n0.05\n0.68\n0.93\n0.11\n0.05\n0.04\n0.00\n0.11\n\n\n\n(0.00)\n(0.00)\n(0.01)\n(0.01)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n\n\n\n\n\nThe sparser design fails because the treatment density is insufficient to reveal the potential outcomes required by the estimand: you cannot figure out the effects of saturation if you do not saturate.\nA future post will describe approaches to addressing spillovers that work through estimation strategies, rather than through sampling and assignment strategies.\n\nPost edited to reflect name change to spillover_designer() on 11/12/2018."
  },
  {
    "objectID": "blog/pilot-studies.html",
    "href": "blog/pilot-studies.html",
    "title": "Should a pilot study change your study design decisions?",
    "section": "",
    "text": "Data collection is expensive, and we often only get one bite at the apple. In response, we often conduct an inexpensive (and small) pilot test to help better design the study. Pilot studies have many virtues, including practicing the logistics of data collection and improving measurement tools. But using pilots to get noisy estimates in order to determine sample sizes for scale up comes with risks.\nPilot studies are often used to get a guess of the average effect size, which is then plugged into power calculators when designing the full study.\nThe procedure is:\n\nConduct a small pilot study (say, N = 50)\nObtain an estimate of the effect size (this is noisy, but better than nothing!)\nConduct a power analysis for a larger study (say, N = 500) on the basis of the estimated effect size in the pilot\n\nWe show in this post that this procedure turns out to be dangerous: at common true effect sizes found in the social sciences, you are at risk of selecting an underpowered design based on the noisy effect estimate in your pilot study. For a related argument about the dangers of post-hoc power analysis, which inspired this post, see Andy Gelman’s blog.\nA different procedure has better properties:\n\nConduct a small pilot study (say, N = 50)\nObtain an estimate of the standard deviation of the outcome variable (again, this is a noisy estimate but better than nothing!)\nEstimate the minimum detectable effect (MDE) for a larger study (say, N = 500), using the estimated standard deviation\n\nWe show what happens in each procedure, using DeclareDesign. In each case, we’ll think about a decision the researcher wants to make based on the pilot: should I move forward with my planned study, or should I go back to the drawing board? We’ll rely on power to make that decision in the first procedure and the MDE in the second procedure.\nTo get started, we set up a designer1 for a standard two-arm trial where half of units are assigned to treatment and we use a difference-in-means estimator. We will use the same designer to simulate the pilot (N = 50) and the main study (N = 500). The designer lets us change the sample size, the true effect size, as well as the true standard deviation of the outcome (sd_y).\nWe will make use of a function that records estimates of the standard deviation of outcomes in each condition.\n\nsd_estimator <- function(data){\n  data.frame(sd_y_0_hat = sd(data$Y[data$Z == 0]), sd_y_1_hat = sd(data$Y[data$Z == 1]))\n}\n\n\ndesigner <- \n  function(sample_size = 50, true_effect_size = 0, sd_y = 1) {\n  design <- \n    declare_model(\n      N = sample_size, \n      u = rnorm(N, sd = sd_y),\n      potential_outcomes(Y ~ true_effect_size * Z + u)) +\n    declare_assignment(Z = complete_ra(N)) +\n    declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n    declare_estimator(Y ~ Z, model = difference_in_means, label = \"dim\") +\n    declare_estimator(handler = label_estimator(sd_estimator), label = \"sd_estimator\")\n}\n\n\nShould you use your pilot to estimate the effect size for your power analysis?\nWe first simulate the effect size estimates we would get from our small pilot study (N = 50). We look at how our piloting design works at true effect sizes from 0 to 0.5.\n\n# simulate estimated effect sizes from the pilot study\npilot_designs <- \n  expand_design(designer, true_effect_size = seq(from = 0, to = 0.5, by = 0.1))\n\nsimulations_pilot <- simulate_design(pilot_designs, sims = sims)\n\nFor each true effect size, the simulations will give us a distribution of estimated effects that a researcher might use as a basis for power analysis. For example, for a true effect size of 0 the researcher might still estimate an effect of 0.10, and so conduct their power analysis assuming that the true effect is 0.10. For each true effect, we can thus construct a distribution of power estimates a researcher might obtain from estimated effects. Since we know the true power for the true underlying effect, we can compare the distribution of post-hoc power estimates to the true power one would estimate if one knew the true effect size.\n\n# estimate power for the full study for possible estimated effect sizes from the pilot study\n# (exploit fact that power is symmetric so we don't need to calculate power for negative effect sizes)\n\nmax_pilot_estimate <- max(simulations_pilot$estimate, na.rm = TRUE)\n\nstudy_designs <- \n  expand_design(designer, \n                sample_size = 500, \n                true_effect_size = seq(0, max_pilot_estimate, 0.01))\n\ndiagnosis_study <- diagnose_design(study_designs, sims = sims)\n\n\n\n\n\n\n\nWhat did we find? In the plot, we show our guesses for the power of the main study based on our pilot effect size estimates.\nAt high true effect sizes (top row), we do pretty well. Most of our guesses are above 80% power, leading us to the correct decision that the study is powered. Indeed we often underestimate our power in these cases meaning that we run larger studies than we need to.\nHowever, at low true effect sizes (bottom row) we show we are equally likely to find that the design is in fact powered as underpowered. We are equally likely to guess the power of the design is 90% as 10%. There is a good chance that we will falsely infer that our design is well powered just because we happened to get a high estimate from a noisy pilot.\n\n\n\n\n\n\n\nHow about estimating the standard deviation of the outcome?\nNow, let’s look at the second approach. Here, instead of using our pilot study to estimate the effect size for a power calculation, we estimate the standard deviation of the outcome and use this to calculate the main study’s minimum detectable effect. The decision we want to make is: is this MDE small enough to be able to rule out substantively important effects?\nWe calculate the minimum detectable effect size using the approximation from (Gelman and Hill 2006, pg. 441), 2.8 times the estimated standard error. We estimate the standard error using Equation 3.6 from Gerber and Green (2012).\n\nsimulations_pilot <-\n  simulations_pilot %>%\n  mutate(se_hat_full_study = sqrt( sd_y_0_hat^2 / 250  + sd_y_1_hat^2 / 250),\n         mde_hat_full_study = 2.8 * se_hat_full_study)\n\nWe plot the distribution of MDE guesses. At each true effect size, our MDE estimates based on the estimated SD of the outcome variable in the treatment and control groups are unbiased for the true MDE (red dots). In other words, our piloting design will give us a good guess for the MDE of our full study.\n\n\n\n\n\nIn summary, pilot studies can be valuable in planning research for many reasons, but power calculations based on noisy effect size estimates can be misleading. A better approach is to use the pilot to learn about the distribution of outcome variables. The variability of the outcome variable can then be plugged into MDE formulas or even power calculations with, say, the smallest effect size of political, economic, or social importance.\nIn the same spirit, pilot studies could also be used to learn the strength of the correlation between pre-treatment covariates and the outcome variable. With this knowledge in hand, researchers can develop their expectations about how much precision there is to be gained from covariate control or blocking.\n\n\n\n\n\n\n\n\n\nReferences\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.\n\n\nGerber, Alan S., and Donald P. Green. 2012. Field Experiments: Design, Analysis, and Interpretation. WW Norton.\n\nFootnotes\n\n\nA designer is a function that writes designs.↩︎"
  },
  {
    "objectID": "blog/declaredesign-holiday-hiatus.html",
    "href": "blog/declaredesign-holiday-hiatus.html",
    "title": "DeclareDesign Holiday Hiatus",
    "section": "",
    "text": "library(DeclareDesign)\nlibrary(ggplot2)\n\npop <-\n  declare_model(\n    N = 14,\n    X = c(\"H\", \"A\", \"P\", \"P\", \"Y\", \" \", \n          \"H\", \"O\", \"L\", \"I\", \"D\", \"A\", \"Y\", \"S\"),\n    position = N:1,\n    index = match(X, LETTERS)\n  )\n\nggplot(data = pop(), aes(index, position, color = X)) +\n  geom_text(aes(label = X)) +\n  theme_bw() +\n  theme(legend.position = \"none\", axis.title = element_blank())"
  },
  {
    "objectID": "blog/badly-posed-questions.html",
    "href": "blog/badly-posed-questions.html",
    "title": "Some designs have badly posed questions and design diagnosis can alert you to the problem",
    "section": "",
    "text": "How could a question not have an answer? These situations can arise when inquiries depend on variables that do not exist or are undefined for some units. In this post, we’ll look at one way a question might not have an answer, but there are others.\nConsider an audit experiment that seeks to assess the effects of an email from a person indicating that they are a Democrat (versus not revealing their party identification) on whether and how well election officials respond to requests for information. Whether or not a response is sent is easily observed and measured. The quality of the response is harder to measure, though some aspects, like the tone of the response, can be measured by human coders or possibly computers if fed enough training data.\nMore difficult than the measurement problem, though, is the problem of the “tone” of responses never sent. Simply dropping such observations is no good, because of the possibility that some officials would have responded in one condition but not in the other. After all, a main purpose of audit experiments is to measure the average effect of treatment on response rates, which requires believing that at least some officials would respond in one condition but not another.\nFor that kind of subject (so called if-treated or if-untreated responders), the effect of treatment on the tone of their email is undefined. It doesn’t exist. The question, “what is the effect of treatment on tone” has no answer if, in either the treatment or control condition, the subject wouldn’t respond. That question is only well-defined for subjects who always respond, regardless of treatment.\nTo summarize:\n\nIf treatment affects whether or not a subject responds, then the treatment effect on tone is undefined.\nThe average treatment effect (ATE) of treatment on tone is also undefined, because that estimand averages over all subjects.\nThe conditional average treatment effect (CATE) of treatment among “Always-responders” is well-defined.\n\n\nDesign delaration in words\nHere are the key parts of the design:\n\nModel: The model has two outcome variables, \\(R_i\\) and \\(Y_i\\). \\(R_i\\) stands for “response” and is equal to 1 if a response is sent, and 0 otherwise. \\(Y_i\\) is the tone of the response, which we’ll measure on a 1-7 “friendliness” scale. \\(Z_i\\) is the treatment indicator and equals 1 if the email indicates the sender is a Democrat and 0 otherwise. The table below describes four possible types of subjects who differ in terms of the potential outcomes of \\(R_i\\).\n\nAlways-responders (ARs) always respond, regardless of treatment\nIf-untreated responders (IURs) respond if and only if they are not treated\nIf-treated responders (ITRs) respond if and only if they are treated\n\nNever-responders (NRs) never respond, regardless of treatment\n\n\nThe table also includes columns for the potential outcomes of \\(Y_i\\), showing which potential outcome subjects would express depending on their type. The key thing to note is that for all types except Always-responders, the effect of treatment on \\(Y_i\\) is undefined because messages never sent have no tone.1 The last (and very important) feature of our model is that the outcomes \\(Y_i\\) are possibly correlated with subject type. Even though both \\(E[Y_i(1) | \\text{Type} = AR]\\) and \\(E[Y_i(1) | \\text{Type} = ITR]\\) exist, there’s no reason to expect that they are the same.\n\nCausal Types\n\n\n\n\n\n\n\n\n\nType\n\\(R_i(0)\\)\n\\(R_i(1)\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\nAlways-responders (ARs)\n1\n1\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\nIf-untreated responders (IURs)\n1\n0\n\\(Y_i(0)\\)\nNA\n\n\nIf-treated responders (ITRs)\n0\n1\nNA\n\\(Y_i(1)\\)\n\n\nNever-responders (NRs)\n0\n0\nNA\nNA\n\n\n\n\nInquiry: We have two inquiries. The first is straightforward: \\(E[R_i(1) - R_i(0)]\\) is the Average Treatment Effect on response. The second inquiry is the undefined inquiry that does not have an answer: \\(E[Y_i(1) - Y_i(0)]\\). We will also consider a third inquiry, which is defined: \\(E[Y_i(1) - Y_i(0) | \\text{Type} = AR]\\), which is the average effect of treatment on tone among Always-Responders.\nData strategy: The data strategy will be to use complete random assignment to assign 250 of 500 units to treatment.\nAnswer strategy: We’ll try to answer all three inquiries with the difference-in-means estimator.\n\nThis design can be declared formally like this:\n\ndesign <-\n# M: Model ----------------------------------------------------------------\n  declare_model(\n    N = 500,\n    noise = rnorm(N),\n    type = sample(1:4, N, replace = TRUE),\n    AR = type == 1,\n    IUR = type == 2,\n    ITR = type == 3,\n    NR = type == 4,\n    \n    # potential outcomes\n    # AR and IUR types report in the control condition\n    R_Z_0 = AR | IUR,\n    # R and ITR types report in the treatment condition\n    R_Z_1 = AR | ITR,\n    # In control, ARs and IURs have different outcomes\n    Y_Z_0 = ifelse(R_Z_0, as.numeric(draw_likert(-0.50 * IUR + noise)), NA),\n    # In treatment, ARs and ITRs have different outcomes, and AR outcomes are higher\n    Y_Z_1 = ifelse(R_Z_1, as.numeric(draw_likert(-0.25 * ITR + noise + 0.25)), NA)\n  ) +\n  \n# I: Inquiry --------------------------------------------------------------\n  declare_inquiry(\n    ATE_R = mean(R_Z_1 - R_Z_0),\n    ATE_Y = mean(Y_Z_1 - Y_Z_0),\n    CATE_Y_AR = mean(Y_Z_1[AR] - Y_Z_0[AR])\n  ) +\n  \n# D: Data Strategy --------------------------------------------------------\n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(R = reveal_outcomes(R ~ Z),\n                      Y = reveal_outcomes(Y ~ Z)) +\n# Answer Strategy ---------------------------------------------------------\n  declare_estimator(R ~ Z, inquiry = \"ATE_R\", label = \"DIM_R\") +\n  declare_estimator(\n    Y ~ Z, inquiry = list(\"ATE_Y\", \"CATE_Y_AR\"), label = \"DIM_Y\")\n\n\n\nSimulations\nHere we simulate the design, diagnose, and plot the resulting output.\n\nsimulations <- simulate_design(design, sims = sims)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nInquiry\nEstimator\nOutcome\nTerm\nN Sims\nMean Estimate\nMean Estimand\nBias\nCoverage\nPower\n\n\n\n\ndesign\nATE_R\nDIM_R\nR\nZ\n500\n0.00\n0.00\n0.00\n1.00\n0.07\n\n\n\n\n\n\n\n\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n(0.01)\n\n\ndesign\nATE_Y\nDIM_Y\nY\nZ\n500\n0.38\nNA\nNA\nNA\n0.81\n\n\n\n\n\n\n\n\n(0.01)\nNA\nNA\nNA\n(0.01)\n\n\ndesign\nCATE_Y_AR\nDIM_Y\nY\nZ\n500\n0.38\n0.25\n0.13\n0.85\n0.81\n\n\n\n\n\n\n\n\n(0.01)\n(0.00)\n(0.01)\n(0.02)\n(0.01)\n\n\n\n\n\nWe learn three things from the design diagnosis.\n\nFirst, as expected, our experiment is unbiased for the average treatment effect on response (ATE_R)\nSecond, our second inquiry (ATE_Y), as well as our diagnostics for it, are undefined. The diagnosis tells us that our definition of potential outcomes produces a definition problem for the estimand. Note that some diagnosands are defined, including power, but none of the diagnosands that depend on the value of the estimand (bias, coverage, rmse) can be calculated.\nThe third estimand (CATE_Y_AR) is defined but the estimator is biased. The reason is that we cannot tell from the data which types are the \\(AR\\) types; we are not conditioning on the correct subset. Indeed, we are unable to do so. If a subject responds in the treatment group, we don’t know if she is a \\(AR\\) or a \\(ITR\\) type; in the control group, we can’t tell if a responder is an \\(AR\\) or an \\(IUR\\) type. Our difference-in-means estimator of the CATE on \\(Y\\) among \\(AR\\)s will be off whenever \\(AR\\)s have different outcomes from \\(ITR\\)s and \\(IUR\\)s.\n\nThere are some solutions to this problem. In some cases, the problem might be resolved by changing the inquiry. Closely related estimands can often be defined, perhaps by redefining \\(Y\\) (e.g., emails never sent have a tone of zero). See Coppock (2019) for a more detailed discussion of solutions that may work for different research scenarios.\n\n\nOther instances of this problem\nThis kind of problem is surprisingly common. Consider the instances below:\n\n\\(Y\\) is the decision to vote Democrat (\\(Y=1\\)) or Republican (\\(Y=0\\)), \\(R\\) is the decision to turn out to vote and \\(Z\\) is a campaign message. The decision to vote may depend on treatment but if subjects do not vote then \\(Y\\) is undefined.\n\\(Y\\) is the weight of infants, \\(R\\) is whether a child is born and \\(Z\\) is a maternal health intervention. Fertility may depend on treatment but the weight of unborn (possibly never conceived) babies is not defined.\n\\(Y\\) is the charity to whom contributions are made during fundraising and \\(R\\) is whether anything is contributed and \\(Z\\) is an encouragement to contribute. The identity of beneficiaries is not defined if there are no contributions.\n\nAll of these examples exhibit a form of post-treatment bias but the issue goes beyond picking the right estimator. Our problem here is conceptual: the effect of treatment on the outcome just doesn’t exist for some subjects. This means that design that is not “diagnosand-complete” in the sense we discuss in this paper. But interestingly, we think, the incompleteness is not obvious. You could implement the design and do your analysis on the data from this design without realizing that the estimand is badly defined. Declaration and diagnosis can alert you to the problem.\n\n\n\n\n\n\n\n\n\nReferences\n\nCoppock, Alexander. 2019. “Avoiding Post-Treatment Bias in Audit Experiments.” Journal of Experimental Political Science 6 (1): 1–4.\n\nFootnotes\n\n\nThis can of course be avoided if one is willing to speculate on what tone would be were a response given in a treatment condition by an individual who would not respond in that condition.↩︎"
  },
  {
    "objectID": "blog/ordered-probit.html",
    "href": "blog/ordered-probit.html",
    "title": "Estimating Average Treatment Effects with Ordered Probit: Is it worth it?",
    "section": "",
    "text": "For the design declaration we assume that the estimand of interest is the average treatment effect on the scale of the data. We do this, perhaps contentiously, even though our outcome is defined on a 1 to 5 ordinal scale. The estimand can be thought of as the average number of steps up or down induced by treatment. This estimand has to be interpreted cautiously, however. In particular it presupposes an interest in outcomes in terms of “steps.” But the “size” of steps depends on the categories provided. Adding in an extra option in the middle of a scale, for example, changes the range of the scale and changes the value of the estimand. Given these issues, other estimands are possible and perhaps preferable (Volfovsky, Airoldi, and Rubin 2015), but for this design, we’ll focus on the ATE.\nSurprisingly, perhaps, we find no real difference between the model-based ordinal logit approach and the differences in means approach. The ordered probit is much more complicated to implement and to draw inferences from: the model is estimated using maximum likelihood, simulation is then used to generate a distribution of fitted values, from which a simulation of the distribution of treatment effects is produced. The standard deviation of these differences is used as an estimate of the standard deviation of treatment effects. The Zelig package (Choirat et al. 2018) makes it easy to do all this quite compactly and turn it all into a step in our design.\nWe call the zelig library, set some parameters, and define a function to take data in and return results.\n\nlibrary(Zelig)\nlibrary(ZeligChoice)\n\n# This helper function implements an ordered probit model using zelig; calculates \n# quantities of interest and return tidy output\n\nordered_probit <-\n  \n  function(data) {\n    zelig_out <- zelig(Y ~ Z, model = \"oprobit\", data = data, cite = FALSE)\n    \n    sim_out <- sim(zelig_out, x = setx(zelig_out, Z = 0), x1 = setx(zelig_out, Z = 1))\n    \n    zelig_df <- zelig_qi_to_df(sim_out)\n    \n    predictions <- with(zelig_df,\n                        (X1 + 2 * X2 + 3 * X3 + 4 * X4 + 5 * X5)[Z == 1] -\n                        (X1 + 2 * X2 + 3 * X3 + 4 * X4 + 5 * X5)[Z == 0])\n    \n    return_dat <-\n      data.frame(term = \"Z\",\n                 estimate = mean(predictions),\n                 std.error = sd(predictions),\n                 conf.low = quantile(predictions, .025),\n                 conf.high = quantile(predictions, .975))\n    }\n\n\nWe can now declare the design:\n\nordered_probit_design <- \n  \n  declare_model(\n    N = 200, \n    noise = rnorm(N),\n    potential_outcomes(Y ~ draw_ordered(1 * Z + noise, breaks = c(0, 0.75, 1, 1.25)))\n  ) + \n      \n  declare_assignment(Z = complete_ra(N)) +\n  \n  declare_inquiry(ate = mean(Y_Z_1 - Y_Z_0)) +\n  \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  \n  declare_estimator(Y ~ Z, inquiry = \"ate\", label = \"DIM\") +\n  \n  declare_estimator(handler = label_estimator(ordered_probit), inquiry = \"ate\", label = \"Ordered Probit\")\n\nSample treatment/outcome data look like this:\n\n\n\n\n\nDiagnosis goes like this:\n\ndiagnose_design(ordered_probit_design)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimator\nTerm\nN Sims\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\n\n\n\n\nDIM\nZ\n1000\n-0.00\n0.18\n1.00\n0.97\n1.35\n0.20\n0.20\n0.00\n1.35\n\n\n\n\n\n(0.01)\n(0.00)\n(0.00)\n(0.01)\n(0.01)\n(0.00)\n(0.00)\n(0.00)\n(0.00)\n\n\nOrdered Probit\nZ\n1000\n-0.03\n0.18\nNA\n0.93\n1.33\n0.19\n0.18\nNA\n1.35\n\n\n\n\n\n(0.01)\n(0.00)\nNA\n(0.01)\n(0.01)\n(0.00)\n(0.00)\nNA\n(0.00)\n\n\n\n\n\nNext, we show a histogram of the difference-in-means and ordered probit estimates of the average treatment effect.\n\n\n\n\n\nStrikingly, difference-in-means and inferences using an ordered probit model perform very similarly.1 We often reach for ordered models to accomodate the fact that the outcome variable is ordinal and not cardinal, but if your goal is to estimate the average shift in outcomes in terms of shifts in points on the outcome variable you might be making more assumptions than you need.\nTo be clear, the point is not that there is no need to model the data properly. Modelling data generating processes lets you answer questions that difference-in-means does not. For example, assuming the model is correct, you get an estimate for treatment effects on a latent variable. Or you can ask how a treatment affects the probability of moving from a “3” to a “4” on this scale. So there may well be good reasons to use tailored models to model elaborate data generating processes, and buying the assumptions they require. But estimating average treatment effects doesn’t appear to be one of them.\n\n\n\n\n\n\n\n\nReferences\n\nChoirat, Christine, James Honaker, Kosuke Imai, Gary King, and Olivia Lau. 2018. Zelig: Everyone’s Statistical Software. http://zeligproject.org/.\n\n\nVolfovsky, Alexander, Edoardo M. Airoldi, and Donald B. Rubin. 2015. “Causal Inference for Ordinal Outcomes.”\n\nFootnotes\n\n\nThe ordered probit estimates are very slightly biased. The bias disappears as the sample size increases.↩︎"
  },
  {
    "objectID": "blog/a-journal-of-null-results-is-a-flawed-fix-for-a-significance-filter.html",
    "href": "blog/a-journal-of-null-results-is-a-flawed-fix-for-a-significance-filter.html",
    "title": "A journal of null results is a flawed fix for a significance filter",
    "section": "",
    "text": "Two distinct problems arise if only significant results are published:\n\nThe results of published studies will be biased towards larger magnitudes.\nThe published studies will be unrepresentative of the distribution of true effects in the relevant population of studies.\n\nThese two problems are quite distinct. The first problem is more familiar: conditional on any true effect size, larger estimates have an easier time passing the statistical significance filter, so the distribution of published results will be biased upwards because it will be missing all of the smaller estimates. The second problem is more subtle. If different studies seek to measure effects that are of different size, conditioning on statistical significance means that we are more likely to learn from places that have large effects than from places that have small effects. The significance filter means that our answers to any particular question will be biased and it means that the set of questions we see answers to will be biased as well. The Journal of Significant Results is a poor guide to the true distribution of causal effects.\nWhat about a Journal of Null Results? Such a journal would condition acceptance on failing to achieve statistical significance. The set of articles published in such a journal would also be biased. We’ll explore this idea with a quick simulation.\nThe two_arm_designer function in the DesignLibrary package generates designs for a basic two-arm trial in which, by default, half the units are assigned to treatment and the remainder to control. (See ?two_arm_designer for more details.) We’ll use this function to make a sequence of designs. We’ll vary the true value of the estimand, the average treatment effect (ate), from 0 to 1 and we’ll consider two sample sizes, N = 20 and N = 200.\n\nlibrary(DesignLibrary)\ndesigns     <- expand_design(two_arm_designer, \n                             ate = seq(0, 1, 0.1), N = c(20, 200))\nsimulations <- simulate_design(designs)\n\n\n\n\nThe data.frame simulations records results from running these designs many times—equivalent here to implementing many independent studies from a large population of possible studies. The figure shows a scatterplot of the estimand versus the estimate for each run of the study. We facet by whether we condition on significance, nonsignificance, or nothing at all.\n\n\n`summarise()` has grouped output by 'N'. You can override using the `.groups`\nargument.\n\n\n\n\n\nScatterplots of estimates against estimands (ranging between 0 and 1) for N = 20 and N = 200. Thick lines show mean values. If vertical and horizontal thick lines cross on the 45 degree line then estimates correspond to estimands on average.\n\n\n\n\nLooking first at the Journal of Significant Results, we see the familiar problem: the average estimate is biased away from the true value of the estimand. This problem is greatly helped by increasing the sample size. But we can also see the second problem – the distribution of estimands (the true effects under study) is also biased towards larger effects, this problem is also allayed, though less dramatically, by larger sample sizes.\nThe Journal of Null Results suffers from a parallel problem, only in reverse. Now estimands are smaller than is typical in the population and, on average, estimates are biased down relative to these estimands. Strikingly, the bias in estimand selection is worse at the larger sample size (though downwards bias within the set of published studies is smaller).\nNow, we agree that proactively publishing null results may help when considering entire research literatures as a whole, and for this reason alone a Journal of Null Results is probably a good thing.\nBut, better would be to not do any conditioning at all. The Journal of Interesting Designs would condition only on the question being interesting and the design being appropriate to answering the question. We see that the distribution of estimates and estimands are both centered on the correct average value. \n\n\nCode to produce figure\nFor those who are interested, here is the code to produce the above figure.\n\nlibrary(tidyverse)\n\nlevels <- c(\"Estimate is significant \\n (Journal of Significant Results)\", \n            \"Estimate is not significant \\n (Journal of Null Results)\", \n            \"No significance filter \\n (Journal of Interesting Designs)\")\n\nsims_1 <- simulations %>% mutate(filter = if_else(p.value < 0.05, levels[1], levels[2]))\n\nsims_2 <- simulations %>% mutate(filter = levels[3])\n\ngg_df <- bind_rows(sims_1, sims_2) %>%\n  mutate(N = paste0(\"N = \", N), filter = factor(filter, levels = levels))\n\nsummary_df <- gg_df %>%\n  group_by(N, filter) %>%\n  summarise(mean_estimand = mean(estimand),\n            mean_estimate = mean(estimate))\n\nggplot(gg_df, aes(x = estimand, y = estimate, color = filter)) +\n  geom_point(alpha = 0.1) +\n  geom_vline(data = summary_df, aes(xintercept = mean_estimand), size = 1.2, alpha = 1, color = \"darkgrey\") +\n  geom_hline(data = summary_df, aes(yintercept = mean_estimate), size = 1.2, alpha = 1, color = \"darkgrey\") +\n  scale_colour_brewer(type = \"qual\") +\n  geom_abline() +\n  geom_vline(xintercept = 0.5) +\n  facet_grid(N ~ filter) +\n  coord_cartesian(xlim = c(-0.5, 1.5), ylim = c(-0.5, 1.5)) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        strip.background = element_blank()) +\n  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank())"
  },
  {
    "objectID": "blog/how-controlling-for-pretreatment-covariates-can-introduce-bias.html",
    "href": "blog/how-controlling-for-pretreatment-covariates-can-introduce-bias.html",
    "title": "How controlling for pretreatment covariates can introduce bias",
    "section": "",
    "text": "This has been a question of some disagreement, with Rosenbaum (2002), for instance, arguing that “there is little to no reason to avoid adjustment for a true covariate, a variable describing subjects before treatment,” and Greenland, Pearl, and Robins (1999) and others arguing that you cannot answer this question without a causal model of how \\(Z\\) relates to \\(X\\) and \\(Y\\). See also this discussion hosted by Andy Gelman. Controlling for pretreatment covariates in a randomized experiment usually can’t hurt and usually increases precision – but what about in an observational study in which pretreatment covariates might be correlated with both the (nonrandomly assigned) treatment and the outcome?\nDesign declaration and diagnosis makes it relatively simple to examine the kinds of cases that worry Greenland et al and see where risks of bias might come from.\nLet’s declare a design with a model of the form:\n\n\\(X = f_1(U_1, U_2)\\)\n\\(Z = f_2(U_2)\\)\n\\(Y = f_3(Z, U_1)\\)\n\nIn this world, \\(X\\) is a function of background unobserved variables \\(U_1\\) and \\(U_2\\), a treatment variable \\(Z\\) is a function of \\(U_2\\), and an outcome \\(Y\\) is a function of \\(Z\\) and \\(U_1\\). We can assume that that \\(X\\) is determined prior to \\(Z\\). We will use two answer strategies, both regression based approaches, one with a control and one without.1 Here is the full declaration:\n\n# Parameters\nb <- 1\nN <- 40\n\n# Declaration\nmodel <- declare_model(N = N, U_1 = rnorm(N), U_2 = rnorm(N),\n                       X = U_1 + U_2, Z  = 1 * (U_2 > 0),\n                       potential_outcomes(Y ~ b * Z + U_1))\ninquiry     <- declare_inquiry(ate = mean(Y_Z_1 - Y_Z_0))\nmeasurement <- declare_measurement(Y = reveal_outcomes(Y ~ Z))\nanswer_1    <- declare_estimator(Y ~ Z, inquiry = \"ate\",\n                                 model = lm_robust, label = \"No control\")\nanswer_2    <- declare_estimator(Y ~ Z + X, inquiry = \"ate\",\n                                 model = lm_robust, label = \"With control\")\n\ndesign <- model + inquiry + measurement + answer_1 + answer_2\n\nHere is the diagnosis:\n\ndiagnosis <- diagnose_design(design)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nInquiry\nEstimator\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\n\n\n\n\ndesign\nate\nNo control\n-0.00\n0.31\n0.86\n0.95\n1.00\n0.31\n0.32\n0.00\n1.00\n\n\ndesign\nate\nWith control\n-1.17\n1.18\n0.14\n0.00\n-0.17\n0.17\n0.17\n0.98\n1.00\n\n\n\n\n\nWe see that the estimator without controls is unbiased while the one with controls is very biased. Clearly, introducing a control was a mistake, even though the control was pretreatment.\nThe reason why the estimator without controls is unbiased is simple enough: \\(U_2\\) is correlated with \\(X\\) and \\(Y\\) (via \\(Z\\)), however it is not correlated with \\(Y\\) given \\(Z\\). Indeed, in the model given, it is as if \\(Z\\) is randomly assigned by \\(U_2\\).\nThe reason why the estimator with controls behaves so poorly is not as obvious. Conditioning on \\(X\\) introduces a correlation between \\(Y\\) and \\(Z\\) that is not due to the effect of \\(Z\\) on \\(Y\\). In the language used by researchers working with graphical causal models, \\(X\\) is a “collider” for \\(U_1\\) and \\(U_2\\). Conditioning on \\(X\\) creates a “backdoor path” between \\(Z\\) and \\(Y\\), inducing a correlation between them that is not a result of the causal effect.\nFor a little more intuition, we can modify the design to look at a world in which \\(Z\\) does not affect \\(Y\\):\n\nnull_design <- redesign(design, N = 5000, b = 0)\n\n\n\n\n\n\n\nDiagnosis yields:\n\n\n\n\n\nestimator\nbias\n\n\n\n\nNo control\n0.00\n\n\nWith control\n-1.17\n\n\n\n\n\nWe still observe bias. To see where this bias is coming from, let us draw data from this design and plot the relationship between \\(Z\\) and \\(Y\\). Doing so lets us see how \\(Z\\) and \\(Y\\) relate to to each other for different values of \\(X\\).\n\ndraw_data(null_design) %>%\n  ggplot(aes(X, Y, color = as.factor(Z))) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = seq(-4, 4, 2)) +\n  scale_color_manual(values = c(\"blue\", \"red\"))\n\n\n\n\nNote: Correlation between Z and Y introduced by controlling for X.\n\n\n\n\nWhat we see here is that, overall, the red points are no higher or lower than the blue points — indicating no treatment effect. Yet within any vertical band (i.e., keeping \\(X\\) fixed), the blue dots are generally higher than the red dots. Conditioning induces a non-causal correlation.\nThe implication is quite a deep one: models of data generating processes are sometimes required in order to justify the choice of statistical models.\n\n\n\n\n\n\n\n\nReferences\n\nGreenland, Sander, Judea Pearl, and James M Robins. 1999. “Causal Diagrams for Epidemiologic Research.” Epidemiology, 37–48.\n\n\nRosenbaum, Paul R. 2002. Observational Studies. Springer.\n\nFootnotes\n\n\nIn contrast to the regression approach examined here, Bayesian approaches that model the causal structure could use information on \\(X\\) without introducing the kinds of problems presented here.↩︎"
  },
  {
    "objectID": "blog/declaredesign-wizard.html",
    "href": "blog/declaredesign-wizard.html",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "",
    "text": "DeclareDesign is a collection of tools to help you “declare” and “diagnose” research designs. In a word, with the DeclareDesign packages you can quickly state the core analysis-relevant features of a research design, and in return you will get a diagnosis that tells you how well your design is likely to perform and how changes in the design could improve performance.\nThat’s the good news. The bad news is that ‘DeclareDesign’ is all set up in R. Great for some, but a dealbreaker for many.\nThat’s why we created DDWizard. DDWizard is a (shiny) web interface that lets you select any design from a growing library of templates, the DesignLibrary, customize them, and interrogate them. All without ever having to write any R code.\nThe wizard has a Design tab and a Diagnose tab. The Design tab lets you load and customize a design; the Diagnose tab lets you interrogate the design—generating nice plots showing how the design performs compared to other similar designs.\nIt’s still in beta but you can already do a lot. We would love it if you tried it out and sent us feedback to improve it (see the end of post).\nTo get started immediately with the simplest design, head to https://eos.wzb.eu/ipi/DDWizard/ and load the “Two Arm” design. Click over to the Diagnose tab and select “Run diagnoses and update plot” to start learning about a very simple experiment with one treatment condition and one control condition."
  },
  {
    "objectID": "blog/declaredesign-wizard.html#create-a-design",
    "href": "blog/declaredesign-wizard.html#create-a-design",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "1 Create a design",
    "text": "1 Create a design\nThe DeclareDesign library has templates (“designers”) for generating many common designs. In each case a complete design usually requires specifying a model of how the world works, inquiries (estimands), data strategies (sampling and assignment) and answer strategies (estimates) (see here for more detail).\nEach designer in the library can make a class of designs based on the arguments you provide. The library includes simple experimental designers, as well as designers for factorial and multiarm experiments. It also has designers for observational studies, such as regression discontinuity designs or instrumental variables designs. And it even has some designers for simple qualitative studies, such as process tracing.\nSuppose for instance you were interested in a 2-by-2 factorial design. The “Two by Two” designer in the library lets you specify the sample size, mean outcomes and standard deviations in each outcome cell, and the assignment probability for each factor (prob A, prob B). You can also specify how your estimand weights the effects across arms (weight A, weight B). Other designers allow different arguments; in the multiarm designer for example you can specify the number of arms you have and then provide arguments related to each arm. (Click the Read more button for details on each designer).\nOnce you plug in the values you want, the interface generates the code for the design and you can start putting it to work.\n\n\n\nFigure 1: The ‘Design’ tab. We have chosen a “Two by Two” factorial design (upper left panel) and selected a set of common features (lower left panel). The design code is printed in the middle panel under ‘Code output.’ In addition to viewing code you can examine sample data and view a summary of a run of the design. We can then move on to the design ‘Diagnosis’ panel. Arguments that are “fixed” in ‘Design’ tab the are hard coded (cannot be easily changed in the code or subject to variation in the ‘Diagnosis’ tab)."
  },
  {
    "objectID": "blog/declaredesign-wizard.html#diagnose-and-improve-your-design",
    "href": "blog/declaredesign-wizard.html#diagnose-and-improve-your-design",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "2. Diagnose and improve your design",
    "text": "2. Diagnose and improve your design\nFor any design selected, you can use the diagnosis tab to further inspect design properties such as power, bias, and root mean squared error (RMSE) under different values of one or more parameters. Interactive graphs and tables make it easy to visualize trends and trade-offs between alternative design specifications.\nAs you do so you can also generate fancy figures to display your diagnoses, varying up to three design parameters at at time.\n\n\n\nFigure 2: The ‘Diagnosis’ tab. Sample graph showing how expected RMSE depends on N, the standard error, and the covariance of potential outcomes (\\(\\rho\\)).\n\n\nTo generate plots:\n\nProvide the values you want (you can give value to any parameters that are not “fixed”—see middle panel).\nChoose the parameter to appear on the x-axis and any other parameters to be displayed in the color aesthetics (optional) or along different plots (optional). (These last two options are only available when multiple parameters are being varied in the diagnosis).\nDownload the graph as .png OR download the code needed to generate the plot and the relevant data as an .R file. If you do this you can further tailor the design in any way you like."
  },
  {
    "objectID": "blog/declaredesign-wizard.html#share-your-design",
    "href": "blog/declaredesign-wizard.html#share-your-design",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "3. Share your design",
    "text": "3. Share your design\nOnce you generate a design there are three ways to share it with others.\n\nYou can download the design as an .rds. This stores a design object that can be shared with R-speaking colleagues.\nYou can download the code for the design and share that as an ‘.R’ script. That’s a good option if you want to put a design declaration in a pre-analysis plan, for example.\nYou can send a link to your design. This is a more flexible option: Declare a design, hit the “Share” link in the top right corner, and send a colleague the URL. They should be brought back to the DDWizard and get to a page with all your design tailoring preserved. The idea here is that even if you are an R user you might want to share your design with colleagues who are not: in this case you can point them directly to your design in a way that lets them examine and interrogate it."
  },
  {
    "objectID": "blog/declaredesign-wizard.html#use-it-for-teaching",
    "href": "blog/declaredesign-wizard.html#use-it-for-teaching",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "4. Use it for teaching",
    "text": "4. Use it for teaching\nMany designers in the DesignLibrary let you illustrate how design-based inferences depend on specific model assumptions. This can be useful for teaching. For example, the “Binary IV” design arguments can be defined in such a way that violates one or more assumptions for a strong instrumental variable. Similarly, the “Mediation” design lets you explore design properties under the violation of sequential ignorability and heterogeneous effects. Simulating and diagnosing such designs helps illustrate the magnitude and direction of bias and other properties when each assumption is violated separately, as well as what estimates are affected by or perform best under these scenarios."
  },
  {
    "objectID": "blog/declaredesign-wizard.html#move-beyond-the-library-use-the-ddwizard-as-an-interface-for-your-own-designs",
    "href": "blog/declaredesign-wizard.html#move-beyond-the-library-use-the-ddwizard-as-an-interface-for-your-own-designs",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "5. Move beyond the library: Use the DDWizard as an interface for your own designs",
    "text": "5. Move beyond the library: Use the DDWizard as an interface for your own designs\nFor more advanced R and DeclareDesign users, the DDWizard can serve as an interactive interface for exploring the properties of any custom-made designer function.\nTo do this locally:\n\nMake a copy of the DesignLibrary repository here\nAdd new designer function(s) to the library in the \"R/\" directory of the package (tips) and rebuild the package locally;\nDownload or clone the DDWizard repository on Github here and run shiny::runApp() on the app directory.\n\nA version of the DDWizard should then run locally with new function(s) from your DesignLibrary version appearing in the dropdown menu below Choose design.\nEven better, you can use pull requests to contribute your designers to the DesignLibrary package in which case they will be available for everyone via the web app (the DDWizard is routinely updated to include the latest version of the DesignLibrary). See instructions here"
  },
  {
    "objectID": "blog/declaredesign-wizard.html#feedback",
    "href": "blog/declaredesign-wizard.html#feedback",
    "title": "Now there is a web interface for declaring and diagnosing research designs",
    "section": "Feedback",
    "text": "Feedback\nThe DDWizard is still under development and we want to make it better.\n\nPlease report issues and make feature requests via this google form.\nOr contribute to developing the app on our Github repository.\nOr ask questions about DeclareDesign more generally on our discussion board."
  },
  {
    "objectID": "blog/bias-cluster-randomized-trials.html",
    "href": "blog/bias-cluster-randomized-trials.html",
    "title": "Cluster randomized trials can be biased when cluster sizes are heterogeneous",
    "section": "",
    "text": "For intuition, imagine two clusters, one of size 1,000,000 and the other of size 1. Say that outcomes are 0 in both clusters in the control condition, but that in the treatment condition they are 0 in the big cluster and 1 in the small one. Then the average treatment effect is about 0 (really: 1/1,000,000). But depending on which cluster is assigned to treatment one will (using difference-in-means) estimate either 0 or 1. So the expected estimate is 0.5. Far from the truth.\nThe Horvitz-Thompson estimator is an alternative to difference-in-means and does not have this problem. Using Horvitz-Thompson, one would estimate either \\(\\frac{1}{10^6}\\left(\\frac{1}{0.5} - \\frac{0}{0.5}\\right)\\) or \\(\\frac{1}{10^6}\\left(\\frac{0}{0.5} - \\frac{0}{0.5}\\right)\\) and so get it right in expectation. In practice however, researchers often avoid Horvitz-Thompson since it can produce estimates outside of the ranges of the data and can exhibit high variance.\nThe design-based fix for this problem is given in Imai et al. (2009). As they show, the problem can be greatly alleviated by blocking on cluster size. We will use a simple design declaration to show the problem and how blocking helps.\n\nA design with heterogeneous cluster sizes\nLet’s declare a design with heterogeneous cluster sizes. There are 300 units in 12 clusters. Two bigger clusters are of size 100 and 10 smaller clusters are of size 10. The 200 units in clusters of size 100 have a 0 treatment effect, the other 100 in clusters of size 10 have an effect of 3. This means that the average treatment effect is 1. Note that we did not include any cluster level “shocks” though we did include heterogeneous effects by cluster.\nHere is the design:\n\nN_clusters <- 12\n\ncluster_design <- \n  # M: Model\n  declare_model(clusters = add_level(N = N_clusters, \n                                          cl_size = rep(c(100, 10), c(N/6, N - N/6)),\n                                          effect = ifelse(cl_size == 100, 0, 3)),\n                     units    = add_level(N = cl_size, u = rnorm(N, sd = .2),\n                                          Y_Z_0 = u, Y_Z_1 = u + effect)) +\n  \n  # I: Inquiry\n  declare_inquiry(ATE_i = mean(Y_Z_1 - Y_Z_0)) +\n\n  # D: Data Strategy\n  declare_assignment(Z = cluster_ra(clusters = clusters)) +\n  \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n\n  # A: Answer Strategy\n  declare_estimator(Y ~ Z, inquiry = \"ATE_i\", clusters = clusters,\n                    model = lm_robust, label = \"dim\") +\n  \n  declare_estimator(Y ~ Z, inquiry = \"ATE_i\", clusters = clusters,\n                    condition_prs = 0.5, simple = FALSE,\n                    model = horvitz_thompson, label = \"ht\")\n\n\n\n\n\n\n\nIn the plot below we show the distribution of possible estimates from different possible random assignments. The true treatment effect is 1. We see bias (of size 0.327) from the fact that the distribution is clearly not centered at 1. Very large effects (approx. 3) are estimated in those cases where both of the large clusters get assigned to control (and so all treated outcomes are around 3, right mode) whereas the estimated effects (approx. 0) when both are assigned to treatment are not so small in comparison (left mode), producing right skew. The HT estimator, in contrast, does fine on bias in this example and also has a tighter distribution.\n\nsimulate_design(cluster_design) %>%\n  ggplot(aes(estimate)) + \n  geom_histogram(bins = 30) + \n  geom_vline(xintercept = 1, linetype = \"dashed\") +\n  facet_wrap( ~ estimator)\n\n\n\n\n\n\n\n\nScale matters\nThe problem in this design, we saw, arises when all the large units get assigned to the control condition. This unlucky combination is a higher probability event in small studies than it is in large studies. In larger studies we are more likely to see balance in the allocation of units to treatment and control. To illustrate, we scale up to 120 clusters rather than 12. We see a more continuous distribution of treatment effects and in a particular a shift away from the extremes of the distribution, which arise only when like types end up in like conditions.\n\nsimulate_design(redesign(cluster_design, N_clusters = 120)) %>%\n  ggplot(aes(estimate)) + \n  geom_histogram(bins = 30) + \n  facet_wrap( ~ estimator)\n\n\n\n\n\n\n\n\n\nIn this case the bias is of size 0.027, which is a big reduction.\n\n\nBlock on cluster size to address this risk\nHow can we address the bias in the difference-in-means estimator? As described in Imai et al. (2009), blocking our treatment assignment such that a similar number of large clusters are assigned to treatment and control, and a similar number of small clusters are assigned to treatment and control, can help a lot.\nTo see this, we can transform this cluster design into a blocked cluster design by changing the assignment strategy; here using one in which we pair off the clusters based on size and randomly assign one in each pair to treatment.\n\nmatched_cluster_design <- replace_step(\n  cluster_design, step = 3, declare_assignment(Z = block_and_cluster_ra(clusters = clusters, blocks = cl_size)))\n\nThe sampling distribution of the difference-in-means estimators is tight—variation reflects only the random differences between clusters and not the systematic differences. It is, moreover, now equivalent to the HT distribution since there is essentially no differential weighting within blocks.\n\n\n\n\nsimulate_design(matched_cluster_design) %>%\n  ggplot(aes(estimate)) + \n  geom_histogram(bins = 30) + \n  facet_wrap( ~ estimator)\n\n\n\n\n\n\n\n\nExtension: The problem is aggravated by sampling (but there is a solution in that case also!)\nThis problem is amplified when clusters are sampled from a larger population of clusters with equal probability. In this case both the difference-in-means and the Horvitz Thompson estimators will be biased. The intuition is similar to the problem with random assignment: tiny clusters are equally likely to be sampled as very large clusters, and the inclusion of some tiny clusters biases down both estimators when outcomes are a function of cluster size. This bias will exist even when randomization is blocked on cluster size. One intuitive possibility to address this bias is to change the probability of sampling to oversample large clusters and undersample small clusters – probability-proportional-to-size sampling. Higgins (2014) proposes such a design. Intuitively, this helps because those tiny clusters that lead to bias are less likely to be selected. Higgins (2014) demonstrates that the Hansen and Hurwitz (1943) estimator is unbiased in this setting.\nWhile we don’t declare this alternative design in this post we will sign off with a step declaration for the HH estimator which could be useful for addressing this problem in the future.\n\n# A step!\nhansen_hurwitz <- function(data){\n  data %>% group_by(clusters) %>% \n      summarize(is_treated = first(Z), cluster_mean = 1/n() * sum(Y)) %>% \n      ungroup %>% \n      summarize(estimate = sum(1/sum(is_treated) * cluster_mean[is_treated]) -\n                           sum(1/sum(!is_treated) * cluster_mean[!is_treated])) %>% \n      as.data.frame\n  }\n\n\n\n\n\n\n\n\n\nReferences\n\nHansen, Morris H., and William N. Hurwitz. 1943. “On the Theory of Sampling from Finite Populations.” The Annals of Mathematical Statistics 14 (4): 333–62.\n\n\nHiggins, Michael J. 2014. “The Benefits of Probability Proportional to Size Sampling in Cluster-Randomized Experiments.”\n\n\nImai, Kosuke, Gary King, Clayton Nall, et al. 2009. “The Essential Role of Pair Matching in Cluster-Randomized Experiments, with Application to the Mexican Universal Health Insurance Evaluation.” Statistical Science 24 (1): 29–53."
  },
  {
    "objectID": "blog/process-tracing.html",
    "href": "blog/process-tracing.html",
    "title": "What can you learn from simulating qualitative inference strategies?",
    "section": "",
    "text": "Qualitative process-tracing sometimes seeks to answer “cause of effects” claims using within-case data: how probable is the hypothesis that \\(X\\) did in fact cause \\(Y\\)? Fairfield and Charman (2017), for example, ask whether the right changed position on tax reform during the 2005 Chilean presidential election (\\(Y\\)) because of anti-inequality campaigns (\\(X\\)) by examining whether the case study narrative bears evidence that you would only expect to see if this were true.1 When inferential logics are so clearly articulated, it becomes possible to do design declaration and diagnosis. Here we declare a Bayesian process-tracing design and use it to think through choices about what kinds of within-case information have the greatest probative value.\nSay we want to evaluate a case-specific hypothesis, \\(H\\), regarding whether \\(Y\\) happened because \\(X\\) happened. The hypothesis is not that \\(X\\) is the only cause of \\(Y\\), but more simply whether \\(Y\\) would have been different had \\(X\\) been different. A researcher looks for “clues” or evidence, \\(E\\), in a case narrative or other qualitative data, which would be more or less surprising to see depending on whether \\(H\\) is true. Collier (2011) lays out the basic strategy. In a recent paper, Murtas, Dawid, and Musio (2017) show how to justify updating case level inferences from experimental data on moderators and mediators.\nFormally declaring and diagnosing such a procedure yields two non-obvious insights:"
  },
  {
    "objectID": "blog/process-tracing.html#model-inquiry-data",
    "href": "blog/process-tracing.html#model-inquiry-data",
    "title": "What can you learn from simulating qualitative inference strategies?",
    "section": "Model-Inquiry-Data",
    "text": "Model-Inquiry-Data\nIf we think of causal relations in counterfactual terms there are just four possible causal relationships between a binary \\(X\\) and a binary \\(Y\\):\n\nThe presence of natural resources could cause civil war (\\(X\\) causes \\(Y\\)).\nThe presence of natural resources could be the only thing preventing war (\\(\\neg X\\) causes \\(Y\\)).\nCivil war might happen irrespective of whether natural resources are present (\\(Y\\) irrespective of \\(X\\)).\nCivil war might not happen irrespective of whether natural resources are present (\\(\\neg Y\\) irrespective of \\(X\\)).\n\nFor the simulations, we will imagine we are in a world with 195 countries of which roughly 30% have natural resources (\\(X\\)) (that’s easy to specify). We will also specify a model in which civil war is governed by causal pathway 1 (\\(X\\) causes \\(Y\\)) in roughly 20% of countries, by pathway 2 (\\(\\neg X\\) causes \\(Y\\)) in only 10% of countries, by pathway 3 (\\(Y\\) irrespective of \\(X\\)) in 20% of countries, and by pathway 4 (\\(\\neg Y\\) irrespective of \\(X\\)) in half of all countries (that’s not so easy to specify and of course is information that is not available at the answer stage).\nIn addition, we imagine that there is further “process” data that is informative about causal relations. We imagine two types (see Collier (2011) for a discussion of clues of this type):\n\nA straw-in-the-wind clue. A straw-in-the-wind clue is an outcome that is somewhat more likely to be present if the hypothesized causal process is in operation and somewhat less likely if it is not. Let’s say, for example, that \\(E_1\\) is the national army taking control over natural resources during a civil war. We imagine that that’s likely to happen if the natural resources caused the war: \\(Pr(E_1 \\mid H) = .75\\). But even if the natural resources didn’t cause the war, the national army might still take over natural resources for other reasons, say \\(Pr(E_1 \\mid \\neg H) = .25\\).\nA smoking gun clue. A smoking gun clue is an outcome that is somewhat likely to be present if the stipulated hypothesis is true, but very unlikely if it is false. Say one of the antagonists was an armed group whose main name, aims, and ideology were centered around the capture and control of natural resources. This information provides a clue which might be really unlikely to arise in general, even if \\(H\\) is true. But it’s very informative if it is observed, since it’s so unlikely to arise if \\(H\\) is not true: it’s a “smoking gun.” Let’s say \\(Pr(E_2 \\mid H) = .3, Pr(E_2 \\mid \\neg H) = 0.05\\).\n\nThese clues might themselves be mediators, or moderators, or even arise post treatment, though we do not specify the full causal model that gives rise to them here. Rather, we simply define a step that generates these clue observations independently, conditional on the causal process. This is a strong assumption: the fact that an armed group formed in order to take resources (\\(E_2\\)) might convince the government to take over the natural resource (\\(E_1\\)) – or it might dissuade the government! We therefore relax this “Independent Clues” assumption below.\nThis gives us enough information to put down the stub of a design in which a model generates data with these features, an imaginary researcher samples one case from the \\(X=Y=1\\) group, and defines the question the researcher wants to ask about this case. Notice here the inquiry takes place after the sampling because we care about what happens in the specific case we chose.\n\ndesign_stub <- \n    \n  declare_model(\n      N = 195, \n      X = rbinom(N, 1, .3) == 1,\n      causal_process = sample(c('X_causes_Y', 'X_causes_not_Y', 'Y_regardless', 'not_Y_regardless'), \n                              N, replace = TRUE, prob = c(.2, .1, .2, .5)),\n      Y = (X & causal_process == \"X_causes_Y\") |     \n          (!X & causal_process == \"X_causes_not_Y\") |\n          (causal_process == \"Y_regardless\"))  +\n  \n  declare_sampling(S = strata_rs(strata = (X == 1 & Y == 1), \n                                 strata_n = c(\"FALSE\" = 0, \"TRUE\" = 1))) +\n  \n  declare_measurement(\n    SIW_observed = rbinom(\n      n = N, size = 1, prob = ifelse(test = causal_process == 'X_causes_Y', .75, .25)),\n    SMG_observed = rbinom(\n      n = N, size = 1, prob = ifelse(test = causal_process == 'X_causes_Y', .3,  .05)),\n    label = \"Independent Clues\") +\n  \n  declare_inquiry(did_X_cause_Y = causal_process == 'X_causes_Y') \n\nSo far, a dataset from this design stub might look like this:\n\ndraw_data(design_stub) %>% kable(digits = 2, align = \"c\")\n\n\n\n\nID\nX\ncausal_process\nY\nS\nSIW_observed\nSMG_observed\n\n\n\n\n055\nTRUE\nX_causes_Y\nTRUE\n1\n1\n0"
  },
  {
    "objectID": "blog/process-tracing.html#answer-strategy",
    "href": "blog/process-tracing.html#answer-strategy",
    "title": "What can you learn from simulating qualitative inference strategies?",
    "section": "Answer strategy",
    "text": "Answer strategy\nWe now turn to the answer strategy. For this, we’ll assume that at the analysis stage researchers use Bayes’ rule to figure out \\(Pr(H \\mid E)\\): the posterior probability that \\(X\\) caused \\(Y\\) in the case we chose, given the clue evidence we found. We make a function that calculates the posterior using Bayes’ rule:\n\\[Pr(H \\mid E) = \\frac{Pr(H) Pr(E|H)}{Pr(H)Pr(E\\mid H) + Pr(\\neg H)Pr(E\\mid\\neg H)}\\]\n\ncalculate_posterior <- function(data, p_H, p_clue_found_H, p_clue_found_not_H, test, label) {\n  clue_found <- data[, test]\n  p_E_H <- ifelse(clue_found, p_clue_found_H, 1 - p_clue_found_H)\n  p_E_not_H <- ifelse(clue_found, p_clue_found_not_H, 1 - p_clue_found_not_H)\n  data.frame(posterior_H = p_E_H * p_H / (p_E_H * p_H + p_E_not_H * (1 - p_H)), clue_found = clue_found)}\n\nBayes’ rule makes use of the probability of observing \\(E\\) if \\(H\\) is true and the probability of observing \\(E\\) if \\(H\\) is not true. The more different these probabilities are the more you learn from new data.\nWe also need to specify the imaginary researcher’s prior belief that \\(H\\) is true. The imaginary researcher knows that only two processes, 1 and 3 from above, could have generated the data \\(X = Y = 1\\). Thus, they might specify a “flat” prior: \\(Pr(H) = .5\\) (though they might have more informed beliefs from background knowledge).\nWe use the calculate_posterior() function we made above to declare two different answer strategies: one predicated on the straw-in-the-wind, and the other on the smoking gun.\n\ndesign <-\n  \n  design_stub + \n  \n  declare_estimator(\n    test               = \"SIW_observed\", \n    p_H                = .5, \n    p_clue_found_H     = .75,\n    p_clue_found_not_H = .25,\n    label              = \"Straw in Wind\",\n    estimand           = \"did_X_cause_Y\",\n    handler            = label_estimator(calculate_posterior)) +\n  \n  declare_estimator(\n    test               = \"SMG_observed\", \n    p_H                = .5, \n    p_clue_found_H     = .30,\n    p_clue_found_not_H = .05,\n    label              = \"Smoking gun\",\n    estimand           = \"did_X_cause_Y\",\n    handler            = label_estimator(calculate_posterior))"
  },
  {
    "objectID": "blog/sometimes-you-need-to-cluster-standard-errors-above-level-of-treatment.html",
    "href": "blog/sometimes-you-need-to-cluster-standard-errors-above-level-of-treatment.html",
    "title": "Sometimes you need to cluster standard errors above the level of treatment",
    "section": "",
    "text": "David McKenzie discussed this issue a while ago here following discussions by Chris Blattman here. While broadly in line with these discussions, our take-away leans a bit more in the direction that yes you really might want to cluster at higher levels than treatment assignment in an experiment in some cases, but only when you are targeting non-sample-based estimands such as population average effects.\nMore generally, the post shows how to check for these kinds of issues when you declare a design, exploiting the fact that with a design declared you can compare the distribution of estimates of standard errors with the standard deviation of the estimates you get across many runs. So you can see not just whether estimates of uncertainty are unbiased, but also whether they are precise.\n\nA case in which clustering standard errors at the level of assignment works well\nConsider first a simple design in which there are block-level and cluster-level shocks, but treatment is assigned at the cluster level. The design has three strategies for estimating the standard error (the standard deviation of the estimator’s sampling distribution):\n\nignore clustering;\nallow for error correlation at the cluster level; and\nallow for error correlation at the block level.\n\nHere is a full declaration of the design.1\n\ndesign_1 <- \n  \n  declare_model(\n    schools    = add_level(N = 20, u_b = rnorm(N)), \n    classrooms = add_level(N =  5, u_c = rnorm(N)), \n    students   = add_level(\n      N =  5, \n      u_i = rnorm(N),\n      potential_outcomes(Y ~  Z + (u_i + u_b + u_c))\n    )\n  ) + \n  \n  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +\n  \n  declare_assignment(Z = cluster_ra(clusters = classrooms)) +\n  \n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) + \n  \n  declare_estimator(Y ~ Z, inquiry = \"ATE\", model = lm_robust, \n                    label = \"No clustering\") +\n\n  declare_estimator(Y ~ Z, inquiry = \"ATE\", model = lm_robust, \n                    clusters = classrooms,\n                    label = \"Assignment-level clustering\") + \n  \n  declare_estimator(Y ~ Z, inquiry = \"ATE\", model = lm_robust, \n                    clusters = schools, \n                    label = \"Higher-level clustering\")\n\nThis design has twenty blocks, each with five clusters made up of five individuals. There are individual, cluster and block shocks, all with unit standard deviation. This means that the ICC is 2/3. Conditioning on block however, the ICC is just 1/2 (since the cluster level and individual level shocks have the same variance).\nWe simulate the design many times (using simulate_design(design_1)). This generates a dataset with the point estimate from each run (which is common across approaches), as well as the estimate of the variance of the point estimates (the standard error squared). This provides enough information to see how well the estimates of uncertainty are doing.\nBelow we plot the distribution of estimates of standard errors (squared) from each of the three strategies alongside the actual variance of estimates across runs (vertical line).\n\n\n\n\n\n\n\n\nThe first thing that jumps out is the bias in the approach that assumes no error correlation: the average standard error (squared) is 0.02, which is well below the variance of the estimates across our repeated samples. That’s the anti-conservative bias that worries people when you fail to cluster standard errors for clustered treatments. It can be quite extreme, as here.\nBy contrast, the approaches that allow for cluster- and block-level correlation in errors approximate the variance in the sampling distribution of the estimates nicely, and on average are about equal to the true variance of the estimates. You will notice though that the distribution of estimates of uncertainty exhibit a lot more variance when you cluster at the block level. What this means is that in this design clustering at too high a level makes it more likely that you will get the estimates of uncertainty wrong (even if you will be right on average).\nThe hummable tune version: If you cluster too high your estimates of variance may have too much variance.\n\n\nA case in which it makes sense to cluster errors above the level of treatment assignment\nSo does this mean you should only ever account for error correlation at the same level the treatment is assigned? Not always. Consider the following similar design, in which there are heterogenous treatment effects that depend on higher-level shocks (in this case at the school level), whereas treatment is still assigned at the lower level of classrooms.\n\nnew_model <- declare_model(\n  schools    = add_level(N = 20, u_b = rnorm(N)), \n  classrooms = add_level(N =  5, u_c = rnorm(N)), \n  students   = add_level(\n    N =  5, \n    u_i = rnorm(N),\n    potential_outcomes(Y ~ u_i + u_b*Z)\n  )\n)\n\ndesign_2 <- replace_step(design_1, step = 1, new_model)\n\nThis kind of design might describe a situation in which individuals in different areas are selected at random to participate in area-level workshops; or one in which clusters of voters are assigned to get information about the political representative in their area before an election, and so on.\nThe distribution of estimates of uncertainty now looks like this:\n\n\n\n\n\n\n\n\nWe see that allowing for group-level correlation in errors among treated units provides estimates of uncertainty that, on average, track the variance of the sampling distribution quite well. Ignoring this correlation produces standard errors that are too small, leading to over-confidence.\nThe design here is not particularly unusual. Heterogeneous effects across groups could be a feature of many studies. This suggests that the issue here could be fairly general.\n\n\nNot such a concern if your focus is on sample average treatment effects\nA key feature of the last design is that the group-level treatment effects are stochastic, and so each simulation takes a draw of blocks from a large population of blocks. Thus, even though the assignment is not clustered by block, the units in each blocks are themselves clusters from a sampling process.\nThis resonates with results in Abadie et al. (2017) (here) which highlights the distinct sampling and assignment rationales for clustering. Here clustering at the assignment level does not account for the clustered sampling into the study. To illustrate this last point we make a small change to the design to remove this cluster-sampling feature. We draw a single dataset, and suppose that we are dealing with a finite population.\n\nfixed_data <- draw_data(design_2)\n\nWe then splice this new fixed data into the previous design to make a new design.\n\ndesign_3 <- replace_step(design_2, 1, declare_model(data = fixed_data))\n\nBecause we are holding the population data fixed, we are no longer sampling 20 clusters from the set of possible clusters. This restricts the variance of the sampling distribution to that generated by the assignment.\nNow the distribution of estimates of uncertainty look like this:\n\n\n\n\n\n\n\n\nThe implications are that when we focus on the sample estimand the version that clusters standard errors at the level of assignment works fairly well (they are slightly conservative reflecting the fact that the Neyman standard errors are conservative). The standard errors that account for group-level error correlation are wildly conservative, since they are positing possible treatment effects that could never come into existence under this model. It’s the wrong sampling distribution.\n\n\nTakeaways\nThe key takeaways:\n\nSenn’s “as ye randomize so shall ye analyze” principle works fine in standard set ups when you are interested in sample average estimands: it makes sense to cluster your standard errors at the level of treatment assignment.\nYou can still go too low: if your units of assignment (be they clusters or individuals) are themselves members of higher-level clusters that are sampled from a larger population and you are interested in population average estimands, then you may need to allow for correlation in errors at that level to account for clustering of effects generated by sampling\nYou can definitely go too high: but this doesn’t mean you should default to a “conservative” rule of thumb. If you assume a sampling process where one doesn’t exist, you can end up being wildly over-conservative in your estimates of the sampling distribution or having an estimate of uncertainty that is right in expectation but far off in realization.\nIf in doubt, diagnose.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nAbadie, Alberto, Susan Athey, Guido W Imbens, and Jeffrey Wooldridge. 2017. “When Should You Adjust Standard Errors for Clustering?” National Bureau of Economic Research.\n\nFootnotes\n\n\nThis kind of design can also be made in a single line with the DesignLibrary package using the block_cluster_two_arm_designer().↩︎"
  },
  {
    "objectID": "blog/neyman-sate-pate.html",
    "href": "blog/neyman-sate-pate.html",
    "title": "Common estimators of uncertainty overestimate uncertainty",
    "section": "",
    "text": "The key insight is that how great a problem this is depends on the target of inference. If you are targeting a sample average treatment effect (SATE), your standard errors will often be too big. If you are targeting a population average treatment effect (PATE), but that population is itself sampled from a superpopulation, your standard errors may also be too big, though the issues are less severe. If you’re targeting a superpopulation average treatment effect (SPATE), your standard errors will be the right size.\nA quick word on what we’re not talking about. Under complete random assignment (exactly \\(m\\) of \\(N\\) units in the sample are treated), the difference-in-means estimator of the average treatment effect is of course unbiased, which means that it returns exactly the right answer, on average. The bias we are talking about here isn’t in the estimator of the treatment effect, but instead, it’s in the standard error estimator.\nWe want to estimate \\(\\text{sd}\\left(\\frac{1}{n_T}\\sum_{i \\in T} Y_i(1) - \\frac{1}{n_C}\\sum_{i \\in C} Y_i(0) \\right)\\). The usual estimator for this is the Neyman standard error. This estimator uses the fact that the variance of a difference (treatment - control) can be expressed in terms of the variance of each group (variance of treatment outcomes, variance of control outcomes), and the covariance between them (see Freedman). We can estimate the variances easily enough but unfortunately we cannot estimate the covariance because we never simultaneously see outcomes for treatment and control for a given unit. Instead the Neyman estimator assumes the worst and estimates an upper bound on the variance. This is equivalent to HC2 robust standard errors in a regression setup and it is what is estimated by default in estimatr::difference_in_means and estimatr::lm_robust.\nFrom some perspectives, a conservative standard error estimator is better than the alternative. With a conservative estimator, we are less certain of our ATE estimates than we should be. If you’re conducting hypothesis tests, upward bias in the standard errors means you’re less likely to commit a Type I error (inappropriately rejecting the null) but you’re more likely to commit a Type II error (inappropriately failing to reject). So how bad this is depends on how you trade off these errors.\nWe’re going to investigate this question at three levels that correspond to three estimands. The highest level is the superpopulation, and the associated estimand is the superpopulation average treatment effect (SPATE). The next highest is the population, whose estimand is the population average treatment effect (PATE). The lowest level is the sample, with an associated estimand called the sample average treatment effect (SATE). Depending on how units are sampled into the population or the sample, these three estimands could have different values.\nWe’re interested in:\n\nThe true standard deviation of the sampling distribution of estimates for the SPATE, the PATE, and the SATE.\nThe estimated standard errors associated with each estimand.\n\nWe can learn about all of these using a simulation conducted in DeclareDesign. The design includes the parameters r (the correlation between Y0 and Y1) and b (the superpopulation average treatment effect) in case you’d like to vary them, but we’ve set them to zero for this demonstration. Note that setting r=0 means that potential outcomes under treatment and control are not correlated. This implies heterogeneous effects: if effects were homogeneous then these outcomes would be perfectly correlated (for intuition, imagine a graph of \\(Y(1)\\) against \\(Y(0)\\)).\n\nr <- 0 # correlation between Y0 and Y1\nb <- 0 # average treatment effect\n\ndesign <- \n  declare_model(N = 64,\n                u_0 = rnorm(N),\n                u_1 = rnorm(n = N, mean = r * u_0, sd = sqrt(1 - r^2)),\n                Y_Z_0 = u_0, \n                Y_Z_1 = u_1 + b) +\n  declare_sampling(S = complete_rs(N, n = 32)) +\n  declare_assignment(Z = complete_ra(N)) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z)\n\n\nThe SATE\nLet’s start with the bottom level, the sample. If the target is the SATE, that means we want to understand the sampling distribution of the ATE estimator, conditional on the sample. We take advantage of a cool feature in DeclareDesign that allows you to control exactly how many draws are conducted at each step by passing a vector to the sims argument. If you said sims = c(1, 2, 3), we would simulate the first step once, the second step twice (\\(1 \\times 2\\)), and the third step six times (\\(1 \\times 2 \\times 3\\)).\nTo simulate the sampling distribution of the SATE estimator, given a particular sample, we want:\n\n1 draw each from the declare_model(), declare_potential_outcomes(), and declare_sampling() steps (together, a single draw of a sample from the population with its potential outcomes)\nA bunch of draws from the declare_assignment step (assigning treatment over and over within the fixed sample). For this simulation, we’ve set assignment_draws to 500\n1 draw each from the declare_reveal and declare_estimator steps\n\n\nSATE_sims <- simulate_design(design, sims = c(1, 1, 1, assignment_draws, 1, 1))\n\n\n\n\n\n\n\nThis code summarizes the simulations and calculates (1) the true variance of the sampling distribution and (2) the average estimated standard error squared. The bias of standard error estimators is usually discussed in terms of variance, not the square root of the variance, because the square root operation is non-linear.\nThe figure shows the distribution of estimates that you would get given a particular sample.1 As we can see, the true variance is lower than the average estimated variance, indicating upward bias in this case.\n\nSATE_summary_df <-\n  SATE_sims %>% \n  summarise(`True Variance of SATE estimator` = var(estimate),\n            `Average Estimated Standard Error Squared` = mean(std.error ^2)) %>%\n  gather(diagnosand, value)\n\n\nSATE_summary_df\n\n\n\n\n\n\ndiagnosand\nvalue\n\n\n\n\nTrue Variance of SATE estimator\n0.065\n\n\nAverage Estimated Standard Error Squared\n0.120\n\n\n\n\n\nWe can also plot the sampling distribution of the standard error estimator to visually show the bias.\n\nSATE_sims %>%\n  ggplot(aes(std.error^2)) +\n  geom_histogram(bins = 30) +\n  geom_vline(data = SATE_summary_df, aes(xintercept = value, color = diagnosand), size = 2) + \n  guides(colour = guide_legend(reverse = TRUE))\n\n\n\n\n\n\nThe PATE\nNext, let’s go one level up. Now the sims argument shows that we’re drawing a single population, then repeatedly drawing samples from that population. The graph shows that even in this case, the true variance of the PATE estimator is lower than estimated.\n\nPATE_sims <- simulate_design(design, sims = c(1, 1, 500, 1, 1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe SPATE\nBut if we imagine we’re sampling from an infinite superpopulation, things look better. Here we repeatedly draw a population from the superpopulation, then draw a sample from that population, and then assign treatment.\n\nSPATE_sims <- simulate_design(design, sims = c(500, 1, 1, 1, 1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome Intuition\nWhy does this happen?\nSay a bag contains half white stones and half black stones and I pull one stone and have to guess about the value of a second stone. If there are only two stones in the bag, then I can use the first draw to guess perfectly about the color of the second one. I can make a reasonably informed guess if there are four stones in the bag. But if there are an infinity of stones then my first draw tells me nothing about the second draw.\nIn essence this is what is happening here. To make the link to treatment effects imagine there were just two units. Unit 1 has outcomes \\(Y_1(0) = 0, Y_1(1) = 1\\) and unit 2 has \\(Y_2(0) = 1, Y_2(1) = 2\\). Then both units have a +1 treatment effect and potential outcomes are positively correlated. Depending on which unit is assigned to treatment the estimate will be either 0 or 2. So quite a bit of variability despite the homogeneous effects. The reason is that if a unit with high outcomes enters the treatment group, then that same unit (with high values) will be missing from the control group and so unusually high outcomes in the treatment group correspond to low outcomes in the control group. Imagine instead that \\(Y_1(0) = 0, Y_1(1) = 2\\) and unit 2 has \\(Y_2(0) = 1, Y_2(1) = 1\\). Then the average effect is still +1 but there are heterogeneous effects and potential outcomes are negatively correlated. No matter which unit is assigned to treatment the estimate will be 1. So no variability now. The reason is that if a unit with a high outcome enters the treatment group, then that same unit (with low values) will be missing from the control group and so both the treatment and control groups will have positive shocks that get differenced out.\nThe key thing is that there are reductions in variability that arise, given heterogeneous effects, when assignments into one group have implications for values in the other. But that implication does not hold so strongly when units are sampled from bigger populations (in the same way as knowing the color of a stone from one draw is less informative about a second draw the bigger the bag from which you are drawing).\nAnother way to think about this is that each level of sampling (from superpopulation to population, from population to sample, from sample to treatment sampling) adds a layer of uncertainty to the true sampling distribution of the estimates. So the distribution of the SATE estimator is tighter than the distribution of PATE estimator is tighter than the distribution of the SPATE estimator. But the standard error estimator is the same in all three cases – it assumes a worst case scenario… which happens to only be true in the SPATE case. In the SATE and PATE cases, the Neyman standard error estimator is upwardly biased.\n\n\nImplications for Inference\nWe’re often concerned that because of \\(p\\)-hacking and specification searches, reported \\(p\\)-values are too low. Funnily enough, the fact that the Neyman standard error estimator is conservative means that sometimes, the reported \\(p\\)-values may be too high!\n\n\nFurther reading\nIt is possible to do better than the Neyman estimate by putting upper and lower bounds on the standard error. See Aronow et al. (2014) ( ungated ) for a lovely treatment of these issues.\n\n\n\n\n\n\nReferences\n\nAronow, Peter M, Donald P Green, Donald KK Lee, et al. 2014. “Sharp Bounds on the Variance in Randomized Experiments.” The Annals of Statistics 42 (3): 850–71.\n\nFootnotes\n\n\nIf you were interested in how the bias of the estimated variances is distributed over samples then you would want to this operation multiple times, which is easily done using sims = c(500, 1, 1, 500, 1, 1)↩︎"
  },
  {
    "objectID": "blog/instrument-does-not-have-to-be-exogenous.html",
    "href": "blog/instrument-does-not-have-to-be-exogenous.html",
    "title": "An instrument does not have to be exogenous to be consistent",
    "section": "",
    "text": "Consider the causal graph below (a directed acyclic graph, or DAG). Here \\(U_2\\) confounds the relationship between \\(X\\) and \\(Y\\). That’s the usual thing and the reason for why you need something like an instrument in the first place. But now a binary \\(U_1\\) also confounds the relationship between \\(Z\\) and \\(X\\) (see for instance Fig 2d Swanson et al. (2018)). To emphasize, in this set up, the instrumental variable and the instrumented variable share a common cause in \\(U_1\\).\n\n\n\n\n\nDAG for a non-randomized instrument. Z is an instrument for the effect of X on Y\n\n\n\n\nUsing DeclareDesign, we write down a declaration that is consistent with this DAG. Our declaration specifies some “compliance types” or “principal strata.” In the standard IV setup with a binary instrument \\(Z\\) and a binary treatment \\(X\\), there are only four types (corresponding to all conceivable ways that the endogenous variable can respond to the exogenous variable): compliers, never-takers, always-takers, and defiers.1 But here, the binary \\(U_1\\) and binary \\(Z\\) both affect \\(X\\), so there are actually sixteen conceivable ways to comply!2\nWe simplify by imagining a world with only three types: \\(U_1\\)-compliers, \\(Z\\)-compliers, and never-takers.3 \\(U_1\\)-compliers have \\(X = 1\\) if and only if \\(U_1 = 1\\). \\(Z\\)-compliers have \\(X = 1\\) if and only if \\(Z = 1\\). Never-takers have \\(X = 0\\) regardless of the values of \\(U_1\\) or \\(Z\\). \\(U_2\\) takes three values, 1-3, and plays two roles. First, it determines whether you are a \\(U_1\\)-complier, \\(Z\\)-complier, or never-taker with respect to \\(X\\). Second, it is positively correlated with your value in \\(Y\\).\nWe’ll define five estimands, which is a lot.\n\nThe Average Treatment Effect (ATE) of \\(X\\) on \\(Y\\).\nThe Intention-To-Treat (ITT) effect. The average effect of \\(Z\\) on \\(Y\\).\nThe first-stage effect. This is the average effect of \\(Z\\) on \\(X\\).\nThe Local Average Treatment Effect (LATE_U1) of \\(X\\) on \\(Y\\), among the subgroup of units that are \\(U_1\\)-compliers\nThe Local Average Treatment Effect (LATE_Z) of \\(X\\) on \\(Y\\), among the subgroup of units that are \\(Z\\)-compliers\n\nWe’ll use three estimators:\n\nThe ITT estimator, which is an OLS regression of \\(Y\\) on \\(Z\\).\nThe first-stage estimator, which is an OLS regression of \\(X\\) on \\(Z\\).\nThe IV estimator, which is two-stage least squares regression of \\(Y\\) on \\(X\\), instrumented by \\(Z\\).\n\nThe declaration also includes two additional parameters (bear with us!) that we’ll vary down below. They are:\n\nheterogeneity: the amount of treatment effect heterogeneity. When this is 0, the effect of \\(X\\) on \\(Y\\) is the same for \\(U_1\\)-compliers as it is for \\(Z\\)-compliers. Otherwise, the effect for the two subgroups is different.\npath_weight: describes whether the U1 --> X or the Z --> X path is stronger. This is equivalent to the fraction of compliers that are \\(U_1\\)-compliers.\n\nOK, here’s the design:\n\nheterogeneity <- 0   # how much does LATE_Z differ from LATE_U1?\npath_weight   <- .5  # what fraction of compliers are U1 compliers?\n\ndesign <-\n  \n  # U2 is the compliance \"type\" (U1 complier, Z complier, or Never Taker)\n  declare_model(\n    N = 2000, \n    # U1 is binary\n    U1 = complete_ra(N),\n    U2 = complete_ra(\n      N, \n      prob_each = c(path_weight * 0.6, (1 - path_weight) * 0.6, 0.4), \n      conditions = c(\"U1_c\", \"Z_c\", \"NT\")),\n    noise = rnorm(N),\n    # X potential outcomes in terms of U1 and Z, given U2 (there are **four**)\n    potential_outcomes(X ~ as.numeric((U2 == \"U1_c\") * U1 +\n                                        (U2 == \"Z_c\")  * Z),\n                       conditions = list(U1 = c(0, 1), Z = c(0, 1))),\n    # X potential outcomes in terms of Z given U1 and U2 (there are **two**)\n    potential_outcomes(X ~ as.numeric((U2 == \"U1_c\") * U1 +\n                                        (U2 == \"Z_c\")  * Z)),\n    # Y potential outcomes in terms of X (there are **two**)\n    potential_outcomes(Y ~ X * (1 + heterogeneity * as.numeric(U2)) + noise, \n                       conditions = list(X = c(0, 1))),\n    # Y potential outcomes in terms of Z (there are **two**)\n    # this is same as above, but X is written in terms of Z\n    potential_outcomes(Y ~ as.numeric((U2 == \"U1_c\") * U1 + (U2 == \"Z_c\") * Z) * \n                         (1 + heterogeneity * as.numeric(U2)) + noise)) +\n  \n  # Z is affected by U1: among U1 = 0, Z has probability 0.3; among U1 = 1, probability 0.6\n  declare_assignment(Z = block_ra(blocks = U1, block_prob = c(0.3, 0.6))) +\n  \n  declare_measurement(X = reveal_outcomes(X ~ U1 + Z)) +\n  \n  # reveal Y (doesn't matter \"how\" this is revealed, either via the X pos or the Z pos)\n  declare_measurement(Y = reveal_outcomes(Y ~ X)) +\n  \n  # Use X POs to learn about the two complier definitions\n  declare_measurement(\n    U1_complier = X_U1_0_Z_0 == 0 & X_U1_0_Z_1 == 0 & X_U1_1_Z_0 == 1 & X_U1_1_Z_1 == 1,\n    Z_complier  = X_U1_0_Z_0 == 0 & X_U1_1_Z_0 == 0 & X_U1_0_Z_1 == 1 & X_U1_1_Z_1 == 1) +\n  \n  # 5 (!) estimands\n  declare_inquiry(\n    ATE =         mean(Y_X_1 - Y_X_0),\n    LATE_U1 =     mean(Y_X_1[U1_complier] - Y_X_0[U1_complier]),\n    LATE_Z =      mean(Y_X_1[Z_complier] - Y_X_0[Z_complier]),\n    ITT =         mean(Y_Z_1 - Y_Z_0),\n    first_stage = mean(X_Z_1) - mean(X_Z_0)) + \n  \n  # Three estimators\n  declare_estimator(Y ~ Z, inquiry = \"ITT\", model = lm_robust, label =  \"itt\") +\n  declare_estimator(X ~ Z, inquiry = \"first_stage\", model = lm_robust, label =  \"first\") +\n  declare_estimator(Y ~ X | Z, inquiry = c(\"ATE\", \"LATE_U1\", \"LATE_Z\"), \n                    model = iv_robust, label =  \"iv_robust\")\n\nLet’s now diagnose this design to show that – pretty counterintuitively for us at least! – the IV estimator still recovers the LATE even when \\(Z\\) and \\(X\\) have a common cause.\n\ndiagnosands <- \n  declare_diagnosands(bias = mean(estimate - estimand),\n                      mean_estimate = mean(estimate),\n                      mean_estimand = mean(estimand))\ndiagnosis_1 <- \n  diagnose_design(\n    design, diagnosands = diagnosands)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nInquiry\nEstimator\nTerm\nN Sims\nBias\nMean Estimate\nMean Estimand\n\n\n\n\ndesign\nATE\niv_robust\nX\n200\n-0.01\n0.99\n1.00\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\ndesign\nfirst_stage\nfirst\nZ\n200\n0.09\n0.39\n0.30\n\n\n\n\n\n\n\n(0.00)\n(0.00)\n(0.00)\n\n\ndesign\nITT\nitt\nZ\n200\n0.09\n0.39\n0.30\n\n\n\n\n\n\n\n(0.00)\n(0.00)\n(0.00)\n\n\ndesign\nLATE_U1\niv_robust\nX\n200\n-0.01\n0.99\n1.00\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\ndesign\nLATE_Z\niv_robust\nX\n200\n-0.01\n0.99\n1.00\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\n\n\n\nLet’s take the diagnosis estimand-by-estimand:\n\nThe ATE is well-estimated by the instrumental variables estimator. This, despite the fact that:\nThe first stage regression estimates are biased for the average effect of \\(Z\\) on \\(X\\) because of the unobserved confounder \\(U_1\\).\nThe ITT estimates are also biased because of the confounding between \\(Y\\) and \\(Z\\).\nThe instrumental variables performs well for the LATE, as defined here. But in this case the LATE is the same as the ATE so this is not surprising.\n\nYou see in the estimator column that the bias in the ITT and first stage estimates are proportionate, such that, in the ratio, the bias cancels out. We provide some intuition for this result below, where we show how it can also break down.\nThe upshot is that when assessing the validity of IV you might be imposing an additional assumption that you might not need to impose. This may be good news in some specific research settings where the more stringent assumption of exogenous assignment of \\(X\\) to \\(Z\\) is not well justified.4\n\nAllowing heterogeneity\nWe show here that we lose the ability to estimate the effect of \\(X\\) on \\(Y\\) when this effect varies among compliance types – the \\(U_1\\)-compliers, the \\(Z\\)-compliers, and the never-takers.5 We can quickly redesign to allow heterogeneity, and see that now, we are biased for all the estimands!\n\ndesign_h <- redesign(design, heterogeneity = 1)\n\ndiagnosis_2 <- \n  diagnose_design(\n    design_h, diagnosands = diagnosands)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nheterogeneity\nInquiry\nEstimator\nTerm\nN Sims\nBias\nMean Estimate\nMean Estimand\n\n\n\n\ndesign_h\n1\nATE\niv_robust\nX\n200\n-0.34\n2.76\n3.10\n\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\ndesign_h\n1\nfirst_stage\nfirst\nZ\n200\n0.09\n0.39\n0.30\n\n\n\n\n\n\n\n\n(0.00)\n(0.00)\n(0.00)\n\n\ndesign_h\n1\nITT\nitt\nZ\n200\n0.18\n1.08\n0.90\n\n\n\n\n\n\n\n\n(0.00)\n(0.00)\n(0.00)\n\n\ndesign_h\n1\nLATE_U1\niv_robust\nX\n200\n0.76\n2.76\n2.00\n\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\ndesign_h\n1\nLATE_Z\niv_robust\nX\n200\n-0.24\n2.76\n3.00\n\n\n\n\n\n\n\n\n(0.01)\n(0.01)\n(0.00)\n\n\n\n\n\nWhy was the bias so much lower under homogeneous effects of \\(X\\) on \\(Y\\) for compliers?\nHere’s some intuition. In both the heterogeneous and homogeneous cases, we misattribute some of the effect of \\(U_1\\) on \\(X\\) to the effect of \\(Z\\) on \\(X\\), because those for whom \\(U_1 = 1\\) are also more likely to have \\(Z = 1\\). Thus, we overestimate the first stage in proportion to this misattribution. In both the homogeneous and heterogeneous cases, we estimate that \\(Z\\) increases the probability of \\(X = 1\\) by 39pp on average, whereas the true effect is 30pp. When we compute the effect of \\(Z\\) on \\(Y\\) for the ITT, those \\(U_1\\)-compliers that we mistook for \\(Z\\)-compliers also produce an effect on \\(Y\\) that we again misattribute to \\(Z\\), though in fact it was caused by the effect of \\(U_1\\) running through \\(X\\). The extent of this misattribution in the ITT is the same as the extent of the misattribution in the first stage when the effects of \\(X\\) on \\(Y\\) are homogeneous. Thus, even though we wanted to divide 0.3 / 0.3 to get 1, we ended up dividing 0.39 / 0.39 – and we still got 1! When the effects are heterogeneous, however, we lose this proportionality: because the effect of \\(X\\) on \\(Y\\) is bigger now for \\(Z\\)-compliers than for \\(U_1\\) compliers, our estimate of the ITT is not biased enough!. We would have wanted to estimate an ITT of 1.20 so that our IV estimator would have given us the true ATE via 1.20 / 0.39 = 3.10. But instead, we misattribute the \\(U_1\\)-compliers’ effect of \\(X\\) on \\(Y\\) to the \\(Z\\)-compliers in a way that is disproportionate to the misattribution of the first stage, \\(Z\\) on \\(X\\). We don’t have enough bias to unbias our estimates!\n\n\nWith non causal instruments the “compliers” are those that comply with respect to the unobserved causal instrument\nAlthough we have described \\(Z\\) as being the instrument, you can see in this DAG that both \\(Z\\) and \\(U_1\\) can affect \\(X\\). So perhaps \\(U_1\\) should thought of as an instrument even if it is unobserved? And perhaps compliers should be thought of as units that comply with \\(U_1\\) and not \\(Z\\)?\nTo explore this possibility, we diagnose design modifications that shift probability mass between two special cases of the DAG.\nThe first special case is the standard IV setup with no arrow between \\(U_1\\) and \\(X\\). The second special case is one discussed in Swanson and Hernán (2017) in which \\(Z\\) is a “noncausal instrument” and the true causal instrument is the unobserved \\(U_1\\). We get this by removing the path from \\(Z\\) to \\(X\\). Swanson and Hernán (2017) show that even though \\(Z\\) does not itself affect \\(X\\), instrumenting \\(X\\) with \\(Z\\) will recover good estimates of a well-defined estimand. You guessed it, that estimand is the LATE for \\(U_1\\) compliers. Amazing!\nThese cases are the two extremes of a continuum of the relative strength of the two paths. To be clear those two paths are U1 --> X and Z --> X. We can adjust the strength of those two paths with the path_weight parameter in our design. For this last simulation, we’ll consider 5 values for this parameter between 0 and 1.\n\ndesigns <- redesign(design, heterogeneity = 1, path_weight = seq(0.01, .99, length = 5))\n\ndiagnosis_3 <- diagnose_design(\n  designs, diagnosands = diagnosands)\n\n\n\n\n\n\nLet’s consider the graph from left to right.\nAll the way to the left, all the compliers are \\(Z\\) compliers. Equivalently, all the way to the left, \\(U_1\\) has no effect on \\(X\\). That’s the standard IV setup in which \\(Z\\) is as-if randomized, so our estimates of the ITT, the first stage, and the LATE are all on target.\nAll the way to the right, all the compliers are \\(U_1\\)-compliers, because \\(Z\\) has no effect on \\(X\\). That’s the “non causal instrument” case described in Swanson and Hernán (2017) (see also Brito and Pearl (2002)). The estimates of everything else – the ITT, the first stage, and the ATE are all quite biased, but the IV estimator does a good job of estimating the LATE among \\(U_1\\)-compliers.\nIn between the leftmost and rightmost extremes, however, our estimates of all of the estimands are biased. Indeed, the middle case (at the 0.50 mark) is exactly the situation we described in the “Allowing heterogeneity” section above. It’s possible (and we’d love to hear from you if you have ideas along these lines!) that an alternative estimation strategy would recover good estimates of one or more of these estimands.\n\n\nBlog update\nThis will be the last of our weekly blog posts on declaredesign.org. When we started blogging, we set ourselves a goal of six months of posts. We really enjoyed putting these posts together, but we’re also excited to shift attention to other parts of the project. We expect to continue to post occasionally here and to put up more informal posts on http://discuss.declaredesign.org and we’d love it if you joined us there.\nYours in declaration and diagnosis,\nGraeme, Jasper, Alex, and Macartan\n\n\n\n\n\n\n\n\n\nReferences\n\nBrito, Carlos, and Judea Pearl. 2002. “Generalized Instrumental Variables.” In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence, 85–93. Morgan Kaufmann Publishers Inc.\n\n\nHernán, Miguel A, and James M Robins. 2006. “Instruments for Causal Inference: An Epidemiologist’s Dream?” Epidemiology, 360–72.\n\n\nSwanson, Sonja A, and Miguel A Hernán. 2017. “The challenging interpretation of instrumental variable estimates under monotonicity.” International Journal of Epidemiology 47 (4): 1289–97.\n\n\nSwanson, Sonja A, Miguel A Hernán, Matthew Miller, James M Robins, and Thomas S Richardson. 2018. “Partial Identification of the Average Treatment Effect Using Instrumental Variables: Review of Methods for Binary Instruments, Treatments, and Outcomes.” Journal of the American Statistical Association 113 (522): 933–47.\n\nFootnotes\n\n\nDenoting \\(x\\) the value that the endogenous variable \\(X\\) takes, compliers have \\(x = f_X(Z) = Z\\), never-takers have \\(x = f_X(Z) = 0\\), always-takers have \\(x = f_X(Z) = 1\\), and defiers have \\(x = f_X(Z) = (1 - Z)\\).↩︎\nThe value \\(X\\) takes could depend on all four potential combinations of \\(U_1\\) and \\(Z\\). So if \\(x = f_X(U_1,Z)\\), you have to think about every possible way in which \\(f_X(0,0)\\), \\(f_X(1,0)\\), \\(f_X(0,1)\\) and \\(f_X(0,0)\\) can map into values of \\(x\\).↩︎\nThe assumption that there are no types who “defy” their \\(U_1\\) or \\(Z\\) assignments amounts to a monotonicity assumption common in the IV framework.↩︎\nOf course, the result also holds when \\(Z\\) and \\(X\\) are unconfounded, which also allows for unbiased estimation of the ITT and the first stage, which may be of practical or theoretical interest in and of themselves.↩︎\nMore precisely, weaker conditions than homogeneity can be sufficient for identification. As put by Hernán and Robins (2006), a sufficient assumption is that “the X-Y causal risk difference is the same among treated subjects with \\(Z=1\\) as among treated subjects with \\(Z=0\\), and similarly among untreated subjects.” See other conditions discussed in Swanson et al. (2018).↩︎"
  },
  {
    "objectID": "blog/learning-from-p.html",
    "href": "blog/learning-from-p.html",
    "title": "What does a p-value tell you about the probability a hypothesis is true?",
    "section": "",
    "text": "This post is inspired by conversations with @david_colquhoun who has been doing a lot of work on the misinterpretation of p-values (see especially “The false positive risk: a proposal concerning what to do about p values”). David poses the question “what is the probability that the null hypothesis is true given the observed \\(p\\)-value?” and provides a nice approach to answering this in terms of a “false positive risk.” The approach we present here is similar in spirit though based on a simulation approach given defined priors rather than being based on likelihood ratios.1\nThe key insight is that there is something to the intuition that if the world doesn’t look how it ought to look if indeed some hypothesis is right, then maybe that hypothesis isn’t right. Formally the connection comes via Bayes rule; the \\(p\\)-value (or, likelihood) plays a big role in Bayes’ formula for calculating the quantity of interest: posterior beliefs in hypotheses, given data.2 To use the rule though you need information on prior beliefs. Unfortunately, since “frequentist” statistics make no use of prior beliefs many researchers generally don’t report priors (indeed since frequentists and Bayesians think about probabilities differently, some will balk at the idea).\nBut what if you did have access to priors? With priors, you can construct Bayesian inferences from the diagnosis of a frequentist design. If we encode our priors into the population declaration then we can map from \\(p\\) to posteriors and let \\(p\\) answer the question we keep on wanting it to answer.\nHere is an illustration. Unlike most other designs we have looked at, in this design the estimand has a distribution. For simplicity we consider a design with a binary outcome; the estimand is the average treatment effect (or in epidemiology the “absolute risk increase”). The distribution for b in our model of the world reflects our beliefs about the estimand: we assume that it is distributed uniform over 0 and 1.3\n\nN <- 50\ndesign <- \n  declare_model(N = N, b = runif(1, min = 0, max = 1), u = runif(N, min = 0, max = 1),\n                potential_outcomes(Y ~ (u < b)*Z + (u > (1 + b)/2))) +\n  declare_assignment(Z = complete_ra(N)) +\n  declare_inquiry(ATE = b[1]) +\n  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +\n  declare_estimator(Y ~ Z)\n\nWhen we simulate this design, each run takes a different estimand (b) from the uniform distribution, generates data and calculates effects and \\(p\\)-values.\n\nsimulations <- simulate_design(design) \n\nNow if we graph the estimand from each run against the \\(p\\)-values from each run we can see the distribution of estimands conditional on the \\(p\\)-value. We can now think of each vertical slice of this graph as displaying the posterior distribution of estimands given \\(p\\).\n\n\n\n\nsimulations %>%\n  ggplot(aes(y = estimand, x = p.value)) +\n    geom_point(size = 1, alpha = 0.1) +\n    stat_smooth(se = FALSE) +\n    scale_x_continuous(trans='sqrt', breaks = c(0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 1)) +\n    xlab(\"p.value (square root scale to clearly distinguish small values)\")\n\n\n\n\nWe see from the graph that a Bayesian who has access to the study design and who learns only about the \\(p\\)-value from a study should update sharply about the size of the treatment effect.4 If they see a very low \\(p\\) they should infer that the effect is large. Conversely, if they see a high \\(p\\) they should infer that the effect is probably quite small: in other words, they do infer, contrary to frequentist wisdom, that absence of evidence is evidence of absence.\n\nPosterior beliefs about a null require prior mass on the null\nWe have shown a set of posterior distributions and marked the posterior mean, but we have not calculated the probability that the null is true. The reason is that, if the prior places a zero probability on the null hypothesis \\(b=0\\), then so will the posterior. To form a posterior on the null being true, one needs a prior distribution that is consistent with the null. One possibility is that you might think of the null hypothesis as being about a range (“the ate is small”) rather than a value (“the ate is 0”). Another possibility is that you really put prior probability mass on a point null, which is what we do here.\nHere we make a new design, in which we specify the prior belief that the true effect is 0 with 50% probability, and otherwise is flat over [0,1]. Remember, our priors are coded in the distribution we provide for b in our model of the world. Here’s the modified design:\n\npop_mass    <- declare_model(N = N, \n                                  b = sample(c(0, runif(1, min = 0, max = 1)), prob = c(.5, .5), size = 1), \n                                  u = runif(N, min = 0, max = 1))\ndesign_mass <- replace_step(design, 1, pop_mass)\n\nWe simulate the design again, but this time on the \\(y\\)-axis we plot the proportion of simulations in which the true effect is 0 at a given \\(p\\)-value: in other words, we graph the posterior probability that the estimand is zero.\n\nsimulations <- simulate_design(design_mass)\n\n\n\n\n\n\n\n\n\nThe \\(p\\)-value increases with the probability that the null hypothesis is true.\n\n\nWarning: Posteriors depend on the design, not just on the results\nIt is nice that one can make inferences about estimands using \\(p\\)-values. But unfortunately, there is no general mapping from \\(p\\)-values to posteriors. Obviously priors matter. Less obviously, perhaps, you also need to have access to the design itself, which determines the likelihood. For instance, the inferences made from knowledge of a \\(p\\)-value would be different for large and small studies.\nWe illustrate briefly by expanding design_mass to two designs with different \\(N\\)s and showing the mapping from \\(p\\)s to posteriors on the null for each of these.\n\ndesigns <- redesign(design_mass, N = c(50, 500))\n\n\n\n\n\n\n\n\n\nWe see here that for any \\(p\\)-value your belief that the null is true will be greater in the large \\(N\\) case than in the small \\(N\\) case (of course if the null is not true, then you expect to have a smaller \\(p\\) in the large \\(N\\) case than in the small \\(N\\) case).\n\n\nImplications for frequentist friends\nDesign diagnosis does not substitute for proper Bayesian analysis. However, there is a payoff for Bayesians with frequentist friends. If you can get them to encode their prior beliefs and declare their designs, then you get a tool to quickly figure out what they should believe given what they find.\n\n\n\n\n\nFootnotes\n\n\nDavid’s goal is more ambitious also as he is advocating for a new reporting norm for conveying the strength of evidence and so he explicitly seeks a statistic that is easy to calculate and can be calculated with a kind of common prior.↩︎\nIf \\(p\\) is the probability of the data under the null, and \\(q\\) is the quantity we care about (the probability of the null given the data), \\(\\pi\\) is the prior on the null, and \\(p'\\) and \\(\\pi'\\) are corresponding quantities for a complementary hypothesis, then Bayes rule says \\(q = p \\pi /(p \\pi + p' \\pi')\\).↩︎\nMore precisely we assume a process in which for effect \\(b\\), share \\(b\\) of the units are affected positively by treatment, share \\((1-b)/2\\) has outcome \\(Y=0\\) regardless and share \\((1-b)/2\\) has outcome \\(Y=1\\) regardless. Note that this is an informative prior—in particular it rules out the possibility of negative effects.↩︎\nIt’s easy and interesting to do the same thing to assess what one should believe about the estimand given the estimate (or given both the estimate and the \\(p\\)-value.)↩︎"
  },
  {
    "objectID": "blog/use-change-scores-or-control.html",
    "href": "blog/use-change-scores-or-control.html",
    "title": "Use change scores or control for pre-treatment outcomes? Depends on the true data generating process",
    "section": "",
    "text": "For a discussion see this post by Andrew Gelman and follow up comments by Winston Lin (that led us to the Allison reference we use below) and by Jens Hainmueller (that describes this logic).\nIn this post, design diagnosis shows that which approach is best depends on how outcomes are generated in the first place. A differencing approach might sometimes be effective at removing confounding bias but might do so at a cost of greater variance. Using this approach might not be optimal if confounding risks are small. Indeed, when there is no confounding (as in a randomized experiment), controlling is generally superior to differencing.\n\nAssessing tradeoffs via diagnosis\nTo illustrate, we declare a two-period, two-arm design in which a unit-specific shock \\(u\\) (with standard deviation .5) is present in each of the two periods. This shock is also possibly correlated with treatment assignment. In addition there are independent unit/period specific shocks, \\(e_1\\) and \\(e_2\\) (with unit standard deviations). For the illustration we assume a unit treatment effect:\n\\[Y_1 = u + e_1\\]\n\\[Y_2 = Z + u + e_2\\]\nA parameter in the design, \\(r\\) controls the degree of confounding. With \\(r = 0\\) there is as-if random assignment; with \\(r = 1\\) treatment assignment probabilities are directly related to \\(u\\).\nHere is the declaration:\n\nr <- 1   # magnitude of confounding\n\nprepost <- \n  \n  declare_model(N = 100, \n                u = rnorm(N) / 2, \n                e1 = rnorm(N), \n                e2 = rnorm(N), \n                Y1 = u + e1,\n                potential_outcomes(Y2 ~ Z + u + e2)\n  ) + \n  \n  declare_assignment(Z = simple_ra(N, prob_unit = r * pnorm(u) + (1 - r) * .5)) +\n  \n  declare_inquiry(ate = mean(Y2_Z_1 - Y2_Z_0)) +\n  \n  declare_measurement(Y2 = reveal_outcomes(Y2 ~ Z),\n                      D = Y2 - Y1) +\n  \n  declare_estimator(Y2 ~ Z, model = lm_robust, inquiry = \"ate\", \n                    label = \"Naive\") +\n  \n  declare_estimator(Y2 ~ Z + Y1, model = lm_robust, inquiry = \"ate\", \n                    label = \"Condition on pretest\") +\n  \n  declare_estimator(D ~ Z, model = lm_robust, inquiry = \"ate\", \n                    label = \"Change scores\") \n\nWe will diagnose a sequence of designs with different degrees of confounding:\n\nprepost_designs <- redesign(prepost, r = seq(from = 0, to = 1, length = 5))\ndiagnosis       <- diagnose_design(prepost_designs)\n\n\n\n\nDiagnosis reveals that the change score approach dominates the condition-on-pretest approach in terms of root mean squared error (RMSE) when the risk of bias is high but not when it is low.\n\nget_diagnosands(diagnosis) %>%\n  ggplot(aes(as.numeric(as.character(r)), rmse)) +\n  geom_line(aes(color = estimator)) +\n  theme_bw() + xlab(\"r\")\n\n\n\n\n\n\nWhat drives the tradeoff?\nWe can take a closer look by decomposing RMSE into bias and variance.\nRegardless of the value of r, change scores exhibit much less bias than conditioning. Units that are higher in the unobserved variable \\(u\\) are higher in \\(Y_2\\) and also more likely to be assigned to \\(Z\\). Putting \\(Y_1\\) on the righthand side, however, does not solve this confounding, for reasons explained in Allison (1990) — in short, the regression model with \\(Y_1\\) on the righthand side assumes that \\(Y_1\\) is uncorrelated with the error term, which it is not.1\nDifferencing always does well here in terms of bias because it removes the shock, \\(u\\), that is associated with treatment assignment: \\(D = Y_2 - Y_1 = Z + u + e_2- u - e_1 = Z + e_2 - e_1\\).\nThe naive approach does poorly here in terms of bias as it does nothing to account for confounding. Controlling for the pretest only partially removes the bias, which can remain quite substantial at high value of r.\nThe bias advantage for change scores is smaller at lower values of r and can be outweighed by the additional variance it introduces into the estimates. Change scores difference out \\(u\\) at a cost of taking on both the \\(e_1\\) and \\(e_2\\) errors. In this design, \\(Var(Y_2 | Z) = Var(u + e_2) = 1.25\\) whereas \\(Var(Y_2 - Y_1 | Z) = Var(u + e_1 - u - e_2) = Var(e_1 - e_2) = 2\\). Much noisier.\n\n\n\n\n\n\n\nTakeaway\nThe takeaway is that with non-experimental designs you cannot have a general preference over these two approaches to taking account of baseline data. You need to use knowledge about how data is generated to determine the right approach. The type of confounding matters, as does the size of different types of errors. If you can speculate about these then diagnosis can help select a strategy (though even after diagnosis, how you choose can depend in part on how you weigh bias and error).\nFor experimental designs (represented here by the cases of r = 0), the choice between the two approaches is much clearer: don’t use change scores, control. The risk of bias is neglibile (see Lin (2013) on this point) and the estimates will be far more precise.\n\n\n\n\n\n\n\n\n\nReferences\n\nAllison, Paul D. 1990. “Change Scores as Dependent Variables in Regression Analysis.” Sociological Methodology, 93–114.\n\n\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” The Annals of Applied Statistics 7 (1): 295–318.\n\nFootnotes\n\n\nIndeed although the differencing approach has an “implied” coefficient of 1 on \\(Y_1\\), Allison (p 103) shows that the average estimated coefficient on \\(Y_1\\) from the control approach will be less than 1. In our case it is, on average, just 0.18.↩︎"
  },
  {
    "objectID": "blog/give-me-a-random-assignment-yesterday.html",
    "href": "blog/give-me-a-random-assignment-yesterday.html",
    "title": "Get me a random assignment YESTERDAY",
    "section": "",
    "text": "You’re partnering with an education nonprofit and you are planning on running a randomized control trial in 80 classrooms spread across 20 community schools. The request is in: please send us a spreadsheet with random assignments. The assignment’s gotta be blocked by school, it’s gotta be reproducible, and it’s gotta be tonight. The good news is that you can do all this in a couple of lines of code. We show how using some DeclareDesign tools and then walk through handling of more complex cases."
  },
  {
    "objectID": "blog/give-me-a-random-assignment-yesterday.html#incorporate-known-data-into-a-dataframe-before-randomization",
    "href": "blog/give-me-a-random-assignment-yesterday.html#incorporate-known-data-into-a-dataframe-before-randomization",
    "title": "Get me a random assignment YESTERDAY",
    "section": "Incorporate known data into a dataframe before randomization",
    "text": "Incorporate known data into a dataframe before randomization\nIn general the world is not quite as neat as in the example above. Say in fact our data came in like this (of course it would be easier if you were sent a nice dataset but you cannot always count on that):\n\nJust got the numbers: School 1 has 6 classes, school 2 has 8, schools 4 and 8 have 3 classes, schools 5 and 9 have 5, school 6 has 2, school 10 has 7. Remember we need this yesterday.\n\nWe want to incorporate this information in the data fabrication step. The add_level functionality in the fabricate function is key here for respecting the multilevel nature of the dataset.\n\nmake_data <- declare_model(\n  school = add_level(N = 10),\n  class  = add_level(N = c(6, 8, 4, 3, 5, 2, 4, 3, 5, 7)))\n\nThis new function would generate a data set that reflects the number of classes in each school."
  },
  {
    "objectID": "blog/give-me-a-random-assignment-yesterday.html#make-better-blocks-from-richer-data",
    "href": "blog/give-me-a-random-assignment-yesterday.html#make-better-blocks-from-richer-data",
    "title": "Get me a random assignment YESTERDAY",
    "section": "Make better blocks from richer data",
    "text": "Make better blocks from richer data\nSay that you had even richer data about the sampling frame. Then you could use this to do even better assignments. Say this is what you get from your partner:\n\nWe just got information on the class sizes. Here it is: School 1: 20, 25, 23, 30, 12, 15; School 2: 40, 42, 53, 67, 35, 22, 18, 18; School 3: 34, 37, 28, 30; School 4: 18, 24, 20; School 5: 10, 24, 13, 26, 18; School 6: 20, 25; School 7: 28, 34, 19, 24; School 8: 32, 25, 31; School 9: 23, 20, 33, 22, 35; School 10: 20, 31, 34, 35, 18, 23, 22\n\nWe want to incorporate this information in the data fabrication step.\n\nmake_data <- declare_model(\n    school = add_level(N = 10),\n    class = add_level(N = c(6, 8, 4, 3, 5, 2, 4, 3, 5, 7),\n                size = c(\n                  20, 25, 23, 30, 12, 15,         # students in each classroom of school 1\n                  40, 42, 53, 67, 35, 22, 18, 18, # students in each classroom of school 2\n                  34, 37, 28, 30,                 # etc...\n                  18, 24, 20,\n                  10, 24, 13, 26, 18,\n                  20, 25,\n                  28, 34, 19, 24,\n                  32, 25, 31,\n                  23, 20, 33, 22, 35,\n                  20, 31, 34, 35, 18, 23, 22\n                )))\n\nThis new data on class sizes might be very useful.\nIf the NGO wants to examine individual level outcomes but is using a classroom-level intervention, then this design is using “clustered” random assignment (students clustered into classrooms). As noted in Imai et al. (2009), however, if clusters are of uneven sizes, standard estimation approaches can be biased, even though it’s a randomized experiment. They propose blocking on cluster size in order to address this problem. We’ll use blockTools (by Ryan T. Moore and Keith Schnakenberg) to block on both school and classroom size within schools.\nThe block function within blockTools forms blocks as a function of size by pairing similarly-sized classrooms (blocks of size 2 is the default for the block function, though this can be changed). By telling the function that classes are grouped within schools, we can ensure that blockTools will pair classrooms within the same school. We turn this functionality into a design step like this:\n\n# A step to generate blocks\nblock_function <- function(data) {\n    out <- block(data, id.vars = \"class\", groups = \"school\", block.vars = \"size\")\n    mutate(data, block_id = createBlockIDs(out, data, id.var = \"class\"))}\n\nmake_blocks <- declare_step(handler =  block_function)\n\nLet’s make a design that includes this step and now uses block_id instead of class for blocking:\n\ndesign <- make_data + make_blocks + declare_assignment(Z = block_ra(blocks = block_id))\n\nWhen we draw data we now get the block variables and the assignment probabilities included. One out of two units is assigned to each block of two and singleton blocks are assigned independently with 0.5 probability to treatment.\n\nour_df <- draw_data(design)\n\nWarning: `is.tibble()` was deprecated in tibble 2.0.0.\nPlease use `is_tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\n\n\n\n\n \n  \n    school \n    class \n    size \n    block_id \n    Z \n  \n \n\n  \n    01 \n    01 \n    20 \n    3 \n    0 \n  \n  \n    01 \n    02 \n    25 \n    1 \n    1 \n  \n  \n    01 \n    03 \n    23 \n    1 \n    0 \n  \n  \n    01 \n    04 \n    30 \n    3 \n    1 \n  \n  \n    01 \n    05 \n    12 \n    2 \n    0 \n  \n  \n    01 \n    06 \n    15 \n    2 \n    1 \n  \n  \n    02 \n    07 \n    40 \n    5 \n    0 \n  \n  \n    02 \n    08 \n    42 \n    5 \n    1 \n  \n  \n    02 \n    09 \n    53 \n    7 \n    0 \n  \n  \n    02 \n    10 \n    67 \n    7 \n    1 \n  \n  \n    02 \n    11 \n    35 \n    6 \n    1 \n  \n  \n    02 \n    12 \n    22 \n    6 \n    0 \n  \n  \n    02 \n    13 \n    18 \n    4 \n    0 \n  \n  \n    02 \n    14 \n    18 \n    4 \n    1 \n  \n  \n    03 \n    15 \n    34 \n    9 \n    0 \n  \n  \n    03 \n    16 \n    37 \n    9 \n    1 \n  \n  \n    03 \n    17 \n    28 \n    8 \n    1 \n  \n  \n    03 \n    18 \n    30 \n    8 \n    0 \n  \n  \n    04 \n    19 \n    18 \n    10 \n    1 \n  \n  \n    04 \n    20 \n    24 \n    11 \n    1 \n  \n  \n    04 \n    21 \n    20 \n    10 \n    0 \n  \n  \n    05 \n    22 \n    10 \n    13 \n    0 \n  \n  \n    05 \n    23 \n    24 \n    12 \n    0 \n  \n  \n    05 \n    24 \n    13 \n    13 \n    1 \n  \n  \n    05 \n    25 \n    26 \n    12 \n    1 \n  \n  \n    05 \n    26 \n    18 \n    14 \n    1 \n  \n  \n    06 \n    27 \n    20 \n    15 \n    0 \n  \n  \n    06 \n    28 \n    25 \n    15 \n    1 \n  \n  \n    07 \n    29 \n    28 \n    16 \n    1 \n  \n  \n    07 \n    30 \n    34 \n    17 \n    1 \n  \n  \n    07 \n    31 \n    19 \n    17 \n    0 \n  \n  \n    07 \n    32 \n    24 \n    16 \n    0 \n  \n  \n    08 \n    33 \n    32 \n    18 \n    0 \n  \n  \n    08 \n    34 \n    25 \n    19 \n    0 \n  \n  \n    08 \n    35 \n    31 \n    18 \n    1 \n  \n  \n    09 \n    36 \n    23 \n    20 \n    0 \n  \n  \n    09 \n    37 \n    20 \n    22 \n    1 \n  \n  \n    09 \n    38 \n    33 \n    21 \n    0 \n  \n  \n    09 \n    39 \n    22 \n    20 \n    1 \n  \n  \n    09 \n    40 \n    35 \n    21 \n    1 \n  \n  \n    10 \n    41 \n    20 \n    25 \n    0 \n  \n  \n    10 \n    42 \n    31 \n    26 \n    1 \n  \n  \n    10 \n    43 \n    34 \n    23 \n    1 \n  \n  \n    10 \n    44 \n    35 \n    23 \n    0 \n  \n  \n    10 \n    45 \n    18 \n    25 \n    1 \n  \n  \n    10 \n    46 \n    23 \n    24 \n    1 \n  \n  \n    10 \n    47 \n    22 \n    24 \n    0 \n  \n\n\n\n\n\n\nThe graph below shows that indeed, the blocking formed pairs of classrooms within each school that are similar to one another and correctly left some classrooms in a block by themselves when there was an odd number of classrooms in a school.\n\nour_df %>%\n  ggplot(aes(size, block_id, color = as.factor(Z))) +\n  geom_point() +\n  facet_wrap(~school, scales = \"free_y\", ncol = 5)"
  },
  {
    "objectID": "blog/give-me-a-random-assignment-yesterday.html#replicate-yourself",
    "href": "blog/give-me-a-random-assignment-yesterday.html#replicate-yourself",
    "title": "Get me a random assignment YESTERDAY",
    "section": "Replicate yourself",
    "text": "Replicate yourself\nIf you set up your assignments as functions like this then it is easy to implement the assignment multiple times:\n\nmany_assignments <- replicate(1000, draw_data(design))\n\nIt’s useful to preserve a collection of assignments like this. One advantage is that it lets you see directly what the real assignment probabilities are—not just the intended assignment probabilities. This is especially useful in complex randomizations where different units might get assigned to treatment with quite different probabilities depending on their characteristics (for instance a procedure that rejects assignment profiles because of concerns with imbalance). Calculating the actual probabilities lets you figure out if you have set things up correctly and in some cases can even be useful for correcting things at the analysis stage if you have not!1 In addition the collection of assignments stored in many_assignment are exactly the assignments you should use for some randomization inference tests."
  },
  {
    "objectID": "blog/give-me-a-random-assignment-yesterday.html#save-the-output-to-an-excel-spreadsheet",
    "href": "blog/give-me-a-random-assignment-yesterday.html#save-the-output-to-an-excel-spreadsheet",
    "title": "Get me a random assignment YESTERDAY",
    "section": "Save the output to an excel spreadsheet",
    "text": "Save the output to an excel spreadsheet\nYour partners mightn’t love csv spreadsheets. But you can easily save to other formats.\nMany people love Microsoft Excel. Using the writexl package (by Jeroen Ooms) will make them happy:\n\nlibrary(writexl)\n\nset_seed(20181204)\n\nour_df <- draw_data(design)\n\nwrite_xlsx(our_df, path = \"students_with_random_assignment.xlsx\")"
  },
  {
    "objectID": "blog/randomization-does-not-justify-t-tests.html",
    "href": "blog/randomization-does-not-justify-t-tests.html",
    "title": "Randomization does not justify t-tests. How worried should I be?",
    "section": "",
    "text": "Deaton and Cartwright (2017) provide multiple arguments against claims that randomized trials should be thought of as a kind of gold standard of scientific evidence. One striking argument they make is that randomization does not justify the statistical tests that researchers typically use. They are right in that. Even if researchers can claim that their estimates of uncertainty are justified by randomization, their habitual use of those estimates to conduct t-tests are not. To get a handle on how severe the problem is we replicate the results in Deaton and Cartwright (2017) and then use a wider set of diagnosands to probe more deeply. Our investigation suggests that what at first seems like a big problem might not in fact be so great if your hypotheses are what they often are for experimentalists—sharp and sample-focused.\nMore specifically, Deaton and Cartwright (2017) argue that that “spurious significance […] arises when the distribution of treatment effects contains outliers or, more generally, is not symmetric.” They back up the claim with simulation results from a case with heterogeneous asymmetrically distributed treatment effects that center on 0. In fact however, both the sharp null of no effect and the null of no average effect in a given sample are false in this example and so the worry about over-rejecting does not apply to these hypotheses.\nA bit more generally, under the sharp null of no effect the distribution of treatment effects in simple trials (with 50% assignment probabilities) will be perfectly symmetrical even if the distribution of potential outcomes is arbitrarily skewed and so the concern Deaton and Cartwright (2017) point to doesn’t arise in the first place.\nThe most important take away though might be that it’s hard to think through when the use of t-tests is or is not appropriate. But design diagnosis can tip you off to whether this likely a problem in your case."
  },
  {
    "objectID": "blog/randomization-does-not-justify-t-tests.html#there-is-no-skew-when-sharp-nulls-are-true",
    "href": "blog/randomization-does-not-justify-t-tests.html#there-is-no-skew-when-sharp-nulls-are-true",
    "title": "Randomization does not justify t-tests. How worried should I be?",
    "section": "There is no skew when sharp nulls are true",
    "text": "There is no skew when sharp nulls are true\nFor the record, we can do the same analysis when the sharp null is in fact true. This just requires replacing the potential outcomes step (step 2) in the design.\n\ndc_sharp <- replace_step(dc_design, 1, \n                         declare_model(N = N, u = rlnorm(N) - exp(.5), Y_Z_0 = u, Y_Z_1 = u))\ndiagnose_design(dc_sharp)\n\n\n\nWarning in sprintf(paste0(\"%.\", digits, \"f\"), as.numeric(x)): NAs introduced by\ncoercion\n\n\n\n\n\nInquiry\nSelect\nVar Estimate\nEst Var Est\nVar Estimand\n\n\n\n\nSATE\nNA\n0.37\n0.37\n0.00\n\n\n\nNA\n(0.01)\n(0.00)\n(0.00)\n\n\nSPATE\nNA\n0.37\n0.37\n0.00\n\n\n\nNA\n(0.01)\n(0.00)\n(0.00)\n\n\n\n\n\nWe find that we do not see the same issue arise when in fact the sharp null is true (in the superpopulation, and thus in every sample). With a true sharp null (and .5 assignment probabilities), even if the potential outcomes are very skewed, the distribution of estimated effects will be symmetrical for the simple reason that, for any estimated treatment effect \\(\\hat{\\tau}\\) arising from assignment \\(Z\\), assignment \\((1-Z)\\) yields \\((-\\hat{\\tau})\\). This clarifies that the skew-based concern about over-rejecting a null that Deaton and Cartwright raise actually depends on the sharp null being false in the first place. (Though, to be clear, the assumption of 50% assignment matters here — skew in estimated effects is certainly possible under the sharp null with other assignment probabilities.)"
  },
  {
    "objectID": "blog/randomization-does-not-justify-t-tests.html#but-there-can-still-be-dragons-so-then-what-to-do",
    "href": "blog/randomization-does-not-justify-t-tests.html#but-there-can-still-be-dragons-so-then-what-to-do",
    "title": "Randomization does not justify t-tests. How worried should I be?",
    "section": "But there can still be dragons, so then what to do?",
    "text": "But there can still be dragons, so then what to do?\nAlthough we might not have to worry about skew when sharp nulls are true, \\(t\\)-stats might still lead you astray when tails are fat.\nAs a simple example, imagine a world in which \\(Y = 0\\) for 50 units and \\(Y = 1\\) for 50 units, independent of \\(Z\\). Say \\(Z\\) is randomly assigned to just four units. Whenever \\(Z\\) is assigned to four units with the same value on \\(Y\\), a t-test will suggest a significant difference (\\(p = 0.04\\)). You can interpret that as a claim that such a data pattern should only be observed 4% of the time if the null is true. But you can figure out pretty quickly that you will see data patterns like this about one eighth of the time.2 So the probability of observing such data under the null is actually much higher than the 4% you might infer from the \\(t\\)-test.\nSo in general there can be dangers using t-tests even with experimental data. A solution in this instance, if we are interested in a sharp null of no effect, is to do randomization inference. This would produce exactly the right p-value. But that will help only if you are alerted to the problem. To alert yourself to the problem, you could routinely diagnose a design with zero effects (a “null design”) and so set yourself up to get a tip off when your power is too high."
  },
  {
    "objectID": "blog/biased-fixed-effects.html",
    "href": "blog/biased-fixed-effects.html",
    "title": "The trouble with ‘controlling for blocks’",
    "section": "",
    "text": "The trouble\nFor intuition, imagine a design that has experimental blocks (these might correspond to geographic regions or gender groups, for example). In block A, we treat 1/3 of the units and in block B, we treat 1/2. We are interested in an outcome \\(Y\\), income, for example. We worry though that if income is higher in group B than group A that we will have introduced a correlation between treatment and outcomes even if there is no causal effect of treatment on income. We want to avoid that kind of false inference.\nA good way to think about the problem is to recognize that the overall average treatment effect can be thought of as an average of the average treatment effects in each block. Luckily, figuring out the average effect within a block is not hard. We can think of each block as its own mini-experiment. Within each block all units are treated with the same probability and so difference-in-means estimation within a block works fine to get at the average effect for units in that block. In order to get an overall ATE estimate, we then just have to average the block level estimates together. So if we weight the within-group effects together by \\(n_j\\) (the size of block \\(j\\)), we have an unbiased estimator of the ATE.\nSimple enough.\nBut in practice researchers often try to do this calculation using “block fixed effects,” i.e., include a set of block dummies in a regression of the outcome on treatment assignment. The problem though is that while fixed-effects regression does average across within-block average effects, it does so using the wrong weighting scheme. The regression weights are \\(p_j(1-p_j)n_j\\), where share \\(p_j\\) of \\(n_j\\) units are treated within block \\(j\\). Fixed-effects OLS essentially puts more weight on the blocks with the greatest variance in the treatment variable.1\nLet’s demonstrate the issue using DeclareDesign and then move on to examining different solutions.\nFirst, we declare a design that has three equally-sized blocks, with block-specific effects (tau) and assignment probabilities (prob). We will use three answer strategies: simple regression of the outcome on the treatment indicator (Naive Pooled), a regression of the outcome on the treatment indicator and block fixed effects (Least Squares Dummy Variables), and a sample-weighted average of the within-block difference-in-means (Blocked DIM). We will use a design where the noise is quite small relative to the error to clarify that that the problem is not about precision.\nHere’s the design declaration:\n\n# Model ------------------------------------------------------------------------\nU <- declare_model(block = add_level(N = 3,\n                                     prob = c(.5, .7, .9),\n                                     tau = c(4, 2, 0)),\n                   indiv = add_level(N = 100, e = rnorm(N), \n                                     Y_Z_0 = e,\n                                     Y_Z_1 = e + tau))\n# Inquiry ----------------------------------------------------------------------\nQ <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))\n\n# Data Strategy ----------------------------------------------------------------\nZ <- declare_assignment(Z = block_ra(blocks = block, block_prob = c(.5, .7, .9)),\n                        Z_cond_prob = obtain_condition_probabilities(assignment = Z, blocks = block, block_prob = c(.5, .7, .9)))\nR <- declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# Answer Strategy --------------------------------------------------------------\nA0 <- declare_estimator(Y ~ Z, inquiry = Q,  \n                        model =  lm_robust, label = \"A0: Naive (Pooled)\")\nA1 <- declare_estimator(Y ~ Z + block, inquiry = Q,  \n                        model =  lm_robust, label = \"A1: LSDV\")\nA2 <- declare_estimator(Y ~ Z, blocks = block, inquiry = Q,  \n                        model =  difference_in_means, label = \"A2: Blocked DIM\")\n\n# Design -----------------------------------------------------------------------\ndesign <- U + Z + Q + R + A0 + A1 + A2\n\nDiagnosis of this design lets us see how these different strategies perform:\n\ndiagnose_design(design, sims = sims)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimator\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\nN Sims\n\n\n\n\nA0: Naive (Pooled)\n-0.38\n0.40\n1.00\n0.33\n1.62\n0.13\n0.17\n0.00\n2.00\n10000\n\n\nA1: LSDV\n0.58\n0.59\n1.00\n0.08\n2.58\n0.13\n0.20\n0.00\n2.00\n10000\n\n\nA2: Blocked DIM\n-0.00\n0.15\n1.00\n0.95\n2.00\n0.15\n0.15\n0.00\n2.00\n10000\n\n\n\n\n\nThe difference-in-means approach does a good job of estimating the true average treatment effect in the sample. The two other approaches get it terribly wrong.\nIt’s easy enough to see why the pooled estimator gets things wrong. In this design, the blocks with bigger treatment probabilities also have smaller outcomes in the treatment condition. This creates a negative relation between treatment and outcomes that pulls down the estimate of effects.\nBut, oddly, the fixed effects estimators is not just biased, it is biased in the opposite direction of the bias of the pooled estimator. Why is that?\n\n\nWhy do fixed effects get it wrong?\nWe can use the design to drill down and see where this bias from the fixed effects estimator is coming from. We will use the design to generate simulated data and to run our estimators on that single draw.2\n\none_draw <- draw_data(design)\nA1(one_draw)\nA2(one_draw)\n\n\n\nWarning in fn(data, ~(Y ~ Z + block), model = ~lm_robust): The argument 'model =\n' is deprecated. Please use '.method = ' instead.\n\n\nWarning in fn(data, ~(Y ~ Z), blocks = ~block, model = ~difference_in_means):\nThe argument 'model = ' is deprecated. Please use '.method = ' instead.\n\n\n\n\n\nestimator\nestimate\n\n\n\n\nA1: LSDV\n2.483\n\n\nA2: Blocked DIM\n1.914\n\n\n\n\n\nWith this simulated data we can calculate the within block effects and the block weights “by hand” to see how the differences-in-means approach and the fixed effects approach do things differently. For this we use dplyr functionality which makes it easy to operate within multiple blocks in parallel.\n\nwithin_block <-\n  one_draw %>%\n  group_by(block) %>%\n  summarise(block_ATE     = mean(Y_Z_1 - Y_Z_0),\n            block_ATE_est = mean(Y[Z == 1]) - mean(Y[Z == 0]),\n            n_j = n(),\n            p_j = mean(Z),\n            sample_weight = n_j,\n            fe_weight     = p_j * (1 - p_j) * n_j) %>%\n  # divide by the sum of the weights\n  mutate(sample_weight = sample_weight/sum(sample_weight),\n         fe_weight = fe_weight/sum(fe_weight))\n\n\n\n\n\n\nblock\nblock_ATE\nblock_ATE_est\nn_j\np_j\nsample_weight\nfe_weight\n\n\n\n\n1\n4\n4.06\n100\n0.5\n0.33\n0.45\n\n\n2\n2\n1.66\n100\n0.7\n0.33\n0.38\n\n\n3\n0\n0.02\n100\n0.9\n0.33\n0.16\n\n\n\n\n\nThis table helps explain the bias: one-third of the sample has an ATE estimate of 4.06, one-third has an ATE estimate of 1.66, and one-third an estimate of 0.02. Yet, the fixed effects estimator attributes those block-level estimated effects weights of 45%, 38%, and 16%, respectively: it exaggerates the true average effect by overweighting blocks with large effects and underweighting blocks with small effects.\nTo finish the example, see that we can recover the fixed effects and block DIM estimates from the within block estimates, just by choosing a different weighting strategy.\n\nwithin_block %>%\n  summarize(LDSV = weighted.mean(block_ATE_est, fe_weight),\n            Blocked_DIM = weighted.mean(block_ATE_est, sample_weight))\n\n\n\n\n\n\n\nEstimate\n\n\n\n\nLSDV\n2.483\n\n\nBlocked_DIM\n1.914\n\n\n\n\n\n\n\nA horserace between different approaches\nIn addition to block-wise difference-in-means, there are many other solutions that have been proposed to the problem outlined above. One might use a saturated regression (Lin 2013), inverse propensity-weighted (IPW) regression, IPW with fixed effects, fixed effects regression with units reweighted by the inverse variance of assignment in their block, or a Horvitz-Thompson estimator. A recent contribution by Gibbons, Serrato, and Urbancic (2018) suggests two new estimators (“interaction-weighted” and “regression-weighted” estimators) and provides a package to estimate them (bfe).\nLess clear, however, is how these different approaches compare against each other.\nWe can address this question for any design using design diagnosis. We add the different estimation approaches to our design:\n\nA3 <- declare_estimator(Y ~ Z, covariates = ~ block, inquiry = Q,\n                        model = lm_lin,\n                        label = \"A3: Interaction (Lin)\")\nA4 <- declare_estimator(Y ~ Z, inquiry = Q,\n                        model = lm_robust, weight = 1/Z_cond_prob,\n                        label = \"A4: IPW\")\nA5 <- declare_estimator(Y ~ Z, fixed_effects = ~block, inquiry = Q,\n                        model = lm_robust, weight = 1/Z_cond_prob,\n                        label = \"A5: IPW + FE\")\nA6 <- declare_estimator(Y ~ Z, fixed_effects = ~block, inquiry = Q,\n                        model = lm_robust, weight = 1/(Z_cond_prob*(1-Z_cond_prob)),\n                        label = \"A6: Var weight + FE\")\nA7 <- declare_estimator(Y ~ Z, inquiry = Q, blocks = block, simple = FALSE,\n                        model = horvitz_thompson, condition_prs = prob,\n                        label = \"A7: Horvitz-Thompson\")\nIWE <- function(data) {\n          M <- EstimateIWE(\"Y\", \"Z\", \"block\", controls = NULL, data = data)\n          data.frame(term = \"Z\" ,estimate = M$swe.est, std.error = M$swe.var^.5)}\n\nRWE <- function(data) {\n          M <- EstimateRWE(\"Y\", \"Z\", \"block\", controls = NULL, data = data)\n          data.frame(term = \"Z\", estimate = M$swe.est, std.error = M$swe.var^.5)}\n\nA8 <- declare_estimator(handler = label_estimator(IWE), inquiry = Q,\n                        label = \"A8: IWE\")\nA9 <- declare_estimator(handler = label_estimator(RWE), inquiry = Q,\n                        label = \"A9: RWE\")\n\n# Augmented Design ---------------------------------------------------------------\n\ndesign <- design + A3 + A4 + A5 + A6 + A7 #+ A8 + A9\n\nAnd we can then simulate and plot the estimates:\n\nsimulations <- simulate_design(design,sims = sims)\n\n\n\n\n\n\n\n\nsimulations %>%\n  group_by(estimator) %>%\n  summarize(SE_bias = mean(std.error - sd(estimate)),\n            ATE_bias = mean(estimate - estimand)) %>%\n  ggplot(aes(x = ATE_bias, y = SE_bias)) +\n  geom_point() +\n  geom_hline(yintercept = 0, size = .1, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, size = .1, linetype = \"dashed\") +\n  geom_text_repel(aes(label = estimator), box.padding = .65,\n                  point.padding = .5, segment.alpha = .5)\n\n\n\n\nInterestingly, the largest differences between the approaches appear to arise from the way in which they calculate the standard error. A great thing about design diagnosis is that one can assess the performance not just of estimates but also of standard errors. We use standard errors as a measure of the standard deviation of the estimates under repeated experiments. This is a quantity we have access to from simulation and so for each approach we can compare the estimated standard error to the standard deviation of the sampling distribution of effects.\nWe see that many approaches appear overly conservative – particularly the weighting approaches, though one approach estimates, on average, a standard error that is marginally smaller than the real standard deviation of the sampling distribution of estimated effects.\nIn terms of estimates, however, there are no real differences in performance between approaches 2-9. The block-specific difference-in-means approach has the merit of conceptual simplicity and great performance. The IPW and Horvitz-Thompson approaches have the advantage that they can be used even if the heterogeneity in assignment propensities is at the unit-level, and not at the block-level. And regression-based approaches have the merit of making it simple to condition on available covariates.\n\n\nThis issue is surprisingly common\nMany designs face this issue, where assignment propensities are different in different groups. Often the issue might not be immediately apparent. Some examples:\n\nSubjects are randomly matched to play a game and you are interested in assessing the difference in play between single gender and mixed gender pairings. There are different numbers of men and women in the group.\nA random set of children in a school are given some treatment and you are interested in seeing the effects on siblings of having another sibling treated. Families are of different sizes.\nOne village in each parish is selected for a treatment. But parishes are of different sizes. \n\nIn all these cases there is what looks at first glance to be equal assignment propensities across units but on closer inspection assignment propensities in fact depend on group size in some way.\nSee Gibbons, Serrato, and Urbancic (2018) for many examples in economics research and assessments of the implications of ignoring this issue.\n\n\n\n\n\n\n\n\n\nReferences\n\nAngrist, Joshua D. 1998. “Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants.” Econometrica 66 (2): 249–88.\n\n\nGibbons, Charles E, Juan Carlos Suárez Serrato, and Michael B Urbancic. 2018. “Broken or Fixed Effects?” Journal of Econometric Methods.\n\n\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” The Annals of Applied Statistics 7 (1): 295–318.\n\nFootnotes\n\n\nThis is a well known problem. See, for instance, Angrist (1998).↩︎\nFunctions in DeclareDesign create functions that take dataframes and return dataframes or statistics. Thus, we could also have taken one draw of the data using one_draw <- U() %>% Y %>% Z %>% R. The first five variables were created by U(): block indicates the block to which the unit belongs, prob indicates the probability of assignment to treatment, tau indicates the block-level treatment effect, indiv indicates the individual ID, and e is the error term. The function Y() appends the potential outcomes, Y_Z_0 and Y_Z_1, by taking e and adding tau in treatment. The function Z() appends two variables: Z is a vector of treatment assignments, block-randomized as a function of the block probabilities, while Z_cond_prob indicates the probability that a given unit is observed in the condition to which they were actually assigned. R() reveals the potential outcomes corresponding to the assignment.↩︎"
  },
  {
    "objectID": "blog/improve-power-using-your-answer-strategy-not-just-your-data-strategy.html",
    "href": "blog/improve-power-using-your-answer-strategy-not-just-your-data-strategy.html",
    "title": "Improve power using your answer strategy, not just your data strategy",
    "section": "",
    "text": "Most power calculators take a small number of inputs: sample size, effect size, and variance. Some also allow for number of blocks or cluster size as well as the overall sample size. All of these inputs relate to your data strategy. Unless you can control the effect size and the noise, you are left with sample size and data structure (blocks and clusters) as the only levers to play with to try to improve your power.\nIn fact, though, power depends on your answer strategy and not just your data strategy and so you might do better putting resources into improving what you do with your data rather than the amount of data you have.\n\nPower from the answer strategy\nRandom assignment generally means that you do not have to include control variables in an analysis in order to achieve unbiasedness. But including controls can improve precision and increase power. If you are trying to improve your power but adding observations is expensive, perhaps you should first explore whether you can improve power by adjusting the estimation approach.\nHere is an illustration of a two-arm trial with 40 units in which 20 units are assigned to treatment, blocking on a binary pre-treatment covariate \\(W\\). We’ll let the treatment effects vary according to \\(W\\), but the true average treatment effect (our estimand in this case) is equal to 1.\n\nN = 40\n\n# Model\nmodel <- declare_model(N, W = rep(0:1, N / 2), u = rnorm(N), potential_outcomes(Y ~ 2 * Z * W + u))  \n\n# Inquiry\ninquiry     <- declare_inquiry(ate = 1)  \n\n# Data strategy\nassignment   <- declare_assignment(Z = block_ra(blocks = W))\nmeasurement  <- declare_measurement(Y = reveal_outcomes(Y ~ Z))\n\n# Answer strategy\nestimator  <- declare_estimator(Y ~ Z, estimand = \"ate\", label = \"Simple D-I-M\")\n\n# Declare the design\ndesign <- model + inquiry + assignment + measurement + estimator\n\nUnder this data generating process, the treatment interacts quite strongly with \\(W\\). The average effect of treatment is 1, but the conditional average treatment effects are 0 and 2 for the two levels of \\(W\\). The difference-in-means analysis strategy for this design is equivalent to an OLS regression of the outcome on the treatment with no control variables included. Because of random assignment, this procedure is of course unbiased, but it leaves money on the table in the sense that we could achieve higher statistical power if we included information about \\(W\\) in some way. Here is the power of the difference-in-means answer strategy:\n\ndiagnose_design(design)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInquiry\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\nN Sims\n\n\n\n\nate\n0.32\n0.75\n0.98\n1.00\n0.32\n0.39\n0.00\n1.00\n10000\n\n\n\n\n\nSo power is good though short of conventional standards. Based on this diagnosis the probability of getting a statistically significant result is only 0.75 even though the true effect is reasonably large.\nLet’s consider two additional estimation strategies. The first controls for the pre-treatment covariate \\(W\\) in an OLS regression of the outcome on treatment plus the covariate. This strategy is the standard approach to the inclusion of covariates in experimental analysis. An alternative is the “Lin estimator,” so named by us because of the lovely description of this approach given in Lin (2013). This estimator interacts treatment with the de-meaned covariates. The lm_lin() function in the estimatr package implements the Lin estimator for easy use.\nHere is the expanded design and the diagnosis:\n\nnew_design <- design +\n              declare_estimator(Y ~ Z + W,  model = lm_robust,\n                                inquiry = \"ate\", label = \"OLS: Control for W\") +\n              declare_estimator(Y ~ Z, covariates = ~ W, model = lm_lin,\n                                inquiry = \"ate\", label = \"Lin: Control + Interaction\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimator\nBias\nRMSE\nPower\nCoverage\nMean Estimate\nSD Estimate\nMean Se\nType S Rate\nMean Estimand\nN Sims\n\n\n\n\nLin: Control + Interaction\n0.00\n0.32\n0.87\n0.95\n1.00\n0.32\n0.31\n0.00\n1.00\n10000\n\n\nOLS: Control for W\n0.00\n0.32\n0.81\n0.97\n1.00\n0.32\n0.35\n0.00\n1.00\n10000\n\n\nSimple D-I-M\n0.00\n0.32\n0.74\n0.99\n1.00\n0.32\n0.39\n0.00\n1.00\n10000\n\n\n\n\n\nWe see here a clear ranking of the three estimation strategies in terms of power. You will notice that the coverage also varies across designs: the simple difference in means approach is actually overly conservative in part because it does not take account of the blocked randomization. The OLS model that in some sense “controls for blocks” does better, but is still above the nominal coverage of 95%. In this case, the coverage of the Lin model is excellent.\n\n\nTradeoffs\nTo figure out how these gains in power from switching up estimation strategies compare with gains from increasing \\(N\\) we declare a sequence of designs, differing only in values for \\(N\\). We do that in two steps:\n\ndesigns   <- redesign(new_design, N = seq(30, 80, 10))\ndiagnoses <- diagnose_design(designs)\n\n\n\n\n\n\n\nThe diagnoses object now contains full diagnoses for a whole sequence of designs that assume different \\(N\\)s and that each contain multiple estimation strategies. Here is a graph of the output showing trade-offs between design size and estimation strategy.\n\ndiagnoses$diagnosands_df %>%\n  ggplot(aes(N, power)) +\n  geom_line(aes(color = estimator))\n\n\n\n\n\n\n\n\nWe see here that if you had 45 units and wanted to use simple differences in means your power would be around 80%. You could up your power to just over 90% by increasing the size of the experiment to about 60 units. Or, conditional on speculations about the heterogeneous effects of treatment, you could do the same thing by staying at 45 but switching over to the Lin estimator.\n\n\nA puzzle\nSometimes researchers coarsen control variables, for example turning a 10 point democracy scale into a binary variable, because they believe the finer scale is noisier. Can you declare a design to assess whether dichotomizing an outcome variable increases or decreases power?\n\n\n\n\n\n\n\n\nReferences\n\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” The Annals of Applied Statistics 7 (1): 295–318."
  },
  {
    "objectID": "blog/modelling-spillovers.html",
    "href": "blog/modelling-spillovers.html",
    "title": "Instead of avoiding spillovers, you can model them",
    "section": "",
    "text": "This is important because spillovers are part of the overall effects of an intervention. If vaccination of one subject improves health outcomes for another, then this gain needs to be understood to assess the total benefits of vaccination. This is hard because we are not used to thinking of spillover effects as estimands, or to writing them in terms of potential outcomes, and so we generally do not think in terms of bias or power for spillover effects. But we can.\n\nA spillover design and the idea of an indirect treatment\nWe declare a design based on the spillover_designer in the DesignLibrary package.1\nIn this design there are 80 groups, each of size 3. Treatment is randomly assigned—ignoring groups. Outcomes do depend on group membership, however. In particular, any individual’s outcome depends on the number of individuals in the group treated. A function (dgp) specifies how group assignments map into individual payoffs.2\n\ndgp <- function(i, Z, G) Z[i]/3 + sum(Z[G == G[i]])^2/5 + rnorm(1)\n\nspillover_design <- \n\n  declare_model(G = add_level(N = 80), \n                     j = add_level(N = 3, zeros = 0, ones = 1)) +\n  \n  declare_inquiry(direct = mean(sapply(1:240,  # just i treated v no one treated \n    function(i) { Z_i <- (1:240) == i\n                  dgp(i, Z_i, G) - dgp(i, zeros, G)}))) +\n  \n  declare_inquiry(indirect = mean(sapply(1:240, \n    function(i) { Z_i <- (1:240) == i           # all but i treated v no one treated   \n                  dgp(i, ones - Z_i, G) - dgp(i, zeros, G)}))) +\n  \n  declare_assignment(Z = complete_ra(N)) + \n  \n  declare_measurement(\n    neighbors_treated = sapply(1:N, function(i) sum(Z[-i][G[-i] == G[i]])),\n    one_neighbor  = as.numeric(neighbors_treated == 1),\n    two_neighbors = as.numeric(neighbors_treated == 2),\n    Y = sapply(1:N, function(i) dgp(i, Z, G))\n  ) +\n  \n  declare_estimator(Y ~ Z, \n                    inquiry = \"direct\", \n                    model = lm_robust, \n                    label = \"naive\") +\n  \n  declare_estimator(Y ~ Z * one_neighbor + Z * two_neighbors,\n                    term = c(\"Z\", \"two_neighbors\"),\n                    inquiry = c(\"direct\", \"indirect\"), \n                    label = \"saturated\", \n                    model = lm_robust)\n\nThe key feature of this design is that units belong in groups. When a unit gets treated, the effect of the treatment spreads out across other group members (but no further).\nIn this kind of setting, we can say you get indirectly treated when someone in your group – your “neighbor” – gets treated. In this case, we might think of the number of neighbors treated in a given assignment as your indirect treatment. For three-member groups, this definition of spillovers implies every unit has at least six potential outcomes \\(Y_{z,n}\\). For example, \\(Y_{1,2}\\) is the potential outcome for a unit who is treated in a group where both other members are treated, while \\(Y_{1,0}\\) is the potential outcome for a unit when they are the only member treated in their group.\nIf we plot the units in groups using colors for their individual treatment status and labeling them with the number of neighbors treated, one set of assignments for a sample of groups might look like this:\n\n\n\n\n\n\n\n\n\nThere are two notable departures from the design we looked at before. First, we declare an estimand for indirect effects and not just for direct effects. For direct effects we focus on the effect of being treated given no neighbors are treated (\\(E[Y_{1,0} - Y_{0,0}]\\)). For indirect effects we focus on the effect for an individual of having everyone else treated given that they themselves are not treated (\\(E[Y_{0,2} - Y_{0,0}]\\)).3 Importantly, this estimand is defined in terms of potential outcomes rather than being dependent on a particular model.\nSecond, alongside the naive estimator, we use an estimator that seeks to model the direct and indirect effects directly. By modelling indirect effects in the estimation step, we can seek to estimate the average direct treatment effect without bias and conditional on the number of neighbors treated.\nIn this context, where the spillover mechanism is well-understood and captured by the statistical model, our modelling approach does a great job of removing bias. Here we show the estimated effects of being treated when no others are treated (direct effect) and of not being treated when all others are treated (indirect effect). We see the mean estimate (dashed blue line) is right on the mean estimand (solid red line) in both cases when we model the spillovers:\n\n\n\n\n\n\n\n\nPower for all estimates now looks like this:\n\n\nWarning: It is deprecated to specify `guide = FALSE` to remove a guide. Please\nuse `guide = \"none\"` instead.\n\n\n\n\n\nWe have great power for the naive estimator – but only because it confidently delivers the wrong answer! The power from the saturated model is not so great, especially for the direct effect.\n\n\nYou can use assignment to improve power in the presence of spillovers\nOne approach to increase power for the direct effect is to tweak the assignment to control the number of groups that have one or two members treated.\nDoing this may produce tradeoffs, however, between power for direct effects and power for indirect effects.\nThe current assignment just assigns units to treatment with .5 probability, ignoring groups. We’ll replace that step with a new assignment strategy where we directly control whether groups get 0, 1, or 2 members treated. (This kind of design is sometimes called a randomized saturation design.)\nWe declare a custom assignment that uses a two-stage procedure, in which we first assign groups to treatment densities, then assign units to treatment conditional on their group’s density.\n\ntwo_stage <- function(data, density_probs){\n  density <- with(data, cluster_ra(clusters = unique(G), \n                                   conditions = c(0,1,2),\n                                   prob_each = density_probs))\n  data$Z <- with(data, block_ra(blocks = G, block_m = density))\n  return(data)\n}\n\nLet’s compare two different first-stage approaches: one where we assign more of our groups to have 0 or 1 members treated, and another in which we assign more to have 0 or 2 members treated.\n\nspillovers_assigned_1 <- \n  replace_step(\n    design = spillover_design, \n    step  =  4, \n    new_step = declare_assignment(handler = two_stage, \n                                  density_probs = c(.45,.45,.1)))\nspillovers_assigned_2 <- \n  replace_step(\n    design = spillover_design, \n    step  =  4, \n    new_step = declare_assignment(handler = two_stage, \n                                  density_probs = c(.45,.1,.45)))\n\nNow power looks like this:\n\n\n\n\n\n\n\n\nWarning: It is deprecated to specify `guide = FALSE` to remove a guide. Please\nuse `guide = \"none\"` instead.\n\n\n\n\n\nWe see a large gain in power for the estimation of direct effects when assigning more groups to have 0 or 1 member treated, and a big loss when assigning fewer groups to those densities in favor of having 2 members treated. We see an opposite tradeoff for the estimation of indirect effects. Optimal assignment depends on the quantities of interest. See Baird et al. (2017) for a great treatment of these issues.\n\n\nSome warnings\nWe got things right in part because we were right about the structure of spillovers. The estimation strategy did not assume much about the functional form of the spillovers but it did require being right about spillovers being contained within groups. If, in addition to the spillovers that we modeled, there were also spillovers between groups, then the estimation strategy would get things wrong in much the same way as the naive approach that ignored spillovers within groups got things wrong. So you need to use knowledge about the structure of spillovers. An interesting exercise is to alter the dgp function so that outcomes also depend on Z[1]—the treatment status of person number 1. How would that alter things?\nLess obvious, perhaps, things were easy here because the group sizes were homogeneous. Why does that matter? The reason is that in this example uniform assignment probabilities for the direct treatment translated into uniform assignment probabilities for the indirect treatments. But generally you cannot count on this. In this case, if groups were of heterogeneous size and treatment was randomly assigned, then units in big groups would be more likely to be exposed to treatment indirectly than units in small groups: a unit in a group of size 3 would be less likely to have two neighbors treated (prob = .25) than a unit in a group of size 4 (prob = 3/8). This can produce bias if treatment effects also depend on group size. To remove the bias you would need to take account of the fact that the indirect treatments were assigned with unequal propensities (even though the direct treatments were assigned to all units with the same probability!). This is a very similar issue to one we discussed here, and some of those approaches to addressing bias arising from heterogeneous (indirect) assignment propensities can also help in the spillover context.\nAlso not too obvious, even if direct treatments are assigned independently, assignment of indirect treatments might be clustered. For example everyone in a family gets indirectly treated together when one member gets directly treated. Given the possibly complex nature of clustering, it might make sense to use randomization inference for hypothesis testing is this setting.\nFor more on this topic, including strategies for estimating uncertainty given indirect treatment, see, for example, Aronow and Samii (2017).\n\n\n\n\n\n\n\n\n\nReferences\n\nAronow, Peter M, and Cyrus Samii. 2017. “Estimating Average Causal Effects Under General Interference, with Application to a Social Network Experiment.” The Annals of Applied Statistics 11 (4): 1912–47.\n\n\nBaird, Sarah, J Aislinn Bohren, Craig McIntosh, and Berk Özler. 2017. “Optimal Design of Experiments in the Presence of Interference.” Review of Economics and Statistics, no. 0.\n\nFootnotes\n\n\nAs with any design from the library, you can always look at the underlying code using get_design_code(spillover_designer()).↩︎\nThis dgp function differs from what we examined before by having spillovers that are not complete: direct effects differ from indirect effects.↩︎\nIn fact if you look a the design declaration we are a little more thorough and define the estimand in terms of the treatment status of all individuals and not just the in-group members.↩︎"
  },
  {
    "objectID": "blog/with-great-power-comes-great-responsibility.html",
    "href": "blog/with-great-power-comes-great-responsibility.html",
    "title": "With great power comes great responsibility",
    "section": "",
    "text": "We usually think that the bigger the study the better. And so huge studies often rightly garner great publicity. But the ability to generate more precise results also comes with a risk. If study designs are at risk of bias and readers (or publicists!) employ a statistical significance filter, then big data might not remove threats of bias and might actually make things worse."
  },
  {
    "objectID": "blog/with-great-power-comes-great-responsibility.html#bias-persists-as-n-increases",
    "href": "blog/with-great-power-comes-great-responsibility.html#bias-persists-as-n-increases",
    "title": "With great power comes great responsibility",
    "section": "Bias persists as N increases",
    "text": "Bias persists as N increases\nThe figure below shows the estimated treatment effects in each simulation for a series of sample sizes. The red line is the truth — the real average treatment effect is zero in this simulation. But the estimates are all well above zero, and the problem doesn’t go away as the sample size increases.\n\nget_simulations(diagnosis) %>%\n  ggplot(aes(x = N, y = estimate)) +\n    geom_point(alpha = 0.2) +\n    geom_hline(yintercept = 0.0, color = \"red\") +\n    geom_text(data = data.frame(N = 3000, estimate = -0.1, label = \"True ATE = 0\"),\n              aes(label = label)) +\n    coord_cartesian(ylim = c(-1, 3)) +\n    ggtitle(\"Big data doesn't necessarily remove bias\")"
  },
  {
    "objectID": "blog/with-great-power-comes-great-responsibility.html#likelihood-of-a-false-positive-increases-as-n-increases",
    "href": "blog/with-great-power-comes-great-responsibility.html#likelihood-of-a-false-positive-increases-as-n-increases",
    "title": "With great power comes great responsibility",
    "section": "Likelihood of a false positive increases as N increases",
    "text": "Likelihood of a false positive increases as N increases\nIt gets worse! As sample size increases, so does power, or the probability of getting a “statistically significant” result. The p-values will indicate that the estimate is significant even though it is badly biased away from the truth. The ATE in this simulation is zero, so power should be equal to 0.05, since that’s what we chose as our significance threshold.\n\nget_diagnosands(diagnosis) %>%\n  ggplot(aes(x = N, y = power)) +\n    geom_point(alpha = 0.5) + geom_line() +\n    theme_bw() +\n    ggtitle(\"Big data does help with statistical power---even if estimates are biased\")\n\n\n\n\nIn summary, more data is generally better, but ever bigger data won’t necessarily solve the problem of unobserved confounding. A consequence of the statistical significance filter is that we tend to hear only about findings that are “significant.” Big data gets studies through this filter because, with so many observations, statistical significance is trivially easy to achieve. To be clear, we are not saying that the study in the Lancet is biased (we can’t know whether there are unobserved confounders). But if a design (observational or experimental!) is biased, increasing the sample size can make the wrong inference a whole lot more likely.\nAs Uncle Ben might have said to Peter Parker if he’d opted for social science instead of being a superhero: with great statistical power comes great inferential responsiblity."
  },
  {
    "objectID": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html",
    "href": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html",
    "title": "How misleading are clustered SEs in designs with few clusters?",
    "section": "",
    "text": "Cluster-robust standard errors are known to behave badly with too few clusters. There is a great discussion of this issue by Berk Özler “Beware of studies with a small number of clusters” drawing on studies by Cameron, Gelbach, and Miller (2008). See also this nice post by Cyrus Samii and a recent treatment by Esarey and Menger (2018). A rule of thumb is to start worrying about sandwich estimators when the number of clusters goes below 40. But here we show that diagnosis of a canonical design suggests that some sandwich approaches fare quite well even with fewer than 10 clusters.\nWe’ll explore this question by looking at a range of cluster randomized trials. We do this by generating a base design which includes the number of clusters and the number of units per cluster as arguments and then using that design to make a sequence of designs that vary these arguments. In this design we draw separate errors at the individual and cluster levels so that outcomes are correlated within the clusters. Specifically, we assume a fairly large “intracluster correlation coefficient” (ICC) of 0.5. The design employs a range of different approaches for estimating standard errors from the estimatr package, alongside a naive approach that ignores the clusters entirely.1\nHere’s the basic design:\nWe use the redesign function to make a sequence of related designs based on the base design.2 We’re especially interested in what happens at small numbers of clusters, since that’s where the trouble lies, so we will focus the sequence on the low end.\nWe diagnose all of these in one go:\nLet’s now graph the output separately for the expected standard error, power, and coverage."
  },
  {
    "objectID": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#standard-errors",
    "href": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#standard-errors",
    "title": "How misleading are clustered SEs in designs with few clusters?",
    "section": "Standard Errors",
    "text": "Standard Errors\nOur first plot compares the true standard error (the standard deviation of the estimates themselves) to the expected standard error estimate. The blue points are the true standard errors at each sample size; they go down as the number of clusters increases. The red points are the average estimated standard errors. When the number of clusters is small, we see that the average estimate is too small: the standard error estimators are downwardly biased. This problem is extreme for the naive approach. It is still clearly an issue for “CR0” (a variant of cluster-robust standard errors that appears in R code that circulates online) and Stata’s default standard errors. We see though that it is not as severe for the CR2 standard errors (a variant that mirrors the standard HC2 robust standard errors formula). We’re using the adjustment described in Pustejovsky and Tipton (2018).\n\nget_diagnosands(diagnosis) %>%\n  gather(diagnosand, value, sd_estimate, mean_se) %>%\n  ggplot(aes(N_clusters, value, group = diagnosand, color = diagnosand)) +\n  geom_point() + geom_line() +\n  theme(legend.position = \"bottom\", strip.background = element_blank()) +\n  facet_grid(cluster_size ~ estimator, labeller = label_both)"
  },
  {
    "objectID": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#power",
    "href": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#power",
    "title": "How misleading are clustered SEs in designs with few clusters?",
    "section": "Power",
    "text": "Power\nIn our data-generating process, the true ATE is exactly zero. Statistical power is the probability of getting a significant estimate. Since the true ATE is exactly zero, this probability should be exactly 0.05, as we’re using the standard significance threshold. Just as the analysis of the standard errors showed, when the number of clusters is small, we’re anticonservative. The naive approach is again wildly off, particularly when there are large clusters. But the clustered approaches also have problems. When the number of clusters is smaller than 10, the CR0 and Stata estimators are falsely rejecting at rates exceeding 10%.\n\nget_diagnosands(diagnosis) %>%\nggplot(aes(N_clusters, power)) +\n  geom_point() + geom_line() +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\") +\n  theme(strip.background = element_blank()) +\n  facet_grid(cluster_size ~ estimator, labeller = label_both)"
  },
  {
    "objectID": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#coverage",
    "href": "blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html#coverage",
    "title": "How misleading are clustered SEs in designs with few clusters?",
    "section": "Coverage",
    "text": "Coverage\nCoverage is the rate at which the estimated confidence intervals include the true value of the parameter. We’re estimating 95% confidence intervals, so if things are working as advertised, coverage would be 95%. But since at small numbers of clusters, we’re overconfident (the standard errors are too small), the coverage rates are well below the 95% target. Again though, CR2 performs quite well.\n\nget_diagnosands(diagnosis) %>%\nggplot(aes(N_clusters, coverage)) +\n  geom_point() + geom_line() +\n  geom_hline(yintercept = 0.95, linetype = \"dashed\") +\n  theme(strip.background = element_blank()) +\n  facet_grid(cluster_size ~ estimator, labeller = label_both)"
  },
  {
    "objectID": "blog/sometimes-blocking-can-reduce-your-precision.html",
    "href": "blog/sometimes-blocking-can-reduce-your-precision.html",
    "title": "Sometimes blocking can reduce your precision",
    "section": "",
    "text": "You can often improve the precision of your randomized controlled trial with blocking: first gather similar units together into groups, then run experiments inside each little group, then average results across experiments. Block random assignment (sometimes called stratified random assignment) can be great—increasing precision with blocking is like getting extra sample size for free. Blocking works because it’s like controlling for a pre-treatment covariate in the “Data Strategy” rather than in the “Answer Strategy.” But sometimes it does more harm than good.\nThe standard experimental guidance is to block if you can in order to improve precision. (If for some reason you don’t have access to the pre-treatment covariates before the experiment is conducted, don’t fret, as the precision gains you would get from blocking on the front end can largely be made up by controlling on the back end.) In fact, even if you make blocks at random, you do as well as you would do under complete random assignment. For a textbook explanation of the benefits of blocking, see Gerber and Green (2012) (Section 3.6.1).\nBut is it possible to make things worse? Can you make a blocking that results in less precision than you would get from complete random assignment design?\nThe answer is yes. But you have to try really hard. If you organize units into groups that are internally unusually heterogeneous you can make things worse. For a formal analysis, see Imai (2008)."
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting started with DeclareDesign",
    "section": "",
    "text": "DeclareDesign is a set of tools for planning research studies\nVIDEO"
  },
  {
    "objectID": "getting-started.html#installing-declaredesign",
    "href": "getting-started.html#installing-declaredesign",
    "title": "Getting started with DeclareDesign",
    "section": "Installing DeclareDesign",
    "text": "Installing DeclareDesign\nInstall the latest version of DeclareDesign along with its helper packages fabricatr, randomizr, and estimatr in R by typing:\n\ninstall.packages(\"DeclareDesign\")"
  },
  {
    "objectID": "getting-started.html#declaring-a-two-arm-randomized-trial",
    "href": "getting-started.html#declaring-a-two-arm-randomized-trial",
    "title": "Getting started with DeclareDesign",
    "section": "Declaring a two-arm randomized trial",
    "text": "Declaring a two-arm randomized trial"
  },
  {
    "objectID": "getting-started.html#diagnosing-a-design",
    "href": "getting-started.html#diagnosing-a-design",
    "title": "Getting started with DeclareDesign",
    "section": "Diagnosing a design",
    "text": "Diagnosing a design"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About DeclareDesign",
    "section": "",
    "text": "The DeclareDesign project was founded by Graeme Blair (UCLA), Jasper Cooper (UCSD), Alexander Coppock (Yale University), and Macartan Humphreys (Columbia University and WZB)."
  },
  {
    "objectID": "about.html#project-contributors",
    "href": "about.html#project-contributors",
    "title": "About DeclareDesign",
    "section": "Project contributors",
    "text": "Project contributors\nDeclareDesign has benefited from the contributions of many researchers and coders. We recognize key contributors in addition to the principal investigators to each component:\nDeclareDesign for R: Neal Fultz\nestimatr for R: Luke Sonnet\nfabricatr for R: Aaron Rudkin\nrandomizr for Stata: John Ternovski\nDeclareDesignWizard: Clara Bicalho, Markus Konrad, and Sisi Huang\nDesignLibrary: Clara Bicalho and Lily Medina\ndeclaredesign.org: Nicholas Rivera\nWe thank contributors to earlier iterations of the project Thomas Leavitt, Tara Slough, Georgiy Syunyaev, and Anna Wilke. We also thank early beta testers Lauren Young, Erin York, and Yang-Yang Zhou."
  },
  {
    "objectID": "about.html#contributing",
    "href": "about.html#contributing",
    "title": "About DeclareDesign",
    "section": "Contributing",
    "text": "Contributing\nWe encourage you to submit bug reports and feature requests for our software as Github issues. We ask that contributors agree to our code of conduct."
  },
  {
    "objectID": "about.html#funding",
    "href": "about.html#funding",
    "title": "About DeclareDesign",
    "section": "Funding",
    "text": "Funding\nWe are grateful for major funding from the Laura and John Arnold Foundation and seed funding from EGAP – Evidence in Governance and Politics."
  },
  {
    "objectID": "fabricatr/news.html",
    "href": "fabricatr/news.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "fabricatr 0.16.0\n\nReplacement draw_likert function.\njoin function renamed to join_using to avoid confusion with other R functions and to more clearly indicate its purpose.\nBug fixes.\n\n\n\nfabricatr 0.14.0\n\nBug fixes\n\n\n\nfabricatr 0.12.0\n\nAdded potential_outcomes (creates multiple columns of potential outcomes according to a formula)\nAdded reveal_outcomes (reveals observed outcomes on the basis of potential outcomes and a treatment assignment)\nAdded draw_multivariate (interface for adding correlated draws to fabricate calls)\n\n\n\nfabricatr 0.10.0\n\nChanges for compatibility with rlang 0.4.0\nMinor bug fixes\n\n\n\nfabricatr 0.8.0\n\nChanges to prepare for R 3.6.0\n\n\n\nfabricatr 0.6.0\n\nAdded split-modify-combine functionality to modify_level via the by argument.\nChanged behavior of draw_ordered to ensure categories are data-independent and adding a strict option that replaces values with NA if values are outside all breaks.\nLabeled correlate functionality as experimental.\nMany bug fixes.\n\n\n\nfabricatr 0.4.0\n\nrecycle() helper function for expanding and recycling data\nAdded correlate() function to allow users to generate arbitrary correlated random variables.\nAdded category_labels argument to draw_categorical\nAdded draw_quantile and split_quantile functions\nMajor updates to test harness\nChanged ID label stapling behaviour in fabricate calls.\nAllow users to pass ID_label in level creation calls to allow back-door unnamed level calls.\nBugfix for constants in certain modify_level contexts.\nChanged specification of latent variables with links; users should now provide latent as an argument when using a link.\nNew syntax for using length(ID) from upper level to define N of lower level.\nWhen passing a vector to draw_categorical prob argument, package now sends message instead of warning.\nMajor additions to documentation and vignettes, including vignettes for common social sciences variables, time series, and using other creation packages with fabricatr.\nBugfix in certain cases with single-level variables autocompleting to “data” and not working.\nAdded unique_labels argument to resample_data to allow block-level statistic calculation.\n\n\n\nfabricatr 0.2.0\nFirst CRAN submission for fabricatr"
  },
  {
    "objectID": "fabricatr/articles/cross_classified.html",
    "href": "fabricatr/articles/cross_classified.html",
    "title": "Panel and Cross-classified data",
    "section": "",
    "text": "Although much of fabricatr’s is designed to generate hierarchical, nested data, we also provide functions to generate panel and cross-classified (partially nested) data. In this vignette, we offer instructions to do both."
  },
  {
    "objectID": "fabricatr/articles/cross_classified.html#panel-data-construction",
    "href": "fabricatr/articles/cross_classified.html#panel-data-construction",
    "title": "Panel and Cross-classified data",
    "section": "Panel Data Construction",
    "text": "Panel Data Construction\nLet’s begin by visualizing an example of panel data, where we have data for each of several countries in each of several years.\n\n\n\n\n\nThis data arrangement is somewhat more complex than traditional nested, hierarchical data. Each observation draws from a common pool of countries and years. In other words, the year-specific variables attached to Country A’s 1997 observation are also attached to Country B’s 1997 observation.\nThe steps for generating a panel in fabricatr are as follows:\n\nGenerate multiple non-nested data frames (Countries and Years)\nUse the cross_levels() function to join the non-nested data frames to make a panel.\nOptionally, add new variables or further levels in the resulting cross-classified data. (Observation-level variables)\n\n\nGenerating multiple, non-nested levels in fabricatr\nFirst, we need to generate country and year data. By default, fabricatr fully nests subsequent levels under the first level call. Here, we must explicitly not do this.\n\npanels <- fabricate(\n  countries = add_level(N = 150, country_fe = runif(N, 1, 10)),\n  years = add_level(N = 25, year_shock = runif(N, 1, 10), nest = FALSE),\n  ...\n)\n\nNote that this function call will not evaluate because we have specified the two non-nested data frames, but not yet told fabricatr what to do with them. The second (and any subsequent) non-nested levels should contain the nest = FALSE argument – otherwise, years would be interpreted as to be a level nested within countries. Each level will track all of its own variables, so it is possible to add as many features as you would like to the levels.\n\n\nImporting non-nested data frames\nIt is also possible to import multiple non-nested data frames; this will allow you to assemble pre-existing data sources however you would like. Recall that the first argument to a fabricate() call is the data you wish to import. We have previously seen that it is possible to import a single data frame this way, but it is also possible to import a list of data frames, staging them all for use for cross-classifying data. Data imported in this manner looks like this:\n\nexample_data <- fabricate(\n  list(data_frame_1, data_frame_2),\n  ...\n)\n\nAgain, the fabricate() call is incomplete – we have imported the data we wish to cross-classify on, but not yet learned how to merge the data. If you do not specify how to merge the data, fabricate() will simply return the most recent data frame imported or generated, unmodified.\n\n\nSpecifying a merge function\nSpecifying a merge function to create a panel is simple. You need only to tell fabricatr which levels you wish to merge, and then you will have an assembled panel and can generate new variables at the observation-level. We do this using a call to cross_levels():\n\npanels <- fabricate(\n  countries = add_level(N = 150, country_fe = runif(N, 1, 10)),\n  years = add_level(N = 25, year_shock = runif(N, 1, 10), nest = FALSE),\n  obs = cross_levels(\n    by = join_using(countries, years),\n    new_variable = country_fe + year_shock + rnorm(N, 0, 2)\n  )\n)\n\nNote that cross_levels() takes a single required argument, which is of the form by = join_using(...). This join_using command tells fabricatr how to assemble your data. In this case, we are telling it to join the countries data frame to the years data frame, resulting in country-year observations.\nJust like with regular add_level() commands, you can add new variables which have full access to the existing columns."
  },
  {
    "objectID": "fabricatr/articles/cross_classified.html#cross-classified-or-correlated-data-joins",
    "href": "fabricatr/articles/cross_classified.html#cross-classified-or-correlated-data-joins",
    "title": "Panel and Cross-classified data",
    "section": "Cross-Classified or Correlated Data Joins:",
    "text": "Cross-Classified or Correlated Data Joins:\nAnother type of data fabricatr excels at enabling is cross-classified data. In a cross-classified dataset, just like in a panel, observations draw from a combination of multiple existing data sets. Our example in this vignette will be students. Students attend a primary school and a secondary school. Unlike in a panel, not every student attends every school; and not every combination of schools has exactly one student. Student outcomes depend both on primary and secondary school education.\nLet’s begin by visualizing how our data will be laid out:\n\n\n\n\n\nThe main steps involved in generating cross-classified data are as follows:\n\nGenerate multiple non-nested data frames (Primary and Secondary Schools)\nUse the link_levels() function to join the non-nested data frames on particular variables, optionally specifying a desired correlation outcome.\nOptionally, add new variables or further levels in the resulting cross-classified data. (Student-level characteristics)\n\nWe have already learned above how to generate multiple non-nested data frames; now we example how to specify a merge function for cross-classified data.\n\nSpecifying a merge function for cross-classified data.\nOne difference between panel data and cross-classified data is that we need to specify the number of observations we will create by combining the existing levels of data. For example, there may be 20 primary schools and 15 secondary schools in a mid-sized city, but several thousand students. Specifying this is as easy as providing an N argument to the link_levels() call. At this juncture, we will assume there is no relationship between the primary school a student attends and the secondary school a student attends.\nOur model generates primary schools and secondary schools, each of which have a quality variable associated with them (ps_quality for primary schools, and ss_quality for secondary schools):\n\nschools_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(N = 15, ss_quality = runif(N, 1, 10), nest = FALSE),\n  students = link_levels(N = 1500, by = join_using(primary_schools, secondary_schools))\n)\n\nWe see that compared to generating a panel, the only change is to switch the joining function to link_levels() and adding an N argument. The result is, predictably, a data frame containing 1500 observations, each of five columns: primary_schools (ID), ps_quality, secondary_schools (ID), ss_quality, and students (ID).\n\n\nAdding additional variables\nAs shown above, it is simple to add variables to the new, cross-classified data:\n\nschools_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(N = 15, ss_quality = runif(N, 1, 10), nest = FALSE),\n  students = link_levels(\n    N = 1500, by = join_using(primary_schools, secondary_schools),\n    SAT_score = 800 + 13 * ps_quality + 26 * ss_quality +\n      rnorm(N, 0, 50)\n  )\n)\n\nHere, each student is assigned a standardized testing score, equal to a baseline, plus an additive effect from the quality of their primary school, plus a large additive effect from the quality of their secondary school, plus a stochastic component.\nA linear regression confirms that the resulting data approximately reflects the the data generating process:\n\nlm(SAT_score ~ ps_quality + ss_quality, data = schools_data)\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(>|t|)\n\n\n\n\n(Intercept)\n800\n4.12\n194\n0\n\n\nps_quality\n13\n0.57\n23\n0\n\n\nss_quality\n26\n0.44\n60\n0\n\n\n\n\n\nOther variables can be added in the students level, or indeed in either of the component levels.\n\n\nCorrelations after merging\nA variety of R packages support functionality for joining data in various ways. However, a key feature of fabricatr is that it is possible to generate correlated cross-classified data. Above, we assumed that the primary school a student attended has no relationship to the secondary school the same student attends. This assumption does not reflect actual patterns in the social world. We might, for example, reasonably assume that students assigned to better primary schools are later assigned to better secondary schools – whether due to economic geography of the area, selective admissions, or other causes. It is easy to specify a correlation between these outcomes using much the same syntax we used before:\n\ncorr_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(N = 15, ss_quality = runif(N, 1, 10), nest = FALSE),\n  students = link_levels(\n    N = 1500, by = join_using(ps_quality, ss_quality, rho = 0.5),\n    SAT_score = 800 + 13 * ps_quality + 26 * ss_quality +\n      rnorm(N, 0, 50)\n  )\n)\n\nHere, we have changed the structure of our join_using() function call. First, the variables we are joining on are ps_quality and ss_quality. fabricatr locates these variables within the data frames they come from. Second we specify a Spearman’s (rank) correlation coefficient, rho, which will induce a correlation in the resulting data based on the join_using function. In this case, we want a correlation between ps_quality and ss_quality of 0.5.\nTechnical details of the implementation of this function are contained below, but in the mean time the important thing to note is that rho can be any value from -1 to 1, and that the resulting correlation will be approximately equal to rho.\nNote: Because of the technical details of our implementation, the true correlation in the resulting data will be slightly attenuated (smaller in magnitude) from the specified rho. There is no general purpose correction to compensate for this attenuation.\nWe can check the resulting correlation here:\n\ncor(corr_data$ps_quality, corr_data$ss_quality)\n\n0.48\nIt should be noted that the specified correlation exists only within the variables on which a join was specified: other variables from either data source will not be explicitly connected except through the joined variables.\nCorrelation is only possible for cross-classified data, not panel data."
  },
  {
    "objectID": "fabricatr/articles/cross_classified.html#joining-more-than-two-levels",
    "href": "fabricatr/articles/cross_classified.html#joining-more-than-two-levels",
    "title": "Panel and Cross-classified data",
    "section": "Joining more than two levels",
    "text": "Joining more than two levels\nAll of the functions specified above work when joining more than two levels. We could extend our student example to include, for example, college quality. Nothing changes about the join syntax beyond the addition of the third or subsequent variable names:\n\nthree_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(N = 15, ss_quality = runif(N, 1, 10), nest = FALSE),\n  colleges = add_level(N = 50, c_quality = runif(N, 1, 10), nest = FALSE),\n  students = link_levels(\n    N = 1500,\n    by = join_using(\n      ps_quality, ss_quality, c_quality,\n      rho = 0.2\n    ),\n    earning_potential = 20000 + (2000 * ps_quality) +\n      (6000 * ss_quality) + (10000 * c_quality) +\n      rnorm(N, 0, 5000)\n  )\n)\n\nOne potential source for failure is specifying an invalid rho. If you specify a rho that makes the correlation between the three variables impossible to obtain, the fabricate() call will fail. A common case of this occurring is specifying a negative rho with three or more levels – in general, if A is negatively correlated with B, and B is negatively correlated with C, then A and C cannot be negatively correlated.\nInstead of specifying a rho correlation coefficient, users can specify a sigma correlation matrix to make the resulting correlations more sophisticated. Consider the following setup:\n\nsigma <- matrix(\n  c(\n    1, 0.4, 0.2,\n    0.4, 1, 0.8,\n    0.2, 0.8, 1\n  ),\n  ncol = 3, nrow = 3\n)\n\nadv_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(N = 15, ss_quality = runif(N, 1, 10), nest = FALSE),\n  colleges = add_level(N = 50, c_quality = runif(N, 1, 10), nest = FALSE),\n  students = link_levels(\n    N = 1500,\n    by = join_using(\n      ps_quality, ss_quality, c_quality,\n      sigma = sigma\n    ),\n    earning_potential = 20000 + (2000 * ps_quality) +\n      (6000 * ss_quality) + (10000 * c_quality) +\n      rnorm(N, 0, 5000)\n  )\n)\n\nsigma must be specified as a symmetric square matrix with a diagonal of all 1s and a feasible correlation structure."
  },
  {
    "objectID": "fabricatr/articles/cross_classified.html#technical-appendix-implementation-of-correlated-joins.",
    "href": "fabricatr/articles/cross_classified.html#technical-appendix-implementation-of-correlated-joins.",
    "title": "Panel and Cross-classified data",
    "section": "Technical appendix: Implementation of correlated joins.",
    "text": "Technical appendix: Implementation of correlated joins.\nThe implementation of the correlated join is done via the Gaussian copula. Mathematically, what is occurring is as follows:\n\nUser specifies a correlation structure.\nDraw multivariate standard normal data with that correlation structure.\nTransform the standard normal data for each dimension to quantiles of the standard normal cumulative distribution function.\nTake the data from the source distribution at the empirical quantile equal to the quantiles from step 3. This ensures that the data being joined on have a Spearman’s (rank) correlation coefficient as specified in the multivariate standard normal draw.\nMap the data chosen back to a row from the source distribution and join that row to the chosen row from the other source distributions, ensuring that all covariates are put in the resulting merged data."
  },
  {
    "objectID": "fabricatr/articles/getting_started.html",
    "href": "fabricatr/articles/getting_started.html",
    "title": "Getting started with fabricatr",
    "section": "",
    "text": "fabricatr is designed to help you solve two key problems:"
  },
  {
    "objectID": "fabricatr/articles/getting_started.html#creating-common-variable-types",
    "href": "fabricatr/articles/getting_started.html#creating-common-variable-types",
    "title": "Getting started with fabricatr",
    "section": "1. Creating common variable types",
    "text": "1. Creating common variable types\nfabricatr allows you to quickly create variables that mimic those you plan to collect during the course of observational or experimental work. The current version supports common variable types including assignment to treatment, count data, ordinal data (including “Likert scale” data, popular in surveys and survey experiments), categorical data (popular for modeling demographic characteristics). In addition, we support the creation of data with fixed intra-cluster correlations, so individual observations can be modelled as being part of groups or regions.\nImagine a survey experiment of voters from across social groups. With fabricatr, we can model voters as part of social groups, each of whom has characteristics like ideology and income, opinions about political issues. We can assign these voters to a treatment encouraging them to vote for a proposition, and model the results of the experiment:\n\nlibrary(fabricatr)\n\nvoters <- fabricate(\n  N = 1000,\n  group_id = rep(1:10, 100),\n  ideology = draw_normal_icc(mean = 0, N = N, clusters = group_id, ICC = 0.7),\n  ideological_label = draw_ordered(\n    x = ideology,\n    break_labels = c(\n      \"Very Conservative\", \"Conservative\",\n      \"Liberal\", \"Very Liberal\"\n    )\n  ),\n  income = exp(rlnorm(n = N, meanlog = 2.4 - (ideology * 0.1), sdlog = 0.12)),\n  Q1_immigration = draw_likert(x = ideology, min = -5, max = 5, bins = 7),\n  Q2_defence = draw_likert(x = ideology + 0.5, min = -5, max = 5, bins = 7),\n  treatment = draw_binary(0.5, N = N),\n  proposition_vote = draw_binary(latent = ideology + 1.2 * treatment, link = \"probit\")\n)\n\nLet’s look at a small fraction of the data generated this way:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_id\nideology\nideological_label\nQ1_immigration\nQ2_defence\ntreatment\nproposition_vote\n\n\n\n\n3\n-0.22\nConservative\n4\n4\n0\n0\n\n\n3\n-0.39\nConservative\n4\n4\n0\n0\n\n\n4\n-1.19\nVery Conservative\n3\n4\n0\n1\n\n\n6\n-0.77\nConservative\n3\n4\n1\n1\n\n\n1\n0.68\nLiberal\n4\n5\n1\n1\n\n\n\n\n\nModeling data like this allows common analyses in advance of conducting your experiment. This data can also be included in a pre-analysis plan to add clarity to your experimental design and contribute to improving transparency and replicability. fabricatr also allows you to import existing data and modify it easily, or to resample existing data into new, simulated populations.\nIf you’d like to read more about using fabricatr to model the variables you plan to collect in your experiment, see our guide on common social science variables, our technical manual on generating variables with fabricatr, or our tutorials on resampling data or integrating other data-generating packages into a fabricatr workflow.."
  },
  {
    "objectID": "fabricatr/articles/getting_started.html#structuring-your-data",
    "href": "fabricatr/articles/getting_started.html#structuring-your-data",
    "title": "Getting started with fabricatr",
    "section": "2. Structuring your data",
    "text": "2. Structuring your data\nfabricatr also allows you to structure your data in the shape your real experimental data will be. Although many experimental data are individual observations, like the example above, other popular data structures include panel data, multi-level (hierarchical or “nested”) data and cross-classified data. fabricatr supports both of these cases.\nOne common example in the social sciences is panel data, which is easy to create with fabricatr:\n\nlibrary(fabricatr)\n\npanel <- fabricate(\n  countries = add_level(N = 150, country_fe = runif(N, 1, 10)),\n  years = add_level(N = 25, year_shock = runif(N, 1, 10), nest = FALSE),\n  observations = cross_levels(\n    by = join_using(countries, years),\n    outcome_it = country_fe + year_shock + rnorm(N, 0, 2)\n  )\n)\n\nIf you’d like to read more about using fabricatr to structure your data, see our guides on building and importing datasets in fabricatr, generating cross-classified and panel data, or resampling data with fabricatr."
  },
  {
    "objectID": "fabricatr/articles/getting_started.html#declaredesign",
    "href": "fabricatr/articles/getting_started.html#declaredesign",
    "title": "Getting started with fabricatr",
    "section": "DeclareDesign",
    "text": "DeclareDesign\nfabricatr is one of four packages that make up the DeclareDesign software suite. Along with fabricatr, which helps you imagine your data before you collect it, we offer estimatr, fast estimators for social scientists, randomizr, an easy to use tools for common forms of random assignment and sampling, and DeclareDesign, a package for declaring and diagnosing research designs to understand and improve them.\nIn addition to our documentation in R and online, we are happy to respond to any questions you have about using our packages, or incorporate your requests for new features. You can contact us via the DeclareDesign help board."
  },
  {
    "objectID": "fabricatr/articles/advanced_features.html",
    "href": "fabricatr/articles/advanced_features.html",
    "title": "Advanced features",
    "section": "",
    "text": "More complicated level creation with variable numbers of observations\nadd_level() can be used to create more complicated patterns of nesting. For example, when creating lower level data, it is possible to use a different N for each of the values of the higher level data:\n\nvariable_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = c(2, 4), age = runif(N, 18, 70))\n  )\nvariable_data\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\n\n\n\n\n1\n1778\n1\n46\n\n\n1\n1778\n2\n50\n\n\n2\n1499\n3\n35\n\n\n2\n1499\n4\n65\n\n\n2\n1499\n5\n34\n\n\n2\n1499\n6\n23\n\n\n\n\n\nHere, each city has a different number of citizens. And the value of N used to create the age variable automatically updates as needed. The result is a dataset with 6 citizens, 2 in the first city and 4 in the second. As long as N is either a number, or a vector of the same length of the current lowest level of the data, add_level() will know what to do.\nIt is also possible to provide a function to N, enabling a random number of citizens per city:\n\nmy_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = sample(1:6, size = 2, replace = TRUE), age = runif(N, 18, 70))\n  )\nmy_data\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\n\n\n\n\n1\n1850\n1\n53\n\n\n1\n1850\n2\n55\n\n\n2\n1128\n3\n45\n\n\n2\n1128\n4\n42\n\n\n2\n1128\n5\n47\n\n\n2\n1128\n6\n69\n\n\n2\n1128\n7\n40\n\n\n2\n1128\n8\n18\n\n\n\n\n\nHere, each city is given a random number of citizens between 1 and 6. Since the sample() function returns a vector of length 2, this is like specifying 2 separate Ns as in the example above.\nIt is also possible to define N on the basis of higher level variables themselves. Consider the following example:\n\nvariable_n <- fabricate(\n  cities = add_level(N = 5, population = runif(N, 10, 200)),\n  citizens = add_level(N = round(population * 0.3))\n)\n\n\n\n\n\n\ncities\npopulation\ncitizens\n\n\n\n\n1\n133\n001\n\n\n1\n133\n002\n\n\n1\n133\n003\n\n\n1\n133\n004\n\n\n1\n133\n005\n\n\n1\n133\n006\n\n\n\n\n\nHere, the city has a defined population, and the number of citizens in our simulated data reflects a sample of 30% of that population. Although we only display the first 6 rows for brevity’s sake, the first city would have 27 rows in total.\nFinally, relying on the ID label from the higher level, it is also possible to define N on the basis of the higher level’s length:\n\nn_inherit <- fabricate(\n  cities = add_level(N = 5, population = runif(N, 10, 200)),\n  citizens = add_level(N = sample(1:10, length(cities), replace=TRUE))\n)\n\nHere, each city has a random number of citizens from 1 to 10, but we need to supply the length of the higher level’s variable (in this case, the ID label cities) to the sample function to ensure that one draw is made per city.\n\n\nCorrelated variables with custom functions\nSome users might be implemented in drawing correlated variables generated by functions not amongst the default R statistical distributions or those functions supplied by fabricatr. Any function can be made to work with correlate() provided it accepts an argument called quantile_y which will pass a series of quantiles to draw from the distribution of interest.\nAs an example, you might have some external data that represents an empirical distribution you wish to draw from. Here we use actual county level vote data from the 2016 US presidential election to generate a vote share correlated with\n\n# Load external data: Thanks to Tony McGovern, https://github.com/tonmcg\ncounty_level_2016_results <- read.csv(url(\"https://raw.githubusercontent.com/tonmcg/County_Level_Election_Results_12-16/master/2016_US_County_Level_Presidential_Results.csv\"))\n\n# Function that takes quantile_y and maps to the empirical quantiles of dataset\ncustom_quantile <- function(data, quantile_y) {\n  round(ecdf(data)(quantile_y), 2)\n}\n\n# Traditional fabricate() call:\ncounty_vote_data <- fabricate(\n  N = 500,\n  poverty_rate = runif(N, min = 0.01, max = 0.40),\n  dem_vote = correlate(custom_quantile, \n                       data = county_level_2016_results$per_dem,\n                       given = poverty_rate, \n                       rho = 0.3)\n)\n\ncor(county_vote_data$dem_vote, county_vote_data$poverty_rate, method=\"spearman\")\n\n0.34\n\n\nTidyverse integration\nBecause the functions in fabricatr take data and return data, they are cross-compatible with a tidyverse workflow. Here is an example of using magrittr’s pipe operator (%>%) and dplyr’s group_by and mutate verbs to add new data.\n\nlibrary(dplyr)\n\nmy_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = c(2, 3), age = runif(N, 18, 70))\n  ) %>%\n  group_by(cities) %>%\n  mutate(pop = n())\n\nmy_data\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\npop\n\n\n\n\n1\n1988\n1\n47\n2\n\n\n1\n1988\n2\n32\n2\n\n\n2\n1899\n3\n60\n3\n\n\n2\n1899\n4\n66\n3\n\n\n2\n1899\n5\n52\n3\n\n\n\n\n\nIt is also possible to use the pipe operator (%>%) to direct the flow of data between fabricate() calls. Remember that every fabricate() call can import existing data frames, and every call returns a single data frame.\n\nmy_data <-\n  data_frame(Y = sample(1:10, 2)) %>%\n  fabricate(lower_level = add_level(N = 3, Y2 = Y + rnorm(N)))\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\nmy_data\n\n\n\n\n\n\nY\nlower_level\nY2\n\n\n\n\n10\n1\n9.2\n\n\n10\n2\n9.8\n\n\n10\n3\n9.6\n\n\n4\n4\n4.8\n\n\n4\n5\n5.2\n\n\n4\n6\n4.3"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#binary-and-binomial-outcomes",
    "href": "fabricatr/articles/variable_generation.html#binary-and-binomial-outcomes",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Binary and binomial outcomes",
    "text": "Binary and binomial outcomes\nThe simplest possible type of data is a binary random variable (also called a bernoulli random variable). Generating a binary random variable requires only one parameter prob which specifies the probability that outcomes drawn from this variable are equal to 1. By default, draw_binary() will generate N = length(prob) draws. N can also be specified explicitly. Consider these examples:\n\ndraw_binary_ex <- fabricate(\n  N = 3, p = c(0, .5, 1),\n  binary_1 = draw_binary(prob = p),\n  binary_2 = draw_binary(N = 3, prob = 0.5)\n)\n\nIn addition to binary variables, you can make data from repeated Bernoulli trials (“binomial” data). This requires using the draw_binomial() function and specifying an argument trials, equal to the number of trials.\n\nbinomial_ex <- fabricate(\n  N = 3,\n  freethrows = draw_binomial(N = N, prob = 0.5, trials = 10)\n)\n\nSome researchers may be interested in specifying probabilities through a “link function”. This can be done in any of your data generating functions through the link argument. The default link function is “identity”, but we also support “logit”, and “probit”. These link functions transform continuous and unbounded latent data into probabilities of a positive outcome. If you are specifying a link function, you should also specify your latent variable as the latent argument.\n\nbernoulli_probit <- fabricate(\n  N = 3, x = 10 * rnorm(N),\n  binary = draw_binary(latent = x, link = \"probit\")\n)"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#ordered-outcomes",
    "href": "fabricatr/articles/variable_generation.html#ordered-outcomes",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Ordered outcomes",
    "text": "Ordered outcomes\nSome researchers may be interested in generating ordered outcomes – for example, Likert scale outcomes. You can do this with the draw_ordered() function. Ordered variables require a vector of breakpoints, supplied as the argument breaks – points at which the underlying latent variable switches from category to category. The first break should always be below the lower bound of the data, while the final break should always be above the upper bound of the data – if breaks do not cover the data, draw_ordered() will attempt to correct this by adding breaks where appropriate.\nIn the following example, each of three observations has a latent variable x which is continuous and unbounded. The variable ordered transforms x into three numeric categories: 1, 2, and 3. All values of x below -1 result in ordered 1; all values of x between -1 and 1 result in ordered 2; all values of x above 1 result in ordered 3:\n\nordered_example <- fabricate(\n  N = 3,\n  x = 5 * rnorm(N),\n  ordered = draw_ordered(x, breaks = c(-Inf, -1, 1, Inf))\n)"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#likert-variables",
    "href": "fabricatr/articles/variable_generation.html#likert-variables",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Likert variables",
    "text": "Likert variables\nLikert variables are a special case of ordered variables. Users can use draw_ordered() with properly specified breaks and break labels to generate Likert data, or use the draw_likert() function as a convenient alias:\n\nsurvey_data <- fabricate(\n  N = 100,\n  Q1 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 7),\n  Q2 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 7),\n  Q3 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 7)\n)\n\ndraw_likert() takes one compulsory argument (x, which represents the latent variable being transformed into ordered data). By default, draw_likert() provides a 7-item Likert scale with breaks at [-\\(\\infty\\), -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, \\(\\infty\\)]. Users can explicitly specify the type argument to use other types of Likert data. Supported types are 4, 5, and 7. Default breaks for 5-item Likert scales are [-\\(\\infty\\), -1.5, -0.5, 0.5, 1.5, \\(\\infty\\)]. Default breaks for 4-item Likert scales are [-\\(\\infty\\), -1, 0, 1, \\(\\infty\\)].\nOptionally, users can specify their own breaks. These will override the type command and scale type will be detected based on the length of the break argument. As above, a break argument with 8 values will produce a 7-item Likert scale, one with 6 values will produce a 5-item Likert scale, and one with 5 values will produce a 4-item Likert scale.\nLabels are automatically provided by draw_likert(). The default 7-item Likert scale uses the labels [“Strongly Disagree”, “Disagree”, “Lean Disagree”, “Don’t Know / Neutral”, “Lean Agree”, “Agree”, “Strongly Agree”].\nExamples of how users might use the function are available below:\n\nsurvey_data <- fabricate(\n  N = 100,\n  Q1 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 7),\n  Q2 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 5),\n  Q3 = draw_likert(x = rnorm(N), min = -5, max = 5, bins = 4),\n  Q4 = draw_likert(x = rnorm(N), breaks = c(-Inf, -0.8, 0, 1, 2, Inf))\n)\n\ntable(survey_data$Q2)\n\n\n\n\n\n\n2\n3\n4\n\n\n\n\n12\n71\n17\n\n\n\n\n\nThis function is a convenient, quick alias for creating likert variables with these labels. Users who want more flexibility with respect to break labels or number of breaks should use draw_ordered() and specify breaks and break labels explicitly."
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#ordered-quantile-outcomes-e.g.-quartile-decile-etc.",
    "href": "fabricatr/articles/variable_generation.html#ordered-quantile-outcomes-e.g.-quartile-decile-etc.",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Ordered quantile outcomes (e.g. quartile, decile, etc.)",
    "text": "Ordered quantile outcomes (e.g. quartile, decile, etc.)\nSome variables of interest are modeled as quantile outcomes; for example, income data in a survey might be reported or analyzed by income deciles. We provide two simple helper functions for this purpose: draw_quantile() which allows you to generate quantile outcomes without underlying data, and split_quantile() which allows you to transform underlying data into quantile outcomes. This is particularly relevant for survey data that has been made granular to protect respondent privacy.\nIn this example, we will generate income data for a population and then transform it into deciles:\n\npopulation <- fabricate(\n  N = 1000,\n  income = 20000 * rgamma(N, 1.4, 0.65),\n  income_decile = split_quantile(income, type = 10)\n)\n\nThe type paramater of the split_quantile() function specifies how many bins to split the data into. In the decile example, 10. Note that the resulting quantiles will be based on the sample data, not the parameterization of the population. It would also be possible to skip the step of characterizing the income data by directly modeling income deciles:\n\n\n\nThis parameterization of the income variable was derived by researching U.S. individual income data and using numerical optimization to derive the parameterization that best approximated a series of quantiles from that data. Many other data generation packages, including wakefield, implement automatic generation of income data. For more information about using fabricatr with other data generating packages, see our online tutorial"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#count-outcomes",
    "href": "fabricatr/articles/variable_generation.html#count-outcomes",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Count outcomes",
    "text": "Count outcomes\ndraw_count() allows you to create Poisson-distributed count outcomes. These require that the user specify the parameter mean, equal to the Poisson distribution mean (often referred to as lambda in statistical formulations of count data).\n\ncount_outcome_example = fabricate(N = 3,\n                                  x = c(0, 5, 100),\n                                  count = draw_count(mean = x))"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#categorical-data",
    "href": "fabricatr/articles/variable_generation.html#categorical-data",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Categorical data",
    "text": "Categorical data\ndraw_categorical() can generate non-ordered, categorical data. Users must provide a vector of probabilities for each category (or a matrix, if each observation should have separate probabilities).\nIf probabilities do not sum to exactly one, they will be normalized, but negative probabilities will cause an error.\nIn the first example, each unit has a different set of probabilities and the probabilities are provided as a matrix:\n\ncategorical_example <- fabricate(\n  N = 6,\n  p1 = runif(N, 0, 1),\n  p2 = runif(N, 0, 1),\n  p3 = runif(N, 0, 1),\n  cat = draw_categorical(N = N, prob = cbind(p1, p2, p3))\n)\n\nIn the second example, each unit has the same probability of getting a given category. draw_categorical() will issue a warning to remind you that it is interpreting the vector in this way.\n\nwarn_draw_cat_example <- fabricate(\n  N = 6,\n  cat = draw_categorical(N = N, prob = c(0.2, 0.4, 0.4))\n)\n\n“categorical” variables can also use link functions, for example to generate multinomial probit data."
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#binary-data-with-fixed-iccs",
    "href": "fabricatr/articles/variable_generation.html#binary-data-with-fixed-iccs",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Binary data with fixed ICCs",
    "text": "Binary data with fixed ICCs\ndraw_binary_icc() takes three required arguments: prob, a probability or vector of probabilities which determine the chance a given observation will be a 1; clusters, a map of units to clusters (required to generate the correlation structure); and ICC, the fixed intra-cluster correlation (from 0 to 1). Users may optionally specify N; if it is not specified, draw_binary_icc() will determine it based on the length of the clusters vector.\nConsider the following example, which models whether individuals smoke:\n\n\n\n\n# 100 individual population, 20 each in each of 5 clusters\nclusters = rep(1:5, 20)\n\n# Individuals have a 20% chance of smoking, but clusters are highly correlated\n# in their tendency to smoke\nsmoker = draw_binary_icc(prob = 0.2, clusters = clusters, ICC = 0.5)\n\n# Observe distribution of smokers and non-smokers\ntable(smoker)\n\n\n\n\n\n\n0\n1\n\n\n\n\n76\n24\n\n\n\n\n\nWe see that approximately 20% of the population smokes, in line with our specification, but what patterns of heterogeneity do we see by cluster?\n\ntable(clusters, smoker)\n\n\n\n\n\n\n0\n1\n\n\n\n\n16\n4\n\n\n19\n1\n\n\n18\n2\n\n\n4\n16\n\n\n19\n1\n\n\n\n\n\nHere we learn that of our 5 clusters, 4 are overwhelmingly non-smokers, while a fifth is composed of 80% smokers.\nWe can also specify separate mean for each cluster; but it is worth noting that the higher the ICC, the more the cluster mean will depart from the nominal cluster mean.\nIf you do not specify a vector of probabilities or a correlation coefficient, the default values are probability 0.5 for each cluster and ICC of 0.5. If you do not specify cluster IDs, the function will return an error."
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#normal-data-with-fixed-iccs",
    "href": "fabricatr/articles/variable_generation.html#normal-data-with-fixed-iccs",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Normal data with fixed ICCs",
    "text": "Normal data with fixed ICCs\ndraw_normal_icc() takes four required arguments: mean, a mean or vector of means, one for each cluster; clusters, a map of units to clusters (required to generate the correlation structure); ICC, the fixed intra-cluster correlation coefficient; and sd, a standard deviation or vector of standard deviations, one for each cluster. Users can optionally specify N, a number of units, but if it is not supplied draw_normal_icc() will determine it based on the length of the clusters vector.\nIf sd is not supplied, each cluster will be assumed to have a within-cluster standard deviation of 1 and the sd_between will be implied by this sd and the ICC parameter. If mean is not supplied, each cluster will be assumed to be mean zero.\nHere, we model student academic performance by cluster:\n\n\n\n\n# 100 students, 10 each in 10 clusters\nclusters <- rep(1:5, 20)\n\nnumeric_grade <- draw_normal_icc(mean = 80, clusters = clusters, ICC = 0.5, sd = 15)\n\nletter_grade <- draw_ordered(\n  x = numeric_grade,\n  breaks = c(-Inf, 60, 70, 80, 90, Inf),\n  break_labels = c(\"F\", \"D\", \"C\", \"B\", \"A\")\n)\n\nmean(numeric_grade)\n\n84.12\nThe mean grade matches the population mean. Now let’s look at the relationship between cluster and letter grade to observe the cluster pattern:\n\ntable(letter_grade, clusters)\n\n\n\n\n\n\nF\nD\nC\nB\nA\n\n\n\n\n0\n0\n3\n2\n15\n\n\n0\n3\n5\n9\n3\n\n\n5\n3\n8\n2\n2\n\n\n4\n7\n2\n5\n2\n\n\n0\n0\n0\n2\n18\n\n\n\n\n\nIt is obvious upon inspection that two of the clusters contain academic high-performers, while two of the clusters have a substantial failure rate. Although each cluster has the same mean in expectation, the induced intra-cluster correlation forces some clusters higher and others lower.\nAlternatively, users can specify ICC and total_sd. The resulting variable will be rescaled to have a standard deviation exactly equal to total_sd."
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#correlated-data",
    "href": "fabricatr/articles/variable_generation.html#correlated-data",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Correlated Data",
    "text": "Correlated Data\nWhen generating correlated data using correlate(), the following approach is used, where X is the source variable, F is the empirical distribution of X, G is the target distribution, and Y is the realized variable drawn from that distribution:\n\nCalculate the quantiles of the observed X in the empirical distribution X\nDraw these quantiles from a standard normal distribution\nGenerate a standard normal version of Y based on the specified relationship.\nMap the standard normal Y into the quantiles of the standard normal distribution\nDraw from the target distribution at those quantiles.\n\nBecause all transformations are affine, the rank order correlation induced in the standard normal stage is preserved in the target distribution. Mathematically:\n\\[\n\\begin{aligned}\n  X_{quan} &= F^{-1}(X) \\\\\n  X_{std} &= \\Phi(X_{quan}) \\\\\n  Y_{std} &\\sim N(\\rho \\times X_{std}, (1 - \\rho^2)) \\\\\n  Y_{quan} &= \\Phi^{-1}(Y_{std}) \\\\\n  Y &= G(Y_{quan})\n\\end{aligned}\n\\]\nOne thing that may be counterintuitive about this approach is that the correlation is based on the sample characteristics of X – the empirical data X observed without reference to its distribution of origin – but the population characteristics of Y. This choice was chosen because it minimizes the amount of information required of users and maximizes the flexibility of source variables, although it may result in some imprecision on a given draw owing to the finite sample size of X (or chance deviation of X from the desired distribution during sampling)."
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#binary-icc",
    "href": "fabricatr/articles/variable_generation.html#binary-icc",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Binary ICC",
    "text": "Binary ICC\nWhen generating binary data with a fixed ICC, we use this formula, where \\(i\\) is a cluster and \\(j\\) is a unit in a cluster:\n\\[\n\\begin{aligned}\n  z_i &\\sim \\text{Bern}(p_i) \\\\\n  u_{ij} &\\sim \\text{Bern}(\\sqrt{\\rho}) \\\\\n  x_{ij} &=\n  \\begin{cases}\n    x_{ij} \\sim \\text{Bern}(p_i) & \\quad \\text{if } u_{ij} = 1 \\\\\n    z_i & \\quad \\text{if } u_{ij} = 0\n  \\end{cases}\n\\end{aligned}\n\\]\nIn expectation, this guarantees an intra-cluster correlation of \\(\\rho\\) and a cluster proportion of \\(p_i\\). This approach is derived from Hossain, Akhtar and Chakraborti, Hrishikesh. “ICCBin: Facilitates Clustered Binary Data Generation, and Estimation of Intracluster Correlation Coefficient (ICC) for Binary Data”, available on CRAN or GitHub"
  },
  {
    "objectID": "fabricatr/articles/variable_generation.html#normal-icc",
    "href": "fabricatr/articles/variable_generation.html#normal-icc",
    "title": "Generating discrete random variables with fabricatr",
    "section": "Normal ICC",
    "text": "Normal ICC\nWhen generating normal data with a fixed ICC, we follow this formula, again with \\(i\\) as a cluster and \\(j\\) as a unit in the cluster:\n\\[\n\\begin{aligned}\n  \\sigma^2_{\\alpha i} &= \\frac{(\\rho * \\sigma^2_{\\epsilon i})}{(1 - \\rho)} \\\\\n  \\alpha_i &\\sim \\mathcal{N}(0, \\sigma^2_{\\alpha i}) \\\\\n  \\mu_{ij} &\\sim \\mathcal{N}(\\mu_i, \\sigma^2_{\\epsilon i}) \\\\\n  x_{ij} &= \\mu_{ij} + \\alpha_i\n\\end{aligned}\n\\]\nIn expectation, this approach guarantees an intra-cluster correlation of \\(\\rho\\), a cluster mean of \\(\\mu_{i}\\), and a cluster-level variance in error terms of \\(\\sigma^2_{\\epsilon i}\\). This approach is specified on StatsExchange."
  },
  {
    "objectID": "fabricatr/articles/resampling.html",
    "href": "fabricatr/articles/resampling.html",
    "title": "Resampling data with fabricatr",
    "section": "",
    "text": "One way to imagine new data is to take data you already have and resample it, ensuring that existing inter-correlations between variables are preserved, while generating new data or expanding the size of the dataset. fabricatr offers several options to simulate resampling.\n\nBootstrapping\nThe simplest option in fabricatr is to “bootstrap” data. Taking data with N observations, the “bootstrap” resamples these observations with replacement and generates N new observations. Existing observations may be used zero times, once, or more than once. Bootstrapping is very simple with the resample_data() function:\n\nsurvey_data <- fabricate(N = 10, voted_republican = draw_binary(prob = 0.5, N = N))\n\nsurvey_data_new <- resample_data(survey_data)\nhead(survey_data_new)\n\n\n\n\n\n\nID\nvoted_republican\n\n\n\n\n02\n0\n\n\n07\n0\n\n\n01\n1\n\n\n03\n1\n\n\n10\n0\n\n\n02\n0\n\n\n\n\n\nIt is also possible to resample fewer or greater number of observations from your existing data. We can do this by specifying the argument N to resample_data(). Consider expanding a small dataset to allow for better imagination of larger data to be collected later.\n\nlarge_survey_data <- resample_data(survey_data, N = 100)\nnrow(large_survey_data)\n\n100\n\n\nResampling hierarchical data\nOne of the most powerful features of all of fabricatr is the ability to resample from hierarchical data at any or all levels. Doing so requires specifying which levels you will want to resample with the ID_labels argument. Unless otherwise specified, all units from levels below the resampled level will be kept. In our earlier country-province-citizen dataset, resampling countries will lead to all provinces and citizens of the selected country being carried forward. You can resample at multiple levels simultaneously.\nConsider this example, which takes a dataset containing 2 cities of 3 citizens, and resamples it into a dataset of 3 cities, each containing 5 citizens.\n\nmy_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = 3, age = runif(N, 18, 70))\n  )\n\nmy_data_2 <- resample_data(my_data, N = c(3, 5), ID_labels = c(\"cities\", \"citizens\"))\nhead(my_data_2)\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\n\n\n\n\n1\n1769\n3\n23\n\n\n1\n1769\n2\n68\n\n\n1\n1769\n1\n51\n\n\n1\n1769\n1\n51\n\n\n1\n1769\n1\n51\n\n\n2\n1205\n5\n64\n\n\n\n\n\nresample_data() will first select the cities to be resampled. Then, for each city, it will continue by selecting the citizens to be resampled. If a higher level unit is used more than once (for example, the same city being chosen twice), and a lower level is subsequently resampled, the choices of which units to keep for the lower level will differ for each copy of the higher level. In this example, if city 1 is chosen twice, then the sets of five citizens chosen for each copy of the city 1 will differ.\nYou can also specify the levels you wish to resample from using the name arguents to the N parameter, like in this example which does exactly the same thing as the previous example, but specifies the level names in a different way:\n\nmy_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = 3, age = runif(N, 18, 70))\n  )\n\nmy_data_2 <- resample_data(my_data, N = c(cities = 3, citizens = 5))\nhead(my_data_2)\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\n\n\n\n\n1\n1125\n3\n69\n\n\n1\n1125\n1\n49\n\n\n1\n1125\n3\n69\n\n\n1\n1125\n2\n35\n\n\n1\n1125\n2\n35\n\n\n2\n1075\n5\n62\n\n\n\n\n\n\n\nUnique per-sample labels\nSome researchers may be interested in preserving unique labels for each sample draw at a given level. An example of this may be to sample cities, as above, but then want to run city-level statistics; if the same city is sampled twice, then the city-level statistic will incorrectly combine both samples. This can be solved with unique_labels = TRUE, which will create a new column for each sampled level, called <level name>_unique, which will be unique for each sample. Consider the following code:\n\nmy_data_unique <- resample_data(my_data, N = c(cities = 3), unique_labels = TRUE)\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\ncities_unique\n\n\n\n\n2\n1075\n4\n60\n2_1\n\n\n2\n1075\n5\n62\n2_1\n\n\n2\n1075\n6\n26\n2_1\n\n\n2\n1075\n4\n60\n2_2\n\n\n2\n1075\n5\n62\n2_2\n\n\n2\n1075\n6\n26\n2_2\n\n\n2\n1075\n4\n60\n2_3\n\n\n2\n1075\n5\n62\n2_3\n\n\n2\n1075\n6\n26\n2_3\n\n\n\n\n\n\n\n“Passthrough” Resampling\nIn some cases it may make sense to resample each unit at a given level. For example, there may be value in resampling 1 citizen in each and every city represented in the data set. fabricatr allows the user to specify ALL for the N argument to a given level to accomplish this:\n\nmy_data <-\n  fabricate(\n    cities = add_level(N = 2, elevation = runif(n = N, min = 1000, max = 2000)),\n    citizens = add_level(N = 3, age = runif(N, 18, 70))\n  )\n\nmy_data_3 <- resample_data(my_data, N = c(ALL, 1), ID_labels = c(\"cities\", \"citizens\"))\nhead(my_data_3)\n\n\n\n\n\n\ncities\nelevation\ncitizens\nage\n\n\n\n\n1\n1980\n2\n25\n\n\n2\n1072\n5\n46"
  },
  {
    "objectID": "fabricatr/articles/other_packages.html",
    "href": "fabricatr/articles/other_packages.html",
    "title": "Using other data generating packages with fabricatr",
    "section": "",
    "text": "In general, fabricatr is going to be compatible with any existing packages you use to generate synthetic data in one of two ways: either using those packages to create variables within a fabricate call, or using those packages to make complete data frames which are then imported into a fabricate. Below we provide examples for some of the most popular packages that serve this purpose."
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#wakefield-simulating-common-demographic-features",
    "href": "fabricatr/articles/other_packages.html#wakefield-simulating-common-demographic-features",
    "title": "Using other data generating packages with fabricatr",
    "section": "wakefield: simulating common demographic features",
    "text": "wakefield: simulating common demographic features\nwakefield (by Tyler Rinker) is a popular R package for creating synthetic data. wakefield’s strength is that it can quickly generate common variables, especially for human demographic features. wakefield can easily be integrated into a fabricatr workflow in one of two ways: using wakefield to create individual variables within a fabricate call, or using wakefield to make a data frame and importing that data frame into a fabricate call.\nIn this example, we create a data-set of participants in a survey experiment, using wakefield to generate the demographic variables\n\nlibrary(wakefield)\n\nsurvey_experiment_df <- fabricate(\n  N = 50,\n  treatment = draw_binary(prob = 0.5, N = N),\n  age = age(n = N),\n  race = race(n = N),\n  sex = sex(n = N),\n)\n\nResearchers interested in learning about wakefield’s available functionality, parameterizations, and default probability can read wakefield’s user guide on GitHub.\nIn addition to creating variables within a fabricate call, users can import completed wakefield data frames into a fabricate call:\n\nsurvey_experiment_df <- r_data_frame(\n  n = 50,\n  age,\n  race,\n  sex)\n\nfabricatr_df <- fabricate(\n  data = survey_experiment_df,\n  treatment = draw_binary(prob = 0.5, N = N)\n)"
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#randomnames-plausible-names-for-human-subjects",
    "href": "fabricatr/articles/other_packages.html#randomnames-plausible-names-for-human-subjects",
    "title": "Using other data generating packages with fabricatr",
    "section": "randomNames: Plausible names for human subjects",
    "text": "randomNames: Plausible names for human subjects\nrandomNames (by Damian Betebenner) is a package that does one thing well: generate random names for human subjects (including with specified genders and ethnicities). The primary use case would be to use this as part of generating a variable within a fabricate call. In the below example, we use fabricate to generate some other demographic data, and then randomNames to generate matching names.\n\nlibrary(randomNames)\n\nexperiment_data <- fabricate(\n  N = 50,\n  treatment = draw_binary(prob = 0.5, N = N),\n  is_female = draw_binary(prob = 0.5, N = N),\n  patient_name = randomNames(N, gender=is_female)\n)\n\nNote that we make use of the existing is_female variable from the fabricate call to ensure randomNames generates gender-typical names."
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#modeling-causality-with-dags-and-simcausal",
    "href": "fabricatr/articles/other_packages.html#modeling-causality-with-dags-and-simcausal",
    "title": "Using other data generating packages with fabricatr",
    "section": "Modeling causality with DAGs and simcausal",
    "text": "Modeling causality with DAGs and simcausal\nUsers who are familiar with the DAGS (directed acyclic graphs) model of causal inference may have interest in using the simcausal package, which allows users to specify a DAGS model and then sample from it. Integrating this package with fabricatr is likely to involve using simcausal first to specify a model, simulating data from the model, and then importing data into a fabricate call for further user with fabricatr.\nConsider this example, common in the literature on educational attainment and school outcomes, where students come from families that have a wealth parameter, assignment to schools is based partially on wealth, and test outcomes (testoutcome) is based on both school quality and wealth.\n\nlibrary(\"simcausal\")\n\n# Define DAG\nD <- DAG.empty() + \n  node(\"wealth\", distr = \"rnorm\",\n       mean = 30000,\n       sd = 10000) +\n  node(\"schoolquality\", distr = \"runif\",\n       min = 0 + (5 * (wealth > 50000)),\n       max = 10) +\n  node(\"testoutcome\", distr = \"runif\",\n       min = 0 + 0.0001 * wealth + 0.25 * schoolquality,\n       max = 10)\n\n# Freeze DAG object\nset_dag <- set.DAG(D)\n\n# Draw data from DAG\ndf <- sim(set_dag, n = 100)\n\n# Pass into fabricate call and make new variables as necessary\nfabricate(df,\n          passed_test = testoutcome > 6,\n          eligible_for_snap = wealth < 25000)"
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#survival-and-duration-models-with-simsurv",
    "href": "fabricatr/articles/other_packages.html#survival-and-duration-models-with-simsurv",
    "title": "Using other data generating packages with fabricatr",
    "section": "Survival and duration models with simsurv",
    "text": "Survival and duration models with simsurv\nsimsurv is a package dedicated to generating panel survival data. The most likely way you might integrate simsurv with fabricatr would be to use fabricatr to generating covariates which can then be imported into simsurv to model in a hazard or duration context.\nHere, our example will be a clinical trial of a cancer drug. Participants have the expected biographical data: age, gender, whether the patient smokes, the disease stage, assignment to treatment, and a KPS score (commonly used to evaluate overall patient health).\nSurvival data creates a ragged longitudinal survey; some patients will die during the course of the trial, removing them as observations. Others will continue alive until the end of the trial. We specify a “hazard function”, which tells simsurv how the course of patient survival will change over time. Covariates with positive betas increase risk of death, while covariates with negative betas decrease risk of death. We will track patients for 5 years after treatment.\n\nlibrary(simsurv)\n\n# Simulate patient data in a clinical trial\nparticipant_data <- fabricate(\n  N = 100,\n  age = runif(N, min = 18, max = 85),\n  is_female = draw_binary(prob = 0.5, N = N),\n  is_smoker = draw_binary(prob = 0.2 + 0.2 * (age > 50), N = N),\n  disease_stage = round(runif(N, min = 1 + 0.5 * (age > 65), max = 4)),\n  treatment = draw_binary(prob = 0.5, N = N),\n  kps = runif(N, min = 40, max = 100)\n)\n\n# Simulate data in the survival context\nsurvival_data <- simsurv(\n  lambdas = 0.1, gammas = 0.5,\n  x = participant_data, \n  betas = c(is_female = -0.2, is_smoker = 1.2,\n            treatment = -0.4, kps = -0.005,\n            disease_stage = 0.2),\n  maxt = 5)\n\nThe generated data from the survival_data object can then be re-imported into the participant_data using any data merging tools, including through a fabricate call, and then used for subsequent analyses (e.g. using the survival package)."
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#time-series-using-forecast",
    "href": "fabricatr/articles/other_packages.html#time-series-using-forecast",
    "title": "Using other data generating packages with fabricatr",
    "section": "Time series using forecast",
    "text": "Time series using forecast\nforecast, by Rob Hyndman, is a package commonly used to analyze time series data which also has functionality capable of generating simulated time series data. forecast can use the Arima and simulate functions to create pre-specified ARIMA models, including seasonal time trends.\nBelow, we provide an example of using forecast to generate an ARIMA time series, reshape the data, and import it into fabricatr to create new variables of interest.\n\nlibrary(forecast)\n\narima_model <- simulate(\n  Arima(ts(rnorm(100), frequency = 4),\n        order = c(1, 0, 1))\n  \nfabricate(data.frame(arima_model), \n          year = rep(1:25, each=4),\n          quarter = rep(1:4, 25))\n\nHere, ts converts a series of data into a time series, with frequency specifying the number of observations per unit of time (in this case, for example, quarters in a year). Arima ingests this data and fits an ARIMA model with the specified parameters. simulate draws new data from the fit time series, producing a vector of interest. We then import the data into a fabricate call (converting it to a data frame) and add new columns of interest."
  },
  {
    "objectID": "fabricatr/articles/other_packages.html#other-data-simulation-tools",
    "href": "fabricatr/articles/other_packages.html#other-data-simulation-tools",
    "title": "Using other data generating packages with fabricatr",
    "section": "Other data simulation tools",
    "text": "Other data simulation tools\nThe R ecosystem has many other data simulation tools, and all can be used to complement or supplement fabricatr in your workflow. Some of the packages that we have noticed but not covered here include:\n\ngems by Luisa Salazar Vizcaya\nsimFrame by Andreas Alfons\nsimPop by Matthias Templ\nsimstudy by Keith Goldfeld\nsynthPop by Beata Nowok\nSimCorrMix by Allison Cynthia Fialkowski\n\nIf you’d like to see a tutorial on using these packages or any others with fabricatr, please Contact Us so we can help you"
  },
  {
    "objectID": "fabricatr/articles/common_social.html",
    "href": "fabricatr/articles/common_social.html",
    "title": "Common Social Science variables",
    "section": "",
    "text": "fabricatr makes it easy to generate common social science variables. While our other online tutorials focus on exploring the full extent of fabricatr’s capabilities, this tutorial focuses on simple plain-English introductions to common variable types used in social science research, along with an introduction to the statistical terminology associated with them. Examples are drawn from pre-analysis plans filed with Evidence in Governance and Politics (EGAP).\nIf you already feel comfortable understanding these concepts and would prefer a technical manual for our variable creation functions, please consult our Generating Variables tutorial."
  },
  {
    "objectID": "fabricatr/articles/common_social.html#binary-outcomes-e.g.-turnout",
    "href": "fabricatr/articles/common_social.html#binary-outcomes-e.g.-turnout",
    "title": "Common Social Science variables",
    "section": "Binary outcomes (e.g. turnout)",
    "text": "Binary outcomes (e.g. turnout)\nThe simplest possible outcome of interest is a binary outcome: one that can be either true or false. An example of this sort of outcome in a social science research context is whether or not a subject performs an action: Does a person seek medical treatment? Does a person turn out to vote? Does a person write a letter to their congressional representative? Is an infrastructure project completed on time? These sorts of questions are typically modelled as binary outcomes. The “yes” or “no” answer to your question of interest is represented as 1 (“yes”) or 0 (“no”) numerically.\nIn fabricatr, binary data can easily be modeled with the draw_binary() function:\n\nvoter_turnout = draw_binary(prob = 0.4, N = 100)\n\ntable(voter_turnout)\n\n\n\n\n\n\nvoter_turnout\nFreq\n\n\n\n\n0\n58\n\n\n1\n42\n\n\n\n\n\ndraw_binary requires that you supply two pieces of data: prob, which specifies either a single probability or a vector of probabilities (one for each unit), the probability of getting a “1” in your simulated data. For instance, here we are modeling a turnout rate of 40%. Second, it requires N, which specifies how many observations to create.\nIt is also possible to specify the probability stochastically. Imagine if you wish to model a population where individuals under age 40 have a low turnout rate, while individuals above age 40 have a high turnout rate. This is very simple with fabricatr:\n\npopulation <- fabricate(\n  N = 100,\n  age = round(runif(N, 18, 85)),\n  turnout = draw_binary(prob = ifelse(age < 40, 0.4, 0.7), N=N)\n)\n\nThis example introduces you to a few new functions. First, we can wrap multiple variable creation commands in a fabricate call. This will ensure the result is a data frame, and that each variable creation command has access to the previous variables. Second, you see that we can model age using R’s built-in runif function. If you would like more information about modeling statistical distributions in R, see the ?Distributions manual page. Third, you see that we model turnout probability statistically; if the user has an age below 40, they receive turnout probability 0.4. If not, they receive turnout probability 0.7.\nAs noted in the introduction for this tutorial, the target audience for this tutorial is someone interested in common social science outcome variables, but without a strong background in thinking about modelling these variables. If you feel comfortable modelling but need to learn how to specify the variables in fabricatr, please see our tutorial on variable generation with fabricatr. If you need more information about modeling the structure of data or implementing multi-level models, panel data, or cross-classified data with fabricatr, then please see our tutorial on building and importing data."
  },
  {
    "objectID": "fabricatr/articles/common_social.html#ordered-data-e.g.-satisfaction",
    "href": "fabricatr/articles/common_social.html#ordered-data-e.g.-satisfaction",
    "title": "Common Social Science variables",
    "section": "Ordered data (e.g. satisfaction)",
    "text": "Ordered data (e.g. satisfaction)\nThe type of data generated for many survey questions is “ordered”. Ordered data includes the “Likert scale”, and is used when respondents to a survey report an outcome which has a logical ordering from lowest to highest but is not necessarily measured in numerically comparable terms. Consider a basic question like “Do you approve of your mayor’s job performance?”. There are many ways you could measure a respondent’s answer to this question, but one of the most common is by offering the respondent the choice to “Strongly Disapprove”, “Disapprove”, feel “Neutral”, “Approve”, or “Strongly Approve”. This five point scale is ordered data.\nWhen simulating ordered data, we typically think of the problem differently, as a two-step process. The first step is to assign a respondent a score over some range, and the second step is to translate that score into the categories of the ordered variable. We call the first step a “latent variable”. In the real survey, we never see the latent variable, only the ordered data outcome. But we can rely on the latent variable to help shape our simulated data.\nWe generate a simulated latent variable and then translate it into a simulated ordered variable, like so:\n\n\n\n\n\nIn the above graph, most respondents (the “density” represented by the height of the curve) are neutral about the mayor, and relatively few hold extreme opinions. We generated a “normal” latent variable for our respondents and then translate this to the ordered outcome. The simplest normal variable is the “standard normal”, a random variable whose mean (center) is 0, and whose standard deviation (spread) is 1. So, although it is not shown in the graph above, the dashed lines which divide the ordered outcomes are located at -1.5, -0.5, 0.5, and 1.5.\nOf course it would also be possible to affect the center and spread of this question:\n\n\n\n\n\nAlthough thinking about ordered data in this latent context may seem strange at first, actually generating an ordered data outcome in fabricatr is quite easy:\n\nmayor_approval <- draw_ordered(x = rnorm(n = 100),\n                               breaks = c(-1.5, -0.5, 0.5, 1.5),\n                               break_labels = c(\"Strongly Disagree\", \"Disagree\",\n                                                \"Neutral\", \"Agree\",\n                                                \"Strongly Agree\"))\n\ntable(mayor_approval)\n\n\n\n\n\n\nmayor_approval\nFreq\n\n\n\n\nStrongly Disagree\n7\n\n\nDisagree\n20\n\n\nNeutral\n42\n\n\nAgree\n22\n\n\nStrongly Agree\n9\n\n\n\n\n\nLet’s look at this draw_ordered example. draw_ordered requires three pieces of information from us: x (the latent variable), breaks (the places in the latent variable which divide the categories in the ordered outcome), and break_labels (which label the resulting ordered outcome).\nFor x, we use the rnorm command to generate 100 standard normal draws representing our respondents. For breaks and break_labels, we mark and label the breaks as we did above.\nThe appeal of fabricatr is that we can create relationships between variables, so let’s imagine a slightly more complex data where in general the mayor is well liked by members of her political party, but not by members of the opposite political party. To do this, we’ll need to assign respondents to a political party (we’ll mark the mayor’s political party with “1” and the opposition political party with “0”) and then generate our latent variable.\nFirst, let’s visualize the latent variable:\n\n\n\n\n\nHere, colors indicate the two parties. We see that some members of the red party do disagree with the mayor, but the overwhelming majority do not, and vice versa for the blue party. Now, let’s put our visualization into action:\n\nrespondent_data <- fabricate(\n  N = 100,\n  mayor_copartisan = draw_binary(prob = 0.6, N),\n  mayor_approval = draw_ordered(\n    x = rnorm(N, mean = -1 + 2 * mayor_copartisan),\n    breaks = c(-1.5, -0.5, 0.5, 1.5),\n    break_labels = c(\"Strongly Disagree\", \"Disagree\", \"Neutral\",\n                     \"Agree\", \"Strongly Agree\")\n  )\n)\n\ntable(respondent_data$mayor_approval, respondent_data$mayor_copartisan)\n\n\n\n\n\n\n\n0\n1\n\n\n\n\nStrongly Disagree\n17\n0\n\n\nDisagree\n14\n4\n\n\nNeutral\n9\n12\n\n\nAgree\n1\n18\n\n\nStrongly Agree\n1\n24\n\n\n\n\n\nThis example is a little more complex. You can see the use of the fabricate wrapper function, which is described in more detail in our Building and Importing Data guide. Additionally, the latent variable x is more complex. Let’s consider the formula for how this variable is specified. We know that the latent variable space from -1.5 to -0.5 indicates “Disagree”. For respondents who have mayor_copartisan equal to 0 (they are not in the mayor’s political party), their preference will be a standard normal draw centered at \\(-1 + (2 * 0) = -1\\). For respondents who have mayor_copartisan equal to 1 (they are in the mayor’s political party), their preference will be a standard normal draw centered at \\(-1 + (2 * 1) = 1\\) – “Agree”.\nIt is easy to play with the location of breaks, labels for breaks, and format of the underlying latent variable. Here’s an example where the latent variable is “uniform” – there is an equal likelihood of choosing each of the options:\n\nmayor_approval <- draw_ordered(x = runif(n = 100, min = -2.5, max = 2.5),\n                               breaks = c(-1.5, -0.5, 0.5, 1.5),\n                               break_labels = c(\"Strongly Disagree\", \"Disagree\",\n                                                \"Neutral\", \"Agree\",\n                                                \"Strongly Agree\"))\n\nUsers who are new to the R programmming language and want to know more about other statistical distributions beyond the norm and unif distributions used here, should run the command ?Distributions in the R console."
  },
  {
    "objectID": "fabricatr/articles/common_social.html#likert-data",
    "href": "fabricatr/articles/common_social.html#likert-data",
    "title": "Common Social Science variables",
    "section": "Likert Data",
    "text": "Likert Data\nMany survey responses that focus on labeling agreement, support, or quality evaluation, including the example above, are called “Likert” data after the psychologist Rensis Likert. These scales are typically 4, 5, or 7 point scales of a measure. fabricatr includes a simple shortcut to make Likert variables without needing to fill out the breaks and break_labels each time.\nBy using draw_likert, users only need to specify the x latent variable – assumed to be distributed with breaks spaced 1 unit apart and with the data centered on 0 – and the type of Likert they would like (the number of categories). In this example, we examine the same data above, but with a 4-category Likert scale where the options are “Strongly Agree”, “Agree”, “Disagree”, and “Strongly Disagree”, with no neutral category.\n\ndraw_likert(runif(n = 100), min = 0, max = 1, bins = 7)\n\ntable(mayor_approval)\n\n\n\n\n\n\nmayor_approval\nFreq\n\n\n\n\nStrongly Disagree\n16\n\n\nDisagree\n25\n\n\nNeutral\n20\n\n\nAgree\n26\n\n\nStrongly Agree\n13"
  },
  {
    "objectID": "fabricatr/articles/common_social.html#categorical-data-e.g.-demographic-measures",
    "href": "fabricatr/articles/common_social.html#categorical-data-e.g.-demographic-measures",
    "title": "Common Social Science variables",
    "section": "Categorical data (e.g. demographic measures)",
    "text": "Categorical data (e.g. demographic measures)\nSurveys often collect demographic information from respondents, including age, gender, and ethnicity. By this point in our guide, you have begun to see how you might generate a continuous numerical variable like age, or how you traditional binary measures of gender might be specified. But some variables, like inclusive measures of gender, or ethnicity, (or hair color, eye color, city of residence, or many other possible variables of interest) are not “ordered” in any sense.\nThese data are often called “categorical” data – a given person has a probability to belong to each of the possible categories.\nImagine that researchers are conducting a survey in Kenya. They wish to capture the country’s four largest ethnic groups: Kikuyu, Luhya, Kalenjin, Luo, and are also interested in capturing the smaller Maasai group. Other respondents are identified as “Other”. When preparing their research, the researchers must simulate the ethnicity of their expected respondents, so they first gather the proportions of each group,\n\n\n  Kikuyu    Luhya Kalenjin      Luo   Maasai    Other \n   0.172    0.138    0.129    0.105    0.022    0.435 \n\n\nfabricatr makes it easy to generate data based on specifications like these using draw_categorical:\n\nrespondent_ethnicity <- draw_categorical(\n  prob = c(0.172, 0.138, 0.129, 0.105, 0.022, 0.435),\n  category_labels = c(\"Kikuyu\", \"Luhya\", \"Kalenjin\", \"Luo\", \"Maasai\", \"Other\"),\n  N = 100)\n\ntable(respondent_ethnicity)\n\n\n\n\n\n\nrespondent_ethnicity\nFreq\n\n\n\n\nKikuyu\n24\n\n\nLuhya\n12\n\n\nKalenjin\n10\n\n\nLuo\n8\n\n\nMaasai\n4\n\n\nOther\n42"
  },
  {
    "objectID": "fabricatr/articles/common_social.html#data-with-fixed-minimum-and-maximum-values",
    "href": "fabricatr/articles/common_social.html#data-with-fixed-minimum-and-maximum-values",
    "title": "Common Social Science variables",
    "section": "Data with fixed minimum and maximum values",
    "text": "Data with fixed minimum and maximum values\nIt is often useful to generate data with fixed minimum or maximum values, but unclear how to best do so. In general the approach we would advocate to doing this is to generate a latent variable (described above) which might fall outside the minimum and maximum values, and then truncating the variable to the minimum and maximum values.\nConsider an experiment with a pre-post treatment design. A series of respondents are asked about their views on government efficacy, which will be measured by the respondents scoring their government from 0 to 100. Some respondents are then given a treatment intervention: for example, information about government service delivery, or a mechanism to report government fraud or waste. Finally, researchers ask the same respondents the same question about government efficacy.\nResearchers might simulate this experiment by choosing a population level Average Treatment Effect (in our example, assume a moderate treatment effect of 15 points), and adding a shock centered at this point to each treated unit’s pre-treatment outcome (in addition to adding noise to the control group). A challenge with this data is that it is naturally truncated: individuals whose scores were already quite high may now be modeled as having post-treatment scores above 100.\n\nset.seed(19861108)\n\nefficacy_experiment <- fabricate(\n  N = 1000,\n  treatment = draw_binary(0.5, N),\n  pre_outcome = rnorm(N, mean = 70, sd = 15),\n  post_outcome = pre_outcome + rnorm(N,\n                                     mean = ifelse(treatment, 15, 0),\n                                     sd = 10)\n)\n\nIn fact, in this example, some respondents have pre-treatment scores above 100! This matters because the real-world data gathered later will be truncated, and so the researchers power to detect effects may be compromised because of a high density of responses near the cutoff. As a result, it is important that researchers model the truncation directly. Doing so is simple using functionality provided by R: pmin and pmax.\nWhen used to truncate variables like this, pmax takes two arguments: a vector of numeric variables, and a minimum value you want to truncate to. Please note that, counter-intuitively, pmax is used to truncate to the minimum value and pmin is used to truncate to the maximum value. We see this design in action below:\n\nset.seed(19861108)\n\nfixed_efficacy_experiment <- fabricate(\n  N = 1000,\n  treatment = draw_binary(0.5, N),\n  pre_outcome = pmin(\n    pmax(rnorm(N, mean = 70, sd = 15), 0),\n    100),\n  post_outcome = pmin(\n    pmax(pre_outcome + rnorm(N,\n                             mean = ifelse(treatment, 15, 0),\n                             sd = 10), 0),\n    100)\n)\n\nLet’s consider how pre_outcome is created: first, each respondent is assigned a pre_treatment score with a mean of 70 points and a standard deviation of 15 points. Next, each of those scores is fed to pmax, along with an argument 0. Any scores that are lower than 0 are bumped up and truncated to 0. Finally, these scores are fed to pmin, along with an argument 100. Any scores that are higher than 100 are bumped down and truncated to 100. The result is that our variables display the desired effect:"
  },
  {
    "objectID": "fabricatr/articles/common_social.html#count-outcomes-and-skewed-distributions",
    "href": "fabricatr/articles/common_social.html#count-outcomes-and-skewed-distributions",
    "title": "Common Social Science variables",
    "section": "Count outcomes and skewed distributions",
    "text": "Count outcomes and skewed distributions\nResearchers may be interested in “count” outcomes, which describe a count of events of interest during a fixed time period. For our example in this section, we draw from “Propaganda and Conflict: Evidence from the Rwandan Genocide” (Yanagizawa-Drott 2014), an article which uses a quasi-experimental design to establish an association between the broadcasts of Radio Télévision Libre des Mille Collines and local instances of violence during the Rwandan Genocide. Substantively, the paper’s conclusion is that higher density in radio coverage is associated with greater local participation in genocidal violence.\nIn our version of this data, we have two variables of interest: number of violent incidents, and density of radio coverage. We know a priori that both variables must be at least 0, we are unsure what the maximum number might be, we know that the number of violent incidents must be a “discrete” variable (in this case, a whole number) while radio coverage is “continuous” (can take fractional values).\nFirst, to model the number of violent incidents, we make use of fabricatr’s draw_count function, which is quite simple – it needs two arguments: mean, which describes the mean count, and N, which describes how many units you need count data for. Statistically, this function generates “Poisson-distributed” count data. This is one of the typical distributions used for count data.\nSecond, to model the radio covarage, we might believe radio coverage is an example of skewed data; in other words, few urban areas might have extremely dense radio coverage, while many rural areas might have very low radio coverage. We, thus, need a data distribution that looks like this:\n\n\n\n\n\nR makes available a fairly simple function for generating this sort of data, rlnorm, which generates log-normal data. Log-normal data is one of the key distributions used to model data with a skew like the one we hypothesize: for example, income data in a population (where relatively few wealthy people have substantially more income than relatively many working class people). rlnorm takes three arguments: n (the number of observations), meanlog (the mean of the log-transformed data), and sdlog (the standard deviation of the log-transformed data).\n\nrtlme_model <- fabricate(\n  N = 1000,\n  radio_coverage = rlnorm(N, meanlog=0, sdlog=1),\n  violent_incident_count = draw_count(mean = 1.5 * radio_coverage, N = N)\n)\n\nReplicating real data is important because the inference you draw when modeling results depends on the “support” (range of values observations take) and “density” (how many observations take each value); to the extent that real-world data will likely be dense in some regions of the data and sparse in others, it is important that your synthetic data is as well in order to recover inferences that will be accurate to your future real-world inferences, and particularly your uncertainty about those inferences.\n\n\n\n\n\nObserve that the uncertainty around our predictions is far wider at the right end of the support, which has relatively little data, than at the left end of the support, where most of the data lives.\nThinking about choosing parameters for meanlog and sdlog is somewhat more mathematically complex in skewed distributions and depending on your use for, you might choose different parameters. Consult R’s documentation on log-normal data by running ?Lognormal. In addition, you may find it useful to investigate other distributions commonly used for this purpose including ?Beta and ?Gamma.\nBelow we present an example of generating income data which roughly approximates the current U.S. income distribution using the rgamma function. The parameters of this income function were derived by extracting quantiles of the current U.S. income distribution and then selecting the gamma distribution parameters and multipliers which best fit the data:\n\npopulation_data <- fabricate(\n  N = 1000,\n  income = 20000 * rgamma(N, 1.4, 0.65)\n)\n\nIn addition to the helper functions provided by fabricatr and the built-in R distributions suitable for generating skewed data, other R packages like sn also include useful functions for generating skewed data and can be incorporated into fabricate calls."
  },
  {
    "objectID": "fabricatr/articles/common_social.html#whats-next",
    "href": "fabricatr/articles/common_social.html#whats-next",
    "title": "Common Social Science variables",
    "section": "What’s next?",
    "text": "What’s next?\nThis brings us to the end of this introductory tutorial on common social science variables. As a next step, our tutorial on variable generation with fabricatr – targeted to a slightly more technical audience – contains more examples of the kinds of variables you can easily create with fabricatr. In addition, we have tutorials on creating time series variables, and on using other variable creation packages with fabricatr.\nFinally, if you are in interested in learning about how to structure your data (for example, to generate multi-level, panel, or cross-classified data), you can consult our tutorials on building data in fabricatr, and panel and cross-classified data in **fabricatr*."
  },
  {
    "objectID": "fabricatr/articles/time_series.html",
    "href": "fabricatr/articles/time_series.html",
    "title": "Time series data with fabricatr",
    "section": "",
    "text": "Below, we begin a series of examples discussing the creation of time series style data in fabricatr. This document assumes you are familiar with the basics of building and importing data with fabricatr."
  },
  {
    "objectID": "fabricatr/articles/time_series.html#multiple-units-with-time-trends",
    "href": "fabricatr/articles/time_series.html#multiple-units-with-time-trends",
    "title": "Time series data with fabricatr",
    "section": "Multiple units with time trends",
    "text": "Multiple units with time trends\nA more complex example might involve several geographic units, each of which has a separate growth value. Here we can use fabricatr’s support for multi-level, hierarchical data to elaborate:\n\npanel_units <- fabricate(\n  countries = add_level(\n    N = 5,\n    base_gdp = runif(N, 15, 22),\n    growth_units = runif(N, 0.2, 0.8),\n    growth_error = runif(N, 0.1, 0.5)\n  ),\n  years = add_level(\n    N = 5,\n    ts_year = 0:4,\n    gdp_measure = base_gdp + (ts_year * growth_units) + rnorm(N, sd=growth_error)\n  )\n)\n\nHere, each country-year inherits the parameters of the country: a base GDP, an annual growth rate (which is constant in this model), and an error parameter. The resulting data is 25 rows; 5 years for each of 5 countries.\n\nMultiple units with fixed global time trends\nNote that it would also be possible to include a fixed global trend in this example by including it as part of the variable specification:\n\nglobal_trend <- 0.1\n\nglobal_trend_example <- fabricate(\n  countries = add_level(\n    N = 5,\n    base_gdp = runif(N, 15, 22),\n    growth_units = runif(N, 0.2, 0.8),\n    growth_error = runif(N, 0.1, 0.5)\n  ),\n  years = add_level(\n    N = 5,\n    ts_year = 0:4,\n    gdp_measure = base_gdp +\n      (ts_year * global_trend) + (ts_year * growth_units) +\n      rnorm(N, sd=growth_error)\n  )\n)"
  },
  {
    "objectID": "fabricatr/articles/time_series.html#multiple-units-with-global-yearly-shocks",
    "href": "fabricatr/articles/time_series.html#multiple-units-with-global-yearly-shocks",
    "title": "Time series data with fabricatr",
    "section": "Multiple units with global yearly shocks",
    "text": "Multiple units with global yearly shocks\nEven more complex designs may include non-trend global level shocks (for example, financial crises or booms that affect all countries). The traditional hierarchical data design may not fit here, because we want common country-level data and common year-level data, both combined to form country-year observations. This is a good example of data that can best be described as multiple non-nested levels. Users interested in implementing this should review our manual on cross-classified and panel data. The below example will use cross_levels and non-nested level data.\n\npanel_global_data <- fabricate(\n  years = add_level(\n    N = 5,\n    ts_year = 0:4,\n    year_shock = rnorm(N, 0, 0.3)\n  ),\n  countries = add_level(\n    N = 5,\n    base_gdp = runif(N, 15, 22),\n    growth_units = runif(N, 0.2, 0.5),\n    growth_error = runif(N, 0.1, 0.5),\n    nest = FALSE\n  ),\n  country_years = cross_levels(\n    by = join_using(years, countries),\n    gdp_measure = base_gdp + year_shock + (ts_year * growth_units) +\n      rnorm(N, sd=growth_error)\n  )\n)\n\nNotice that each variable is specified in the appropriate level; time series year indicators and yearly shocks are specified at the year level; country-specific time trend information and base GDP are specified at the country level; and the actual GDP measure, which is country-year, is specified at the country-year level."
  },
  {
    "objectID": "fabricatr/articles/time_series.html#seasonal-or-arima-time-series",
    "href": "fabricatr/articles/time_series.html#seasonal-or-arima-time-series",
    "title": "Time series data with fabricatr",
    "section": "Seasonal or ARIMA Time Series",
    "text": "Seasonal or ARIMA Time Series\nAlthough fabricatr does not have formal functionality for the creation of ARIMA time series, we recommend that interested users see our guide to using other data creation packages with fabricatr, which includes an example of using the forecast package to generate ARIMA data."
  },
  {
    "objectID": "fabricatr/articles/time_series.html#whats-next",
    "href": "fabricatr/articles/time_series.html#whats-next",
    "title": "Time series data with fabricatr",
    "section": "What’s next?",
    "text": "What’s next?\nYou may also be interested in our online tutorial on structuring panel and cross-classified data.."
  },
  {
    "objectID": "fabricatr/articles/building_importing.html",
    "href": "fabricatr/articles/building_importing.html",
    "title": "Building and Importing Data",
    "section": "",
    "text": "fabricatr is a package designed to help you imagine your data before you collect it. While many solutions exist for creating simulated datasets, fabricatr is specifically designed to make the creation of realistic social science datasets easy. In particular, we need to be able to imagine correlated data and hierarchical data.\n\nBasics\nUsing fabricatr begins by calling the function fabricate(). fabricate() can be used to create single-level of hierarchical data. There are three main ways to call fabricate():\n\nMaking a single-level dataset by specifying how many observations you would like\nMaking a single-level dataset by importing data and optionally modifying it by creating new variables\nMaking a hierarchical dataset.\n\n\n\nSingle-level datasets from scratch\nMaking a single-level dataset begins with providing the argument N, a number representing the number of observations you wish to create, followed by a series of variable definitions. Variables can be defined using any function you have access to in R. fabricatr provides several simple functions for generating common types of data. These are covered below. Functions that create subsequent variables can rely on previously created variables, which ensures that variables can be related to one another:\n\nlibrary(fabricatr)\nmy_data <- fabricate(N = 5, Y = runif(N), Y2 = Y * 5)\nmy_data\n\n\n\n\n\n\nID\nY\nY2\n\n\n\n\n1\n0.78\n3.9\n\n\n2\n0.50\n2.5\n\n\n3\n0.54\n2.7\n\n\n4\n0.61\n3.0\n\n\n5\n0.32\n1.6\n\n\n\n\n\nThis simple example makes use of R’s built-in runif command. The rest of the tutorial assumes a familiarity with R and its basic data generating processes.\n\n\nFilling out observations.\nfabricate is intended to make rectangular data frames: this means that each variable added at a level needs to be the same length. Failure to provide equal-length variables will result in an error. We provide a convenient helper function, recycle, to help expand existing data to fit the length of your level. Here, let’s use the existing month variable from R to generate data using a month:\n\nmonth_gdp <- fabricate(\n  N = 20,\n  month_name = recycle(month.abb),\n  gdp_growth = rnorm(N, 0.5, 0.5)\n)\n\nmonth.abb contains the months of the year: [“Jan”, “Feb”, “Mar”, …, “Dec”]. It is obvious that although we are asking for 20 observations, there are only twelve months in the year. recycle will automatically wrap the month text resulting in a data frame with the 12 months “Jan” through “Dec”, followed by 8 months “Jan” through “Aug”.\n\n\nSingle-level datasets using existing data\nInstead of specifying the argument N, users can specify the argument data to import existing datasets. Once a dataset is imported, subsequent variables have access to N, representing the number of observations in the imported data. This makes it easy to augment existing data with simulations based on that data.\nIn this example, we make use of the quakes dataset, built into R, which describes characteristics of earthquakes off the coast of Fiji. The mag variable in this dataset contains the richter magnitude of the earthquakes. We will expand this data to add variables modelling hypothetical fatalities and insurance costs:\n\nsimulated_quake_data <- fabricate(\n  data = quakes,\n  fatalities = round(pmax(0, rnorm(N, mean = mag)) * 100),\n  insurance_cost = fatalities * runif(N, 1000000, 2000000)\n)\nhead(simulated_quake_data)\n\n\n\n\n\n\nlat\nlong\ndepth\nmag\nstations\nfatalities\ninsurance_cost\n\n\n\n\n-20\n182\n562\n4.8\n41\n494\n564,736,181\n\n\n-21\n181\n650\n4.2\n15\n390\n414,044,159\n\n\n-26\n184\n42\n5.4\n43\n596\n708,701,956\n\n\n-18\n182\n626\n4.1\n19\n293\n567,537,664\n\n\n-20\n182\n649\n4.0\n11\n487\n920,442,976\n\n\n-20\n184\n195\n4.0\n12\n319\n436,673,133\n\n\n\n\n\nNotice that variable creation calls are able to make reference to both the variables in the imported data set, and newly created variables. Also, function calls can be arbitrarily nested – the variable fatalities uses several nested function calls.\n\n\nHierarchical data\nThe most powerful use of fabricatr is to create hierarchical (“nested”) data. In the example below, we create 5 countries, each of which has 10 provinces. We also have covariates at the country level (GDP per capita and life expectancy) and at the provincial level (presence of natural resources, and presence of manufacturing industry):\n\ncountry_data <-\n  fabricate(\n    countries = add_level(\n      N = 5,\n      gdp_per_capita = runif(N, min = 10000, max = 50000),\n      life_expectancy = 50 + runif(N, 10, 20) + ((gdp_per_capita > 30000) * 10)\n    ),\n    provinces = add_level(\n      N = 10,\n      natural_resources = draw_binary(prob = 0.3, N = N),\n      manufacturing = draw_binary(prob = 0.7, N = N)\n    )\n  )\nhead(country_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountries\ngdp_per_capita\nlife_expectancy\nprovinces\nnatural_resources\nmanufacturing\n\n\n\n\n1\n40,451\n73\n01\n1\n1\n\n\n1\n40,451\n73\n02\n0\n1\n\n\n1\n40,451\n73\n03\n0\n0\n\n\n1\n40,451\n73\n04\n1\n1\n\n\n1\n40,451\n73\n05\n0\n0\n\n\n1\n40,451\n73\n06\n0\n1\n\n\n\n\n\nSeveral things can be observed in this example. First, fabricate knows that your second add_level() command will be nested under the first level of data. Each level gets its own ID variable, in addition to the variables you create. Second, the meaning of the variable “N” changes. During the add_level() call for countries, N is 5. During the add_level() call for provinces, N is 10. And the resulting data, of course, has 50 observations.\nFinally, the province-level variables are created using the draw_binary() function. This is a function provided by fabricatr to make simulating discrete random variables simple. When you simulate your own data, you can use fabricatr’s functions, R’s built-ins, or any custom functions you wish. draw_binary() is explained in our tutorial on variable generation using fabricatr\n\n\nAdding hierarchy to existing data\nfabricatr is also able to import existing data and nest hierarchical data under it. This maybe be useful if, for example, you have existing country-level data but wish to simulate data at lower geographical levels for the purposes of an experiment you plan to conduct.\nImagine importing the country-province data simulated in the previous example. Because fabricate() returns a data frame, this simulated data can be re-imported into a subsequent fabricate call, just like external data can be.\n\ncitizen_data <-\n  fabricate(\n    data = country_data,\n    citizens = add_level(\n      N = 10,\n      salary = rnorm(\n        N,\n        mean = gdp_per_capita + natural_resources * 5000 + manufacturing * 5000,\n        sd = 10000\n      )\n    )\n  )\nhead(citizen_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountries\ngdp_per_capita\nlife_expectancy\nprovinces\nnatural_resources\nmanufacturing\ncitizens\nsalary\n\n\n\n\n1\n40,451\n73\n01\n1\n1\n001\n45,852\n\n\n1\n40,451\n73\n01\n1\n1\n002\n56,768\n\n\n1\n40,451\n73\n01\n1\n1\n003\n52,549\n\n\n1\n40,451\n73\n01\n1\n1\n004\n46,428\n\n\n1\n40,451\n73\n01\n1\n1\n005\n70,148\n\n\n1\n40,451\n73\n01\n1\n1\n006\n64,771\n\n\n\n\n\nIn this example, we add a third level of data; for each of our 50 country-province observations, we now have 10 citizen-level observations. Citizen-level covariates like salary can draw from both the country-level covariate and the province-level covariate.\nNotice that the syntax for adding a new nested level to existing data is different than the syntax for adding new variables to the original dataset.\n\n\nModifying existing levels\nSuppose you have hierarchical data, and wish to simulate variables at a higher level of aggregation. For example, imagine you import a dataset containing citizens within countries, but you wish to simulate additional country-level variables. In fabricatr, you can do this using the modify_level() command.\nLet’s use our country-province data from earlier:\n\nnew_country_data <-\n  fabricate(\n    data = country_data,\n    countries = modify_level(average_temperature = runif(N, 30, 80))\n  )\n\nhead(new_country_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountries\ngdp_per_capita\nlife_expectancy\nprovinces\nnatural_resources\nmanufacturing\naverage_temperature\n\n\n\n\n1\n40,451\n73\n01\n1\n1\n38\n\n\n1\n40,451\n73\n02\n0\n1\n52\n\n\n1\n40,451\n73\n03\n0\n0\n69\n\n\n1\n40,451\n73\n04\n1\n1\n64\n\n\n1\n40,451\n73\n05\n0\n0\n33\n\n\n1\n40,451\n73\n06\n0\n1\n65\n\n\n\n\n\nWe can observe that the new variable is created at the level of aggregation you chose – countries. Also, although N is not specified anywhere, modify_level() knows how large N should be based on the number of countries it finds in the dataset. It is important, then, to ensure that the modify_level() command is correctly assigned to the level of interest. We can also modify more than one level.\nHere, we modify our country-province-citizen data from above:\n\nnew_citizen_data <-\n  fabricate(\n    data = citizen_data,\n    countries = modify_level(average_temperature = runif(N, 30, 80)),\n    provinces = modify_level(\n      conflict_zone = draw_binary(N, prob = 0.2 + natural_resources * 0.3),\n      infant_mortality = runif(N, 0, 10) + conflict_zone * 10 +\n        (average_temperature > 70) * 10\n    ),\n    citizens = modify_level(\n      college_degree = draw_binary(N, prob = 0.4 - (0.3 * conflict_zone))\n    )\n  )\n\nBefore assessing what this tells us about modify_level(), let’s consider what the data simulated does. It creates a new variable at the country level, for a country level average temperature. Subsequently, it creates a province level binary indicator for whether the province is an active conflict site. Provinces that have natural resources are more likely to be in conflict in this simulation, drawing on conclusions from literature on “resource curses”. The infant mortality rate for the province is able to depend both on province level data we have just generated, and country-level data: it is higher in high-temperature areas (reflecting literature on increased disease burden near the equator) and also higher in conflict zones. Citizen access to education is also random, but depends on whether they live in a conflict area.\nThere are a lot of things to learn from this example. First, it’s possible to modify multiple levels. Any new variable created will automatically propagate to the lower level data according – by setting an average temperature for a country, all provinces, and all citizens of those provinces, have the value for the country. Values created from one modify_level() call can be used in subsequent variables of the same call, or subsequent calls.\nAgain, we see the use of draw_binary(). Using this function is covered in our tutorial on generating discrete random variables, linked below.\n\n\nAverages within higher levels of hierarchy\nA powerful feature of nested data and fabricatr’s setup is that variable creating can access variables from higher in\nYou may want to include the mean value of a variable within a group defined by a higher level of the hierarchy, for example the average income of citizens within city. You can do this with ave(), a built-in R command:\n\nave_example <- fabricate(\n  cities = add_level(N = 2),\n  citizens = add_level(\n    N = 1:2, income = rnorm(N),\n    income_mean_city = ave(income, cities)\n  )\n)\nave_example\n\n\n\n\n\n\ncities\ncitizens\nincome\nincome_mean_city\n\n\n\n\n1\n1\n-1.39\n-1.39\n\n\n2\n2\n-0.16\n0.73\n\n\n2\n3\n1.62\n0.73\n\n\n\n\n\nHere, we can create citizen-level data which relies on the data of other citizens within the same city. ave() takes two arguments: first, the name of the variable we are averaging on (in this case, income), and second, the name of the level we are grouping by (in this case cities). Other R functions which are able to group by variables to compute statistics of interest are also compatible with fabricatr.\n\n\nNext Steps\nYou’ve seen fabricatr’s ability to generate single-level and hierarchical data, which is enough to get you started on using the package. From here, you can explore more about modeling the structure of data by reading our tutorial on panel and cross-classified data or using fabricatr to bootstrap or resample hierarchical data. Or, if you would like to learn about modeling specific variables using fabricatr, you can read our tutorial on common social science variables; our technical manual on generating discrete random variables; or our guide on using other data generation packages with fabricatr."
  },
  {
    "objectID": "fabricatr/index.html",
    "href": "fabricatr/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "Making decisions about research design and analysis strategies is often difficult before data is collected, because it is hard to imagine the exact form data will take. Instead, researchers typically modify analysis strategies to fit the data. fabricatr helps researchers imagine what data will look like before they collect it. Researchers can evaluate alternative analysis strategies, find the best one given how the data will look, and precommit before looking at the realized data.\n\n\nTo install the latest stable release of fabricatr, please ensure that you are running version 3.3 or later of R and run the following code:\ninstall.packages(\"fabricatr\")\nTo install the latest development release of fabricatr, please ensure that you are running version 3.3 or later of R and run the following code:\ninstall.packages(\"fabricatr\", dependencies = TRUE,\n                 repos = c(\"http://r.declaredesign.org\", \"https://cloud.r-project.org\"))\n\n\n\nOnce you have installed fabricatr, you can easily import your own data or generate new data. fabricatr is designed to help you solve two key problems:\n\nGenerating variables that look like the real thing, including Likert survey responses, treatment status, demographic variables, and variables correlated by group.\nGenerating data that are structured like the real thing, including panel data, multi-level (“nested”) data or cross-classified data.\n\nfabricatr is easy to learn and easy to read. Consider this example which generates data modeling the United States House of Representatives:\nset.seed(1)\nlibrary(fabricatr)\n\nhouse_members <- fabricate(\n  party_id = add_level(\n    N = 2, party_names = c(\"Republican\", \"Democrat\"), party_ideology = c(0.5, -0.5),\n    in_power = c(1, 0), party_incumbents = c(241, 194)\n  ),\n  rep_id = add_level(\n    N = party_incumbents, member_ideology = rnorm(N, party_ideology, sd = 0.5),\n    terms_served = draw_count(N = N, mean = 4),\n    female = draw_binary(N = N, prob = 0.198)\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\nparty_names\nparty_ideology\nin_power\nmember_ideology\nterms_served\nfemale\n\n\n\n\nRepublican\n0.5\n1\n0.43\n3\n0\n\n\nRepublican\n0.5\n1\n-0.19\n1\n0\n\n\nRepublican\n0.5\n1\n0.52\n4\n0\n\n\nRepublican\n0.5\n1\n0.85\n2\n0\n\n\nRepublican\n0.5\n1\n0.59\n5\n0\n\n\n\n\n\n\nFor more information, read our online tutorial to get started with fabricatr. This tutorial will give you a brief overview of fabricatr’s main functions and direct you towards your next steps. You can also read our documentation inside R using the command ?fabricate as your entry point.\nThis project is generously supported by a grant from the Laura and John Arnold Foundation and seed funding from EGAP."
  },
  {
    "objectID": "fabricatr/reference/recycle.html#description",
    "href": "fabricatr/reference/recycle.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThis function is a helper function designed call rep_len to expand the length of a data vector, but which can dynamically retrieve N from the surrounding level call for use in fabricatr."
  },
  {
    "objectID": "fabricatr/reference/recycle.html#usage",
    "href": "fabricatr/reference/recycle.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nrecycle(x, .N = NULL)"
  },
  {
    "objectID": "fabricatr/reference/recycle.html#arguments",
    "href": "fabricatr/reference/recycle.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nData to recycle into length N\n\n\n.N\nthe length to recycle the data to, typically provided implicitly by a or fabricate call wrapped around the function call."
  },
  {
    "objectID": "fabricatr/reference/recycle.html#value",
    "href": "fabricatr/reference/recycle.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of data padded to length N"
  },
  {
    "objectID": "fabricatr/reference/recycle.html#examples",
    "href": "fabricatr/reference/recycle.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\nfabricate(\n  N = 15,\n  month = recycle(month.abb)\n)\n\n   ID month\n1  01   Jan\n2  02   Feb\n3  03   Mar\n4  04   Apr\n5  05   May\n6  06   Jun\n7  07   Jul\n8  08   Aug\n9  09   Sep\n10 10   Oct\n11 11   Nov\n12 12   Dec\n13 13   Jan\n14 14   Feb\n15 15   Mar"
  },
  {
    "objectID": "fabricatr/reference/get_unique_variables_by_level.html#description",
    "href": "fabricatr/reference/get_unique_variables_by_level.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nFind which variables are unique at a given level in hierarchical data"
  },
  {
    "objectID": "fabricatr/reference/get_unique_variables_by_level.html#usage",
    "href": "fabricatr/reference/get_unique_variables_by_level.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nget_unique_variables_by_level(data, ID_label, superset = NULL)"
  },
  {
    "objectID": "fabricatr/reference/get_unique_variables_by_level.html#arguments",
    "href": "fabricatr/reference/get_unique_variables_by_level.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata\na data.frame\n\n\nID_label\nthe ID label to split upon\n\n\nsuperset\nSuperset contains a vector of character strings that contain variables the modify level call is going to write. Some of these may be columns in the data frame, others might not be. If superset is specified, then we definitely only want to check those variables"
  },
  {
    "objectID": "fabricatr/reference/get_unique_variables_by_level.html#value",
    "href": "fabricatr/reference/get_unique_variables_by_level.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\na character vector enumerating the unique variables"
  },
  {
    "objectID": "fabricatr/reference/all.html#description",
    "href": "fabricatr/reference/all.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nMagic number constant to allow users to specify ALL for passthrough resampling"
  },
  {
    "objectID": "fabricatr/reference/all.html#usage",
    "href": "fabricatr/reference/all.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nALL"
  },
  {
    "objectID": "fabricatr/reference/split_quantile.html#description",
    "href": "fabricatr/reference/split_quantile.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nSurvey data is often presented in aggregated, depersonalized form, which can involve binning underlying data into quantile buckets; for example, rather than reporting underlying income, a survey might report income by decile. split_quantile can automatically produce this split using any data x and any number of splits `type."
  },
  {
    "objectID": "fabricatr/reference/split_quantile.html#usage",
    "href": "fabricatr/reference/split_quantile.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nsplit_quantile(x = NULL, type = NULL)"
  },
  {
    "objectID": "fabricatr/reference/split_quantile.html#arguments",
    "href": "fabricatr/reference/split_quantile.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA vector of any type that can be ordered – i.e. numeric or factor where factor levels are ordered.\n\n\ntype\nThe number of buckets to split data into. For a median split, enter 2; for terciles, enter 3; for quartiles, enter 4; for quintiles, 5; for deciles, 10."
  },
  {
    "objectID": "fabricatr/reference/split_quantile.html#examples",
    "href": "fabricatr/reference/split_quantile.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Divide this arbitrary data set in 3.\ndata_input <- rnorm(n = 100)\nsplit_quantile(x = data_input, type = 3)\n\n  [1] 3 1 3 2 2 3 1 2 1 3 1 1 2 1 2 1 2 3 2 1 2 1 2 3 2 3 2 1 1 3 1 3 1 3 3 1 1\n [38] 2 1 1 3 1 2 3 3 2 3 2 2 3 1 2 2 3 3 2 1 3 1 2 3 2 1 1 3 3 2 2 1 3 1 2 3 3\n [75] 2 1 1 3 2 2 2 3 1 2 1 2 1 1 3 3 3 3 2 1 1 3 2 1 2 3\nLevels: 1 2 3"
  },
  {
    "objectID": "fabricatr/reference/draw_likert.html#description",
    "href": "fabricatr/reference/draw_likert.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nRecode a latent variable into a Likert response variable"
  },
  {
    "objectID": "fabricatr/reference/draw_likert.html#usage",
    "href": "fabricatr/reference/draw_likert.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_likert(\n  x,\n  min = NULL,\n  max = NULL,\n  bins = NULL,\n  breaks = NULL,\n  labels = NULL\n)"
  },
  {
    "objectID": "fabricatr/reference/draw_likert.html#arguments",
    "href": "fabricatr/reference/draw_likert.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\na numeric variable considered to be “latent”\n\n\nmin\nthe minimum value of the latent variable\n\n\nmax\nthe maximum value of the latent variable\n\n\nbins\nthe number of Likert scale values. The latent variable will be cut into equally sized bins as in seq(min, max, length.out = bins + 1)\n\n\nbreaks\nA vector of breaks. This option is useful for settings in which equally-sized breaks are inappropriate\n\n\nlabels\nAn optional vector of labels. If labels are provided, the resulting output will be a factor."
  },
  {
    "objectID": "fabricatr/reference/draw_likert.html#examples",
    "href": "fabricatr/reference/draw_likert.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\nx <- 1:100\n\ndraw_likert(x, min = 0, max = 100, bins = 7)\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3\n [38] 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6\n [75] 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n\ndraw_likert(x, breaks = c(-1, 10, 100))\n\n  [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2"
  },
  {
    "objectID": "fabricatr/reference/join_using.html#description",
    "href": "fabricatr/reference/join_using.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nHelper function handling specification of which variables to join a cross-classified data on, and what kind of correlation structure needed. Correlation structures can only be provided if the underlying call is a link_levels() call."
  },
  {
    "objectID": "fabricatr/reference/join_using.html#usage",
    "href": "fabricatr/reference/join_using.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\njoin_using(..., rho = 0, sigma = NULL)"
  },
  {
    "objectID": "fabricatr/reference/join_using.html#arguments",
    "href": "fabricatr/reference/join_using.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nA series of two or more variable names, unquoted, to join on in order to create cross-classified data.\n\n\nrho\nA fixed (Spearman’s rank) correlation coefficient between the variables being joined on: note that if it is not possible to make a correlation matrix from this coefficient (e.g. if you are joining on three or more variables and rho is negative) then the cross_levels() call will fail. Do not provide rho if making panel data.\n\n\nsigma\nA matrix with dimensions equal to the number of variables you are joining on, specifying the correlation for the resulting joined data. Only one of rho and sigma should be provided. Do not provide sigma if making panel data."
  },
  {
    "objectID": "fabricatr/reference/join_using.html#examples",
    "href": "fabricatr/reference/join_using.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\npanels <- fabricate(\n  countries = add_level(N = 150, country_fe = runif(N, 1, 10)),\n  years = add_level(N = 25, year_shock = runif(N, 1, 10), nest = FALSE),\n  obs = cross_levels(\n    by = join_using(countries, years),\n    new_variable = country_fe + year_shock + rnorm(N, 0, 2)\n  )\n)\n\nschools_data <- fabricate(\n  primary_schools = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n  secondary_schools = add_level(\n    N = 15,\n    ss_quality = runif(N, 1, 10),\n    nest = FALSE),\n  students = link_levels(\n    N = 1500,\n    by = join_using(primary_schools, secondary_schools),\n    SAT_score = 800 + 13 * ps_quality + 26 * ss_quality + rnorm(N, 0, 50)\n  )\n)"
  },
  {
    "objectID": "fabricatr/reference/index.html",
    "href": "fabricatr/reference/index.html",
    "title": "**Declare**Design",
    "section": "",
    "text": "Function(s)\nDescription\n\n\n\n\nALL\nMagic number constant to allow users to specify ALL for passthrough resampling\n\n\ncorrelate()\nPerform generation of a correlated random variable.\n\n\ncross_levels() link_levels()\nCreates panel or cross-classified data\n\n\ndraw_binary_icc()\nDraw binary data with fixed intra-cluster correlation.\n\n\ndraw_binomial() draw_categorical() draw_ordered() draw_count() draw_binary() draw_quantile()\nDraw discrete variables including binary, binomial count, poisson count, ordered, and categorical\n\n\ndraw_likert()\nRecode a latent variable into a Likert response variable\n\n\ndraw_multivariate()\nDraw multivariate random variables\n\n\ndraw_normal_icc()\nDraw normal data with fixed intra-cluster correlation.\n\n\nfabricate() add_level() modify_level() nest_level()\nFabricate data\n\n\nget_unique_variables_by_level()\nFind which variables are unique at a given level in hierarchical data\n\n\njoin_using()\nHelper function handling specification of which variables to join a cross-classified data on, and what kind of correlation structure needed. Correlation structures can only be provided if the underlying call is a link_levels() call.\n\n\npotential_outcomes()\nBuild potential outcomes variables\n\n\nrecycle()\nExpands data to a given length through recycling.\n\n\nresample_data()\nResample data, including hierarchical data\n\n\nreveal_outcomes()\nReveal outcomes\n\n\nsplit_quantile()\nSplit data into quantile buckets (e.g. terciles, quartiles, quantiles, deciles)."
  },
  {
    "objectID": "fabricatr/reference/correlate.html#description",
    "href": "fabricatr/reference/correlate.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThis function is EXPERIMENTAL, and we cannot guarantee its properties for all data structures. Be sure to diagnose your design and assess the distribution of your variables."
  },
  {
    "objectID": "fabricatr/reference/correlate.html#usage",
    "href": "fabricatr/reference/correlate.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncorrelate(draw_handler, ..., given, rho)"
  },
  {
    "objectID": "fabricatr/reference/correlate.html#arguments",
    "href": "fabricatr/reference/correlate.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndraw_handler\nThe unquoted name of a function to generate data. Currently, draw_binary, draw_binomial, and draw_count are supported.\n\n\n…\nThe arguments to draw_handler (e.g. prob, mean, etc.)\n\n\ngiven\nA vector that can be ordered; the reference distribution X that Y will be correlated with.\n\n\nrho\nA rank correlation coefficient between -1 and 1."
  },
  {
    "objectID": "fabricatr/reference/correlate.html#details",
    "href": "fabricatr/reference/correlate.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nIn order to generate a random variable of a specific distribution based on another variable of any distribution and a correlation coefficient rho, we map the first, known variable into the standard normal space via affine transformation, generate the conditional distribution of the resulting variable as a standard normal, and then map that standard normal back to the target distribution. The result should ensure, in expectation, a rank-order correlation of rho."
  },
  {
    "objectID": "fabricatr/reference/correlate.html#examples",
    "href": "fabricatr/reference/correlate.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Generate a variable of interest\nexam_score <- pmin(100, rnorm(n = 100, mean = 80, sd = 10))\n\n# Generate a correlated variable using fabricatr variable generation\nscholarship_offers <- correlate(given = exam_score, rho = 0.7,\n                                draw_count, mean = 3)\n\n# Generate a correlated variable using base R distributions\nfinal_grade <- pmax(100, correlate(given = exam_score, rho = 0.7,\n                                   rnorm, mean = 80, sd = 10))"
  },
  {
    "objectID": "fabricatr/reference/reveal_outcomes.html#description",
    "href": "fabricatr/reference/reveal_outcomes.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nImplements a generalized switching equation. Reveals observed outcomes from multiple potential outcomes variables and an assignment variable."
  },
  {
    "objectID": "fabricatr/reference/reveal_outcomes.html#usage",
    "href": "fabricatr/reference/reveal_outcomes.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nreveal_outcomes(x)"
  },
  {
    "objectID": "fabricatr/reference/reveal_outcomes.html#arguments",
    "href": "fabricatr/reference/reveal_outcomes.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nA formula with the outcome name on the left hand side and assignment variables on the right hand side (e.g., Y ~ Z)."
  },
  {
    "objectID": "fabricatr/reference/reveal_outcomes.html#examples",
    "href": "fabricatr/reference/reveal_outcomes.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\ndat <- fabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z + U)\n)\n\nfabricate(\n  data = dat,\n  Z = rbinom(N, 1, prob = 0.5),\n  Y = reveal_outcomes(Y ~ Z)\n)\n\n   ID          U      Y_Z_0      Y_Z_1 Z          Y\n1  01  1.8711453  1.8711453  1.9711453 0  1.8711453\n2  02  2.2854383  2.2854383  2.3854383 1  2.3854383\n3  03 -0.8681953 -0.8681953 -0.7681953 0 -0.8681953\n4  04  1.8070426  1.8070426  1.9070426 1  1.9070426\n5  05 -0.7822690 -0.7822690 -0.6822690 0 -0.7822690\n6  06 -1.1157401 -1.1157401 -1.0157401 1 -1.0157401\n7  07 -0.4743219 -0.4743219 -0.3743219 0 -0.4743219\n8  08  0.8578228  0.8578228  0.9578228 1  0.9578228\n9  09  1.0105581  1.0105581  1.1105581 1  1.1105581\n10 10  0.4196134  0.4196134  0.5196134 1  0.5196134\n\nfabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z1 + 0.3 * Z2 + 0.5 * Z1 * Z2 + U,\n                     conditions = list(Z1 = c(0, 1),\n                                       Z2 = c(0, 1))),\n  Z1 = rbinom(N, 1, prob = 0.5),\n  Z2 = rbinom(N, 1, prob = 0.5),\n  Y = reveal_outcomes(Y ~ Z1 + Z2)\n)\n\n   ID             U   Y_Z1_0_Z2_0 Y_Z1_1_Z2_0 Y_Z1_0_Z2_1 Y_Z1_1_Z2_1 Z1 Z2\n1  01  0.8849031057  0.8849031057  0.98490311  1.18490311   1.7849031  1  0\n2  02 -0.0008517054 -0.0008517054  0.09914829  0.29914829   0.8991483  0  1\n3  03 -0.4868404404 -0.4868404404 -0.38684044 -0.18684044   0.4131596  1  1\n4  04 -1.3262819500 -1.3262819500 -1.22628195 -1.02628195  -0.4262820  0  1\n5  05 -0.3185716848 -0.3185716848 -0.21857168 -0.01857168   0.5814283  1  1\n6  06  0.7068624169  0.7068624169  0.80686242  1.00686242   1.6068624  0  1\n7  07 -0.2675495840 -0.2675495840 -0.16754958  0.03245042   0.6324504  0  0\n8  08  0.5228689756  0.5228689756  0.62286898  0.82286898   1.4228690  1  0\n9  09  1.3353410017  1.3353410017  1.43534100  1.63534100   2.2353410  1  0\n10 10  1.1230912257  1.1230912257  1.22309123  1.42309123   2.0230912  1  1\n            Y\n1   0.9849031\n2   0.2991483\n3   0.4131596\n4  -1.0262820\n5   0.5814283\n6   1.0068624\n7  -0.2675496\n8   0.6228690\n9   1.4353410\n10  2.0230912"
  },
  {
    "objectID": "fabricatr/reference/draw_binary_icc.html#description",
    "href": "fabricatr/reference/draw_binary_icc.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nData is generated to ensure inter-cluster correlation 0, intra-cluster correlation in expectation ICC. Algorithm taken from Hossein, Akhtar. “ICCbin: An R Package Facilitating Clustered Binary Data Generation, and Estimation of Intracluster Correlation Coefficient (ICC) for Binary Data”."
  },
  {
    "objectID": "fabricatr/reference/draw_binary_icc.html#usage",
    "href": "fabricatr/reference/draw_binary_icc.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_binary_icc(prob = 0.5, N = NULL, clusters, ICC = 0)"
  },
  {
    "objectID": "fabricatr/reference/draw_binary_icc.html#arguments",
    "href": "fabricatr/reference/draw_binary_icc.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nprob\nA number or vector of numbers, one probability per cluster. If none is provided, will default to 0.5.\n\n\nN\n(Optional) A number indicating the number of observations to be generated. Must be equal to length(clusters) if provided.\n\n\nclusters\nA vector of factors or items that can be coerced to clusters; the length will determine the length of the generated data.\n\n\nICC\nA number indicating the desired ICC, if none is provided the default ICC will be 0."
  },
  {
    "objectID": "fabricatr/reference/draw_binary_icc.html#value",
    "href": "fabricatr/reference/draw_binary_icc.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of binary numbers corresponding to the observations from the supplied cluster IDs."
  },
  {
    "objectID": "fabricatr/reference/draw_binary_icc.html#examples",
    "href": "fabricatr/reference/draw_binary_icc.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n# Divide units into clusters\nclusters = rep(1:5, 10)\n\n# Default probability 0.5, default ICC 0\ndraw_binary_icc(clusters = clusters)\n\n [1] 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1\n[39] 1 1 1 1 0 0 0 0 1 0 0 0\n\n# Specify probability or ICC\ncorr_draw = draw_binary_icc(prob = 0.5, clusters = clusters, ICC = 0.5)\n\n# Verify ICC of data.\nsummary(lm(corr_draw ~ as.factor(clusters)))$r.squared\n\n[1] 0.4301471"
  },
  {
    "objectID": "fabricatr/reference/draw_multivariate.html#description",
    "href": "fabricatr/reference/draw_multivariate.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDraw multivariate random variables"
  },
  {
    "objectID": "fabricatr/reference/draw_multivariate.html#usage",
    "href": "fabricatr/reference/draw_multivariate.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_multivariate(formula, sep = \"_\")"
  },
  {
    "objectID": "fabricatr/reference/draw_multivariate.html#arguments",
    "href": "fabricatr/reference/draw_multivariate.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nformula\nFormula describing the multivariate draw. The lefthand side is the names or prefix and the right-hand side is the multivariate draw function call, such as mvrnorm from the MASS library or rmnom from the extraDistr library.\n\n\nsep\nSeparator string between prefix and variable number. Only used when a single character string is provided and multiple variables created."
  },
  {
    "objectID": "fabricatr/reference/draw_multivariate.html#value",
    "href": "fabricatr/reference/draw_multivariate.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\ntibble"
  },
  {
    "objectID": "fabricatr/reference/draw_multivariate.html#examples",
    "href": "fabricatr/reference/draw_multivariate.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\nlibrary(MASS)\n\n# draw from multivariate normal distribution\ndat <-\n  draw_multivariate(c(Y_1, Y_2) ~ mvrnorm(\n    n = 500,\n    mu = c(0, 0),\n    Sigma = matrix(c(1, 0.5, 0.5, 1), 2, 2)\n  ))\n\n\ncor(dat)\n\n          Y_1       Y_2\nY_1 1.0000000 0.5451136\nY_2 0.5451136 1.0000000\n\n# equivalently, you can provide a prefix for the variable names\n# (easier if you have many variables)\ndraw_multivariate(Y ~ mvrnorm(\n  n = 5,\n  mu = c(0, 0),\n  Sigma = matrix(c(1, 0.5, 0.5, 1), 2, 2)\n))\n\n            Y_1         Y_2\n1 -2.0115426136 -1.40499329\n2  1.2603303888  0.83990156\n3 -0.0009569578 -0.35096212\n4  0.5815081464 -0.06580749\n5 -0.2765283060 -0.92400059\n\n# within fabricate\nfabricate(\n  N = 100,\n  draw_multivariate(c(Y_1, Y_2) ~ mvrnorm(\n    n = N,\n    mu = c(0, 0),\n    Sigma = matrix(c(1, 0.5, 0.5, 1), 2, 2)\n  ))\n)\n\n     ID         Y_1         Y_2\n1   001 -1.42467598 -0.41827632\n2   002  0.38459433 -0.90898234\n3   003 -1.03294865  0.48521461\n4   004 -0.14114674 -1.51556098\n5   005 -0.06832941 -2.93628025\n6   006 -0.65117183 -1.02771658\n7   007 -0.59095097 -0.22554491\n8   008  0.49516278 -0.34540462\n9   009 -1.77159741 -1.26068037\n10  010 -0.45964411  1.24082973\n11  011  1.73069506  0.23977157\n12  012  0.82587073  0.77364799\n13  013 -0.10278258  0.54417417\n14  014 -0.14507694 -1.87360588\n15  015  0.42446366 -0.07006108\n16  016  0.89212795 -0.37437890\n17  017 -0.98684838  0.77798960\n18  018 -1.44907616  0.29070680\n19  019 -0.61373546  0.49870545\n20  020  0.90407551  0.31555195\n21  021 -0.07609711  1.20823455\n22  022  0.39643289  1.00967170\n23  023  0.53415603 -0.33041075\n24  024  0.67827891 -0.85626426\n25  025  0.01817031 -1.66673654\n26  026 -1.48243807 -0.77600951\n27  027  0.22237873  0.61808502\n28  028 -1.55915400 -0.38469901\n29  029 -1.21176540 -0.08821391\n30  030 -0.67851860 -0.71049334\n31  031 -0.94558326  0.09933495\n32  032 -0.08600001  0.09557204\n33  033 -0.52155034 -0.96312448\n34  034 -1.83289635 -0.94307363\n35  035  1.13016759  1.01824576\n36  036 -0.48064464 -1.08608631\n37  037  1.17668530  0.98729156\n38  038  0.96852198  0.15378416\n39  039  2.11824263  0.82059694\n40  040 -0.14229090 -0.72123019\n41  041 -0.47864474 -0.38868553\n42  042 -0.12942067 -0.82484825\n43  043  0.77337968  0.81561489\n44  044  0.68997398  0.30380820\n45  045  0.08978647  1.23089496\n46  046 -0.40413428  0.71000755\n47  047 -1.53409605 -0.96348971\n48  048  0.43296101  0.84652269\n49  049 -0.20660681 -1.07463113\n50  050  0.95876221  0.18350889\n51  051 -0.07191743  0.33515195\n52  052  0.17716295  1.72346741\n53  053  0.42786679  0.22960370\n54  054  0.26132633 -0.97977959\n55  055  1.84426770 -0.15732170\n56  056 -0.86599659 -0.59377408\n57  057 -0.06989369  1.38576748\n58  058 -0.27385615  0.46419699\n59  059  0.21084787  0.27583771\n60  060 -0.74295459 -1.62572077\n61  061  1.89974304  0.58776841\n62  062 -1.34460649 -1.08546939\n63  063 -0.96277744 -1.38414416\n64  064 -0.57153658  0.22596251\n65  065  0.52570026 -0.90952090\n66  066 -1.26851874 -1.74406116\n67  067  1.90916158  1.24974352\n68  068 -1.50474820 -1.09880247\n69  069 -0.19603076 -1.18559737\n70  070  0.85372420  0.57551267\n71  071 -1.09028945 -1.33582591\n72  072 -1.69387284 -1.67565908\n73  073 -1.28417593 -1.86927760\n74  074  0.15774101 -0.76524247\n75  075  0.49025234  0.14659895\n76  076 -1.56177537  0.77639189\n77  077  0.33740067  1.14641144\n78  078 -0.63606141  0.69122631\n79  079 -1.41298398 -1.53107834\n80  080  0.86109405  1.96449165\n81  081  0.77551783  0.48630755\n82  082  0.87259481  1.60236032\n83  083 -0.69968107 -1.04956381\n84  084  0.55895064  0.65496766\n85  085 -0.83327131 -1.02661668\n86  086 -0.32115568 -0.16202417\n87  087 -0.24892100  0.04545885\n88  088 -0.51611531 -1.29273586\n89  089  0.85000508  1.85900125\n90  090 -1.03979186 -1.06285485\n91  091  0.19814659 -1.15515637\n92  092  2.30209962  1.42251985\n93  093 -0.08452573 -1.21743704\n94  094 -1.68184781  0.19545289\n95  095 -0.44764773 -0.27475722\n96  096 -2.23043955 -1.16369166\n97  097  0.43229554 -0.80573803\n98  098 -0.16073977 -0.87599886\n99  099 -1.30975205  0.36357046\n100 100 -0.04748996  0.19704316\n\n# You can also write the following, which works but gives less control over the names\nfabricate(N = 100,\nY = mvrnorm(\n  n = N,\n  mu = c(0, 0),\n  Sigma = matrix(c(1, 0.5, 0.5, 1), 2, 2)\n))\n\n     ID         Y.1          Y.2\n1   001 -0.29868250 -0.934770092\n2   002 -0.81608287  0.755926142\n3   003  2.62183022  2.996042666\n4   004  1.00165870  1.468536228\n5   005  0.67710312 -0.930942215\n6   006 -1.52188352 -2.171299092\n7   007 -0.01133819  1.047569108\n8   008  0.73712748 -1.488246094\n9   009  0.62608454  0.820156253\n10  010  1.06241382  1.879273219\n11  011 -0.41511088 -1.000885003\n12  012  1.61107661  1.286316245\n13  013  0.16160711  1.680056163\n14  014  0.05885448  0.245682893\n15  015 -1.68213593 -0.984461094\n16  016  1.59505283 -0.811819575\n17  017  0.17230554 -1.095526142\n18  018 -1.07051677 -2.001518925\n19  019 -0.66974763 -0.675048081\n20  020  0.43827209  0.445701197\n21  021 -0.31595397  0.342827757\n22  022  1.83180393  0.703624637\n23  023  0.72080187  1.752923891\n24  024 -0.97156984 -1.013951616\n25  025 -0.73006510 -0.204166969\n26  026  0.47902482 -2.055061280\n27  027  0.94283588  0.179118822\n28  028 -0.57595047 -0.723276635\n29  029 -1.26343308  0.002676057\n30  030  0.82263582  0.372742130\n31  031 -0.39922235 -0.595264751\n32  032 -0.35359010  0.513093429\n33  033 -0.99907845 -0.222400457\n34  034 -1.08277081 -0.445292036\n35  035  1.11309798  0.814925310\n36  036 -1.03515619 -1.907377510\n37  037 -1.42352614 -2.309070598\n38  038 -1.33694817  0.052287952\n39  039 -0.39792420  0.006865743\n40  040 -0.62461588  1.217179047\n41  041 -0.34447294 -0.443778404\n42  042  0.38314714  0.233436337\n43  043  0.81140283  0.312413655\n44  044  0.21701361  0.481618750\n45  045  1.18039855  1.698451978\n46  046  1.17374858 -0.276683795\n47  047  0.68879941  0.051603662\n48  048  0.16649388 -0.389343729\n49  049  1.36795545  2.075278748\n50  050  1.56708465  1.759153433\n51  051  0.62880846  0.768803792\n52  052 -0.25581675 -0.605275624\n53  053  1.14087257  1.275736569\n54  054  1.13218115  0.856749125\n55  055 -1.45005184 -0.122653386\n56  056  0.45171393  0.279405511\n57  057  1.05925402  0.781379794\n58  058 -0.35487239 -0.480669891\n59  059  1.95910976  0.337724778\n60  060  1.32109609  1.169768634\n61  061  1.25055533  0.711952575\n62  062 -1.28010423 -0.383059811\n63  063  1.27742564  0.352510500\n64  064  0.06087004 -0.562475298\n65  065 -0.85992416 -0.037727269\n66  066  0.56616918 -1.737481640\n67  067 -0.57024063 -0.722248548\n68  068 -0.09460513 -0.119586131\n69  069 -0.19586774 -0.259524824\n70  070  0.60355249 -0.146273106\n71  071  0.18146583  1.181101383\n72  072 -1.16840605  0.240158176\n73  073  0.38524174  0.994765637\n74  074 -0.99745314  0.068784479\n75  075  1.23045416  1.093569104\n76  076  0.33556584 -1.448281841\n77  077  0.60486140  0.396987415\n78  078  0.64225173  0.948490647\n79  079 -1.79983376 -1.988644167\n80  080  0.29519442  0.439047473\n81  081 -0.01230123 -0.114298552\n82  082  0.17229122  0.889377385\n83  083  1.04274991  0.923337181\n84  084 -0.04224103  0.443941347\n85  085 -0.30739997 -0.349018077\n86  086 -1.12003683 -0.628230317\n87  087 -0.42853344 -0.249438186\n88  088 -1.87542676 -1.050878690\n89  089 -2.09557050 -1.786068349\n90  090  0.36652957 -1.145996524\n91  091 -0.84529441 -0.198895493\n92  092  0.65547227  2.224001732\n93  093  0.59811141  0.493114212\n94  094  1.74260210  2.109317665\n95  095 -0.27040656 -0.934368917\n96  096 -0.43194985  1.047275338\n97  097  0.88601441 -0.863174813\n98  098 -1.14398905  0.627840538\n99  099  0.07418618  0.099414218\n100 100 -0.26889566 -1.148404473"
  },
  {
    "objectID": "fabricatr/reference/resample_data.html#description",
    "href": "fabricatr/reference/resample_data.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThis function allows you to resample any data frame. The default mode performs a single resample of size N with replacement. Users can also specify more complex resampling strategies to resample hierarchical data."
  },
  {
    "objectID": "fabricatr/reference/resample_data.html#usage",
    "href": "fabricatr/reference/resample_data.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nresample_data(data, N, ID_labels = NULL, unique_labels = FALSE)"
  },
  {
    "objectID": "fabricatr/reference/resample_data.html#arguments",
    "href": "fabricatr/reference/resample_data.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata\nA data.frame, usually provided by the user.\n\n\nN\nThe number of sample observations to return. If N is a single scalar and no labels are provided, N will specify the number of unit observations to resample. If N is named, or if the ID_labels argument is specified (in which case, both N and ID_labels should be the same length), then the units resampled will be values of the levels resampled (this is useful for, e.g., cluster resampling). If N is the constant ALL for any level, all units of this level will be transparently passed through to the next level of resampling.\n\n\nID_labels\nA character vector of the variables that indicate the data hierarchy, from highest to lowest (i.e., from cities to citizens).\n\n\nunique_labels\nA boolean, defaulting to FALSE. If TRUE, fabricatr will created an extra data frame column depicting a unique version of the ID_label variable resampled on, called _unique."
  },
  {
    "objectID": "fabricatr/reference/resample_data.html#value",
    "href": "fabricatr/reference/resample_data.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA data.frame"
  },
  {
    "objectID": "fabricatr/reference/resample_data.html#examples",
    "href": "fabricatr/reference/resample_data.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Resample a dataset of size N without any hierarchy\nbaseline_survey <- fabricate(N = 50, Y_pre = rnorm(N))\nbootstrapped_data <- resample_data(baseline_survey)\n\n# Specify a fixed number of observations to return\nbaseline_survey <- fabricate(N = 50, Y_pre = rnorm(N))\nbootstrapped_data <- resample_data(baseline_survey, N = 100)\n\n# Resample by a single level of a hierarchical dataset (e.g. resampling\n# clusters of observations): N specifies a number of clusters to return\n\nclustered_survey <- fabricate(\n  clusters = add_level(N=25),\n  cities = add_level(N=round(runif(25, 1, 5)),\n                     population=runif(n = N, min=50000, max=1000000))\n)\n\ncluster_resample <- resample_data(clustered_survey, N = 5, ID_labels = \"clusters\")\n\n# Alternatively, pass the level to resample as a name:\ncluster_resample_2 <- resample_data(clustered_survey, N=c(clusters = 5))\n\n# Resample a hierarchical dataset on multiple levels\nmy_data <-\nfabricate(\n  cities = add_level(N = 20, elevation = runif(n = N, min = 1000, max = 2000)),\n  citizens = add_level(N = 30, age = runif(n = N, min = 18, max = 85))\n)\n\n# Specify the levels you wish to resample:\nmy_data_2 <- resample_data(my_data, N = c(3, 5),\n                           ID_labels = c(\"cities\", \"citizens\"))\n\n# To resample every unit at a given level, use the ALL constant\n# This example will resample 10 citizens at each of the cities:\n\npassthrough_resample_data <- resample_data(my_data, N = c(cities=ALL, citizens=10))\n\n# To ensure a column with unique labels (for example, to calculate block-level\n# statistics irrespective of sample choices), use the unique_labels=TRUE\n# argument -- this will produce new columns with unique labels.\n\nunique_resample <- resample_data(my_data, N = c(cities=5), unique_labels = TRUE)"
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#description",
    "href": "fabricatr/reference/cross_levels.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nThis function allows the user to create data structures that are paneled or cross-classified: where one level of observation draws simultaneously from two or many source levels. Common examples of panels include country-year data which have country-level and year-level characteristics."
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#usage",
    "href": "fabricatr/reference/cross_levels.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ncross_levels(by = NULL, ...)\n\nlink_levels(N = NULL, by = NULL, ...)"
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#arguments",
    "href": "fabricatr/reference/cross_levels.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nby\nThe result of a call to join_using() which specifies how the cross-classified data will be created\n\n\n…\nA variable or series of variables to add to the resulting data frame after the cross-classified data is created.\n\n\nN\nThe number of observations in the resulting data frame. If N is NULL or not provided, the join_using will be an “outer product” – merging each row of each provided data frame with each other data frame to make a full panel."
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#details",
    "href": "fabricatr/reference/cross_levels.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nBy specifying the appropriate arguments in join_using() within the function call, it is possible to induce correlation in cross-classified data."
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#value",
    "href": "fabricatr/reference/cross_levels.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\ndata.frame"
  },
  {
    "objectID": "fabricatr/reference/cross_levels.html#examples",
    "href": "fabricatr/reference/cross_levels.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Generate full panel data\npanel <- fabricate(\n countries = add_level(N = 20, country_shock = runif(N, 1, 10)),\n years = add_level(N = 20, year_shock = runif(N, 1, 10), nest=FALSE),\n obs = cross_levels(by = join_using(countries, years), GDP_it = country_shock + year_shock)\n)\n\n# Include an \"N\" argument to allow for cross-classified\n# data.\nstudents <- fabricate(\n primary_school = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n secondary_school = add_level(N = 15, ss_quality = runif(N, 1, 10), nest=FALSE),\n students = link_levels(N = 500, by = join_using(primary_school, secondary_school))\n)\nhead(students)\n\n  primary_school ps_quality secondary_school ss_quality students\n1             16   8.181004               07   3.996165      001\n2             04   1.813434               01   9.363899      002\n3             14   7.604139               03   3.877573      003\n4             16   8.181004               08   1.060197      004\n5             17   5.624523               03   3.877573      005\n6             14   7.604139               01   9.363899      006\n\n# Induce a correlation structure in cross-classified data by providing\n# rho.\nstudents <- fabricate(\n primary_school = add_level(N = 20, ps_quality = runif(N, 1, 10)),\n secondary_school = add_level(N = 15, ss_quality = runif(N, 1, 10), nest=FALSE),\n students = link_levels(N = 500, by = join_using(ps_quality, ss_quality, rho = 0.5))\n)\ncor(students$ps_quality, students$ss_quality)\n\n[1] 0.4916226"
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#description",
    "href": "fabricatr/reference/draw_discrete.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nDrawing discrete data based on probabilities or latent traits is a common task that can be cumbersome. Each function in our discrete drawing set creates a different type of discrete data: draw_binary creates binary 0/1 data, draw_binomial creates binomial data (repeated trial binary data), draw_categorical creates categorical data, draw_ordered transforms latent data into observed ordered categories, draw_count creates count data (poisson-distributed)."
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#usage",
    "href": "fabricatr/reference/draw_discrete.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_binomial(\n  prob = link(latent),\n  trials = 1,\n  N = length(prob),\n  latent = NULL,\n  link = \"identity\",\n  quantile_y = NULL\n)\n\ndraw_categorical(\n  prob = link(latent),\n  N = NULL,\n  latent = NULL,\n  link = \"identity\",\n  category_labels = NULL\n)\n\ndraw_ordered(\n  x = link(latent),\n  breaks = c(-1, 0, 1),\n  break_labels = NULL,\n  N = length(x),\n  latent = NULL,\n  strict = FALSE,\n  link = \"identity\"\n)\n\ndraw_count(\n  mean = link(latent),\n  N = length(mean),\n  latent = NULL,\n  link = \"identity\",\n  quantile_y = NULL\n)\n\ndraw_binary(\n  prob = link(latent),\n  N = length(prob),\n  link = \"identity\",\n  latent = NULL,\n  quantile_y = NULL\n)\n\ndraw_quantile(type, N)"
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#arguments",
    "href": "fabricatr/reference/draw_discrete.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nprob\nA number or vector of numbers representing the probability for binary or binomial outcomes; or a number, vector, or matrix of numbers representing probabilities for categorical outcomes. If you supply a link function, these underlying probabilities will be transformed.\n\n\ntrials\nfor draw_binomial, the number of trials for each observation\n\n\nN\nnumber of units to draw. Defaults to the length of the vector of probabilities or latent data you provided.\n\n\nlatent\nIf the user provides a link argument other than identity, they should provide the variable latent rather than prob or mean\n\n\nlink\nlink function between the latent variable and the probability of a positive outcome, e.g. “logit”, “probit”, or “identity”. For the “identity” link, the latent variable must be a probability.\n\n\nquantile_y\nA vector of quantiles; if provided, rather than drawing stochastically from the distribution of interest, data will be drawn at exactly those quantiles.\n\n\ncategory_labels\nvector of labels for the categories produced by draw_categorical. If provided, must be equal to the number of categories provided in the prob argument.\n\n\nx\nfor draw_ordered, the latent data for each observation.\n\n\nbreaks\nvector of breaks to cut a latent outcome into ordered categories with draw_ordered\n\n\nbreak_labels\nvector of labels for the breaks to cut a latent outcome into ordered categories with draw_ordered. (Optional)\n\n\nstrict\nLogical indicating whether values outside the provided breaks should be coded as NA. Defaults to FALSE, in which case effectively additional breaks are added between -Inf and the lowest break and between the highest break and Inf.\n\n\nmean\nfor draw_count, the mean number of count units for each observation\n\n\ntype\nThe number of buckets to split data into. For a median split, enter 2; for terciles, enter 3; for quartiles, enter 4; for quintiles, 5; for deciles, 10."
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#details",
    "href": "fabricatr/reference/draw_discrete.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nFor variables with intra-cluster correlations, see draw_binary_icc and draw_normal_icc"
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#value",
    "href": "fabricatr/reference/draw_discrete.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of data in accordance with the specification; generally numeric but for some functions, including draw_ordered and draw_categorical, may be factor if labels are provided."
  },
  {
    "objectID": "fabricatr/reference/draw_discrete.html#examples",
    "href": "fabricatr/reference/draw_discrete.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Drawing binary values (success or failure, treatment assignment)\nfabricate(N = 3,\n   p = c(0, .5, 1),\n   binary = draw_binary(prob = p))\n\n  ID   p binary\n1  1 0.0      0\n2  2 0.5      1\n3  3 1.0      1\n\n# Drawing binary values with probit link (transforming continuous data\n# into a probability range).\nfabricate(N = 3,\n   x = 10 * rnorm(N),\n   binary = draw_binary(latent = x, link = \"probit\"))\n\n  ID           x binary\n1  1  -0.2451297      0\n2  2  -2.2475392      0\n3  3 -12.7678869      0\n\n# Repeated trials: `draw_binomial`\nfabricate(N = 3,\n   p = c(0, .5, 1),\n   binomial = draw_binomial(prob = p, trials = 10))\n\n  ID   p binomial\n1  1 0.0        0\n2  2 0.5        2\n3  3 1.0       10\n\n# Ordered data: transforming latent data into observed, ordinal data.\n# useful for survey responses.\nfabricate(N = 3,\n   x = 5 * rnorm(N),\n   ordered = draw_ordered(x = x,\n                          breaks = c(-Inf, -1, 1, Inf)))\n\n  ID          x ordered\n1  1 -0.6319608       2\n2  2 -4.3211035       1\n3  3  4.8184164       3\n\n# Providing break labels for latent data.\nfabricate(N = 3,\n   x = 5 * rnorm(N),\n   ordered = draw_ordered(x = x,\n                          breaks = c(-Inf, -1, 1, Inf),\n                          break_labels = c(\"Not at all concerned\",\n                                           \"Somewhat concerned\",\n                                           \"Very concerned\")))\n\n  ID          x              ordered\n1  1 -2.9002914 Not at all concerned\n2  2 -5.3191583 Not at all concerned\n3  3  0.6268772   Somewhat concerned\n\n# Count data: useful for rates of occurrences over time.\nfabricate(N = 5,\n   x = c(0, 5, 25, 50, 100),\n   theft_rate = draw_count(mean=x))\n\n  ID   x theft_rate\n1  1   0          0\n2  2   5          2\n3  3  25         22\n4  4  50         50\n5  5 100         96\n\n# Categorical data: useful for demographic data.\nfabricate(N = 6, p1 = runif(N), p2 = runif(N), p3 = runif(N),\n          cat = draw_categorical(cbind(p1, p2, p3)))\n\n  ID         p1         p2        p3 cat\n1  1 0.84973536 0.94105428 0.2854143   1\n2  2 0.19031883 0.16938531 0.2278315   2\n3  3 0.70778305 0.68202877 0.2898533   2\n4  4 0.55710534 0.85035415 0.2831689   1\n5  5 0.69514385 0.09938267 0.7537506   3\n6  6 0.02015851 0.83851009 0.4489346   2"
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#description",
    "href": "fabricatr/reference/draw_normal_icc.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nData is generated to ensure inter-cluster correlation 0, intra-cluster correlation in expectation ICC. The data generating process used in this function is specified at the following URL: https://stats.stackexchange.com/questions/263451/create-synthetic-data-with-a-given-intraclass-correlation-coefficient-icc"
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#usage",
    "href": "fabricatr/reference/draw_normal_icc.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\ndraw_normal_icc(\n  mean = 0,\n  N = NULL,\n  clusters,\n  sd = NULL,\n  sd_between = NULL,\n  total_sd = NULL,\n  ICC = NULL\n)"
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#arguments",
    "href": "fabricatr/reference/draw_normal_icc.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nmean\nA number or vector of numbers, one mean per cluster. If none is provided, will default to 0.\n\n\nN\n(Optional) A number indicating the number of observations to be generated. Must be equal to length(clusters) if provided.\n\n\nclusters\nA vector of factors or items that can be coerced to clusters; the length will determine the length of the generated data.\n\n\nsd\nA number or vector of numbers, indicating the standard deviation of each cluster’s error terms – standard deviation within a cluster (default 1)\n\n\nsd_between\nA number or vector of numbers, indicating the standard deviation between clusters.\n\n\ntotal_sd\nA number indicating the total sd of the resulting variable. May only be specified if ICC is specified and sd and sd_between are not.\n\n\nICC\nA number indicating the desired ICC."
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#details",
    "href": "fabricatr/reference/draw_normal_icc.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nThe typical use for this function is for a user to provide an ICC and, optionally, a set of within-cluster standard deviations, sd. If the user does not provide sd, the default value is 1. These arguments imply a fixed between-cluster standard deviation.\nAn alternate mode for the function is to provide between-cluster standard deviations, sd_between, and an ICC. These arguments imply a fixed within-cluster standard deviation.\nIf users provide all three of ICC, sd_between, and sd, the function will warn the user and use the provided standard deviations for generating the data."
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#value",
    "href": "fabricatr/reference/draw_normal_icc.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\nA vector of numbers corresponding to the observations from the supplied cluster IDs."
  },
  {
    "objectID": "fabricatr/reference/draw_normal_icc.html#examples",
    "href": "fabricatr/reference/draw_normal_icc.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n# Divide observations into clusters\nclusters = rep(1:5, 10)\n\n# Default: unit variance within each cluster\ndraw_normal_icc(clusters = clusters, ICC = 0.5)\n\n [1]  1.94331079 -0.96994217 -0.03740455 -0.50641854  0.22915295  1.09459464\n [7] -1.53020333 -1.28439635  1.57461138 -1.71442341  1.10620718 -0.71155915\n[13]  2.43332041  0.42872400 -1.58906854  3.00405859 -1.10561823  2.17070962\n[19]  0.81525783 -2.37788168  1.79430783 -0.07221708  0.73817500 -0.23465696\n[25]  0.23569840  3.10762763 -0.26702426  2.66028847  0.25847046 -2.63027776\n[31]  0.71780291  0.61426398  2.10753022  0.51584316 -2.67871857  2.52020372\n[37] -0.29870222  1.17181948  2.58787596 -1.89875512  2.56689612 -0.83133502\n[43]  1.47217751 -0.15361899 -2.19157101  3.30556993 -1.51892448  0.25711603\n[49] -0.14535512  0.65049150\n\n# Alternatively, you can specify characteristics:\ndraw_normal_icc(mean = 10, clusters = clusters, sd = 3, ICC = 0.3)\n\n [1] 13.018636  7.555642 14.906395  7.553256 11.778107  9.410019  4.288185\n [8]  7.834565 12.928636 15.466757  9.253184  8.080917 12.783682 11.345818\n[15]  9.549029 12.027705 10.601301  8.461624 14.165417 13.879291  7.376901\n[22] 10.659945 11.616436 11.673308  8.714120 11.087640  9.861759 13.175906\n[29] 13.674047 14.651397 14.562328  7.049779 13.351934 13.674587  9.416164\n[36] 14.435027 10.887002 10.597196  6.762654 13.876267 13.372188  5.912389\n[43]  9.995285 12.766256 10.970058 12.126394  6.586016 16.942169  7.258686\n[50] 11.826078\n\n# Can specify between-cluster standard deviation instead:\ndraw_normal_icc(clusters = clusters, sd_between = 4, ICC = 0.2)\n\n [1]   1.86332579   2.67839800   2.57583482  -9.00379494  -5.46591757\n [6]   3.30171016 -11.78949261  -1.75196225  -5.88981408 -10.03575998\n[11]   2.96161830  -6.48422280 -15.25345162 -13.75415105   5.83011146\n[16]   6.89301066   1.01541752  -3.06940628 -12.95598020  15.30988555\n[21]   1.88761161  -1.67072344   0.06578878   1.45771005   4.29441622\n[26]  11.24618786   4.02100693   3.06037433  -8.59114142   4.38459465\n[31] -14.14014473  13.56735299  17.54493212 -21.72993263  -3.49790217\n[36]  -8.90897520   9.40143522  -3.32762387  -8.05781746  -1.07617383\n[41]   3.23365478  10.96437273  -2.77605940  10.78696489  13.55319165\n[46]  -5.30966454  16.56052317  11.84206778   9.66818197   0.88086918\n\n# Can specify total SD instead:\ntotal_sd_draw = draw_normal_icc(clusters = clusters, ICC = 0.5, total_sd = 3)\nsd(total_sd_draw)\n\n[1] 3\n\n# Verify that ICC generated is accurate\ncorr_draw = draw_normal_icc(clusters = clusters, ICC = 0.4)\nsummary(lm(corr_draw ~ as.factor(clusters)))$r.squared\n\n[1] 0.1391724"
  },
  {
    "objectID": "fabricatr/reference/potential_outcomes.html#description",
    "href": "fabricatr/reference/potential_outcomes.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nFunction to draw multiple potential outcomes, one for each condition that an assignment variable can be set to."
  },
  {
    "objectID": "fabricatr/reference/potential_outcomes.html#usage",
    "href": "fabricatr/reference/potential_outcomes.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\npotential_outcomes(x, conditions = list(Z = c(0, 1)), sep = \"_\")"
  },
  {
    "objectID": "fabricatr/reference/potential_outcomes.html#arguments",
    "href": "fabricatr/reference/potential_outcomes.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nx\nFormula describing the potential outcomes with the outcome name on the left hand side and the expression describing the potential outcomes on the right hand side, e.g. Y ~ 0.1 * Z + rnorm(N) (this would draw two potential outcomes columns by default, named Y_Z_0 and Y_Z_1).\n\n\nconditions\nA list of conditions for each assignment variable. Defaults to list(Z = c(0, 1)).\n\n\nsep\nSeparator inserted between the outcome name and the assignment variable name used to construct the potential outcome variable names, defaults to “_“."
  },
  {
    "objectID": "fabricatr/reference/potential_outcomes.html#examples",
    "href": "fabricatr/reference/potential_outcomes.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\nfabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z + U)\n)\n\n   ID          U      Y_Z_0      Y_Z_1\n1  01 -0.2804221 -0.2804221 -0.1804221\n2  02  0.7762108  0.7762108  0.8762108\n3  03  0.5030595  0.5030595  0.6030595\n4  04 -1.6267495 -1.6267495 -1.5267495\n5  05 -1.0636129 -1.0636129 -0.9636129\n6  06 -0.5932992 -0.5932992 -0.4932992\n7  07 -1.4174494 -1.4174494 -1.3174494\n8  08 -1.0743653 -1.0743653 -0.9743653\n9  09  1.1486946  1.1486946  1.2486946\n10 10  1.5240508  1.5240508  1.6240508\n\n# equivalently,\n\nfabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z + U,\n                     conditions = list(Z = c(0, 1)))\n)\n\n   ID          U      Y_Z_0      Y_Z_1\n1  01 -0.5286643 -0.5286643 -0.4286643\n2  02  0.1047319  0.1047319  0.2047319\n3  03  0.8227429  0.8227429  0.9227429\n4  04 -2.1092076 -2.1092076 -2.0092076\n5  05 -0.4076128 -0.4076128 -0.3076128\n6  06 -0.5196155 -0.5196155 -0.4196155\n7  07 -0.4151714 -0.4151714 -0.3151714\n8  08  0.2683332  0.2683332  0.3683332\n9  09  1.3093935  1.3093935  1.4093935\n10 10  0.1004437  0.1004437  0.2004437\n\nfabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z + U,\n                     conditions = list(Z = c(1, 2, 3)))\n)\n\n   ID          U      Y_Z_1      Y_Z_2      Y_Z_3\n1  01  0.2310970  0.3310970  0.4310970  0.5310970\n2  02  0.3073578  0.4073578  0.5073578  0.6073578\n3  03  0.6145827  0.7145827  0.8145827  0.9145827\n4  04 -1.2106218 -1.1106218 -1.0106218 -0.9106218\n5  05 -1.4503478 -1.3503478 -1.2503478 -1.1503478\n6  06  0.5745316  0.6745316  0.7745316  0.8745316\n7  07  1.3825604  1.4825604  1.5825604  1.6825604\n8  08 -1.2499109 -1.1499109 -1.0499109 -0.9499109\n9  09  0.8178814  0.9178814  1.0178814  1.1178814\n10 10 -0.4730953 -0.3730953 -0.2730953 -0.1730953\n\nfabricate(\n  N = 10,\n  U = rnorm(N),\n  potential_outcomes(Y ~ 0.1 * Z1 + 0.3 * Z2 + 0.5 * Z1 * Z2 + U,\n                     conditions = list(Z1 = c(0, 1),\n                                       Z2 = c(0, 1)))\n)\n\n   ID          U Y_Z1_0_Z2_0 Y_Z1_1_Z2_0 Y_Z1_0_Z2_1 Y_Z1_1_Z2_1\n1  01  0.1864213   0.1864213   0.2864213  0.48642135   1.0864213\n2  02  2.1992658   2.1992658   2.2992658  2.49926581   3.0992658\n3  03  1.1608165   1.1608165   1.2608165  1.46081652   2.0608165\n4  04  0.1510191   0.1510191   0.2510191  0.45101909   1.0510191\n5  05 -0.6628564  -0.6628564  -0.5628564 -0.36285641   0.2371436\n6  06  0.6622574   0.6622574   0.7622574  0.96225740   1.5622574\n7  07  1.3408303   1.3408303   1.4408303  1.64083025   2.2408303\n8  08  0.1729277   0.1729277   0.2729277  0.47292774   1.0729277\n9  09 -0.3995663  -0.3995663  -0.2995663 -0.09956629   0.5004337\n10 10  1.7572031   1.7572031   1.8572031  2.05720311   2.6572031"
  },
  {
    "objectID": "fabricatr/reference/fabricatr.html#description",
    "href": "fabricatr/reference/fabricatr.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nfabricatr helps you imagine your data before you collect it. Hierarchical data structures and correlated data can be easily simulated, either from random number generators or by resampling from existing data sources."
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#description",
    "href": "fabricatr/reference/fabricate.html#description",
    "title": "**Declare**Design",
    "section": "Description",
    "text": "Description\nfabricate helps you simulate a dataset before you collect it. You can either start with your own data and add simulated variables to it (by passing data to fabricate()) or start from scratch by defining N. Create hierarchical data with multiple levels of data such as citizens within cities within states using add_level() or modify existing hierarchical data using modify_level(). You can use any R function to create each variable. Use cross_levels() and link_levels() to make more complex designs such as panel or cross-classified data."
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#usage",
    "href": "fabricatr/reference/fabricate.html#usage",
    "title": "**Declare**Design",
    "section": "Usage",
    "text": "Usage\nfabricate(..., data = NULL, N = NULL, ID_label = NULL)\n\nadd_level(N = NULL, ..., nest = TRUE)\n\nmodify_level(..., by = NULL)\n\nnest_level(N = NULL, ...)"
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#arguments",
    "href": "fabricatr/reference/fabricate.html#arguments",
    "title": "**Declare**Design",
    "section": "Arguments",
    "text": "Arguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n…\nVariable or level-generating arguments, such as my_var = rnorm(N). For fabricate, you may also pass add_level() or modify_level() arguments, which define a level of a multi-level dataset. See examples.\n\n\ndata\n(optional) user-provided data that forms the basis of the fabrication, e.g. you can add variables to existing data. Provide either N or data (N is the number of rows of the data if data is provided). If data and N are not provided, fabricatr will try to interpret the first un-named argument as either data or N based on type.\n\n\nN\n(optional) number of units to draw. If provided as fabricate(N = 5), this determines the number of units in the single-level data. If provided in add_level, e.g. fabricate(cities = add_level(N = 5)), N determines the number of units in a specific level of a hierarchical dataset.\n\n\nID_label\n(optional) variable name for ID variable, e.g. citizen_ID. Set to NA to suppress the creation of an ID variable.\n\n\nnest\n(Default TRUE) Boolean determining whether data in an add_level() call will be nested under the current working data frame or create a separate hierarchy of levels. See our vignette for cross-classified, non-nested data for details.\n\n\nby\n(optional) quoted name of variable modify_level uses to split-modify-combine data by."
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#details",
    "href": "fabricatr/reference/fabricate.html#details",
    "title": "**Declare**Design",
    "section": "Details",
    "text": "Details\nWe also provide several built-in options to easily create variables, including draw_binary, draw_count, draw_likert, and intra-cluster correlated variables draw_binary_icc and draw_normal_icc"
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#value",
    "href": "fabricatr/reference/fabricate.html#value",
    "title": "**Declare**Design",
    "section": "Value",
    "text": "Value\ndata.frame"
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#examples",
    "href": "fabricatr/reference/fabricate.html#examples",
    "title": "**Declare**Design",
    "section": "Examples",
    "text": "Examples\n\nlibrary(fabricatr)\n\n\n\n# Draw a single-level dataset with a covariate\nbuilding_df <- fabricate(\n  N = 100,\n  height_ft = runif(N, 300, 800)\n)\nhead(building_df)\n\n   ID height_ft\n1 001  380.7501\n2 002  697.0140\n3 003  303.1298\n4 004  366.8833\n5 005  725.8904\n6 006  471.1371\n\n# Start with existing data instead\nbuilding_modified <- fabricate(\n  data = building_df,\n  rent = rnorm(N, mean = height_ft * 100, sd = height_ft * 30)\n)\n\n# Draw a two-level hierarchical dataset\n# containing cities within regions\nmulti_level_df <- fabricate(\n regions = add_level(N = 5),\n cities = add_level(N = 2, pollution = rnorm(N, mean = 5)))\nhead(multi_level_df)\n\n  regions cities pollution\n1       1     01  5.972396\n2       1     02  5.587705\n3       2     03  4.618506\n4       2     04  5.416547\n5       3     05  7.014910\n6       3     06  5.955847\n\n# Start with existing data and add a nested level:\ncompany_df <- fabricate(\n data = building_df,\n company_id = add_level(N=10, is_headquarters = sample(c(0, 1), N, replace=TRUE))\n)\n\n# Start with existing data and add variables to hierarchical data\n# at levels which are already present in the existing data.\n# Note: do not provide N when adding variables to an existing level\nfabricate(\n  data = multi_level_df,\n  regions = modify_level(watershed = sample(c(0, 1), N, replace = TRUE)),\n  cities = modify_level(runoff = rnorm(N))\n)\n\n   regions cities pollution watershed      runoff\n1        1     01  5.972396         0  1.35295909\n2        1     02  5.587705         1 -0.92581056\n3        2     03  4.618506         1  0.88453542\n4        2     04  5.416547         1 -1.11334984\n5        3     05  7.014910         0 -2.08102043\n6        3     06  5.955847         0 -0.08748455\n7        4     07  4.511004         1 -0.66140151\n8        4     08  4.810789         0  1.34816004\n9        5     09  4.421794         0  0.96308764\n10       5     10  5.095781         0 -0.77511441\n\n# fabricatr can add variables that are higher-level summaries of lower-level\n# variables via a split-modify-combine logic and the \\code{by} argument\n\nmulti_level_df <-\n fabricate(\n   regions = add_level(N = 5, elevation = rnorm(N)),\n   cities = add_level(N = 2, pollution = rnorm(N, mean = 5)),\n   cities = modify_level(by = \"regions\", regional_pollution = mean(pollution))\n )\n\n# fabricatr can also make panel or cross-classified data. For more\n# information about syntax for this functionality please read our vignette\n# or check documentation for \\code{link_levels}:\ncross_classified <- fabricate(\n  primary_schools = add_level(N = 50, ps_quality = runif(N, 0, 10)),\n  secondary_schools = add_level(N = 100, ss_quality = runif(N, 0, 10), nest=FALSE),\n  students = link_levels(N = 2000,\n                          by = join_using(ps_quality, ss_quality, rho = 0.5),\n                          student_quality = ps_quality + 3*ss_quality + rnorm(N)))"
  },
  {
    "objectID": "fabricatr/reference/fabricate.html#see-also",
    "href": "fabricatr/reference/fabricate.html#see-also",
    "title": "**Declare**Design",
    "section": "See Also",
    "text": "See Also\nlink_levels"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "DeclareDesign Blog",
    "section": "",
    "text": "Jan 8, 2020\n\n\nClara Bicalho, Sisi Huang, Markus Konrad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2019\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2019\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2019\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2019\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2019\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2019\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2019\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2018\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2018\n\n\nDeclare Design Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2018\n\n\nDeclareDesign Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2018\n\n\n\n\n\n\nNo matching items"
  }
]