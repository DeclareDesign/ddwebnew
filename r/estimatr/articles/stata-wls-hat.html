<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="estimatr">
<title>How Stata's hat matrix differs with weights • estimatr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="How Stata's hat matrix differs with weights">
<meta property="og:description" content="estimatr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">estimatr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/getting-started.html">Getting started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/getting-started.html">Getting started using estimatr</a>
    <a class="dropdown-item" href="../articles/absorbing-fixed-effects.html">Absorbing Fixed Effects with estimatr</a>
    <a class="dropdown-item" href="../articles/estimatr-in-the-tidyverse.html">estimatr in the Tidyverse</a>
    <a class="dropdown-item" href="../articles/benchmarking-estimatr.html">Benchmarking estimatr</a>
    <a class="dropdown-item" href="../articles/emmeans-examples.html">Examples with emmeans</a>
    <a class="dropdown-item" href="../articles/mathematical-notes.html">Mathematical notes for estimatr</a>
    <a class="dropdown-item" href="../articles/regression-tables.html">Regression Tables with estimatr</a>
    <a class="dropdown-item" href="../articles/simulations-debiasing-dim.html">Simulations - Debiasing Difference-in-Means</a>
    <a class="dropdown-item" href="../articles/simulations-ols-variance.html">Simulations - OLS and Variance</a>
    <a class="dropdown-item" href="../articles/stata-wls-hat.html">How Stata's hat matrix differs with weights</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-software">Software</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-software">
    <a class="external-link dropdown-item" href="http://declaredesign.org/r/declaredesign/">DeclareDesign</a>
    <a class="external-link dropdown-item" href="https://declaredesign.org/r/randomizr/">randomizr</a>
    <a class="external-link dropdown-item" href="https://declaredesign.org/r/fabricatr/">fabricatr</a>
    <a class="dropdown-item" href="https://declaredesign.org/r/estimatr/">estimatr</a>
    <a class="external-link dropdown-item" href="https://declaredesign.org/r/designlibrary/">DesignLibrary</a>
    <a class="external-link dropdown-item" href="https://eos.wzb.eu/ipi/DDWizard/">DesignWizard</a>
  </div>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://declaredesign.org">declaredesign.org</a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="stata-wls-hat_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>How Stata's hat matrix differs with weights</h1>
                        <h4 data-toc-skip class="author">Luke Sonnet</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/DeclareDesign/estimatr/blob/HEAD/../vignettes/stata-wls-hat.Rmd" class="external-link"><code>../vignettes/stata-wls-hat.Rmd</code></a></small>
      <div class="d-none name"><code>stata-wls-hat.Rmd</code></div>
    </div>

    
    
<p>Researchers use linear regression with heteroskedasticity-robust standard errors. Many social scientists use either Stata or R. One would hope the two would always agree in their estimates. Unfortunately, estimating weighted least squares with HC2 or HC3 robust variance results in different answers across Stata and common approaches in R as well as Python.</p>
<p>The discrepancy is due to differences in how the software estimates the “hat” matrix, on which both HC2 and HC3 variance estimators rely. The short story is that Stata estimates the hat matrix as</p>
<p><span class="math display">\[
\mathbf{H} = \mathbf{X} (\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1} \mathbf{X}^\top
\]</span></p>
<p>while the usual approaches in R, including <a href="https://CRAN.R-project.org/package=sandwich" class="external-link"><code>sandwich</code></a> and <a href="/r/estimatr/"><code>estimatr</code></a>, and Python (e.g. <a href="http://www.statsmodels.org/stable/index.html" class="external-link"><code>statsmodels</code></a>) estimate the following hat matrix</p>
<p><span class="math display">\[
\mathbf{H} = \mathbf{X} (\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1} \mathbf{X}^\top \mathbf{W}
\]</span></p>
<p>This results in differences when researches estimate HC2 and HC3 variance estimators. The HC1 standard errors, Stata’s default, are the same across all packages. The rest of this document just walks through the set-up for the above and demonstrates some results from Stata, R, and Python.</p>
<div class="section level3">
<h3 id="weighted-least-squares">Weighted least squares<a class="anchor" aria-label="anchor" href="#weighted-least-squares"></a>
</h3>
<p>Let’s briefly review WLS. Weights are used in linear regression often for two key problems; (1) to model and correct for heteroskedasticity, and (2) to deal with unequal sampling (or treatment) probabilities. In both cases, we take the standard model</p>
<p><span class="math display">\[
y_i = \mathbf{x}_i^\top \mathbf{\beta} + \epsilon_i,
\]</span></p>
<p>where <span class="math inline">\(y_i\)</span> is the <span class="math inline">\(i\)</span>th unit’s outcome, <span class="math inline">\(\mathbf{x}_i\)</span> is a column vector of covariates, <span class="math inline">\(\mathbf{\beta}\)</span> are the coefficients of interest, and <span class="math inline">\(\epsilon\)</span> is some error, and rescale the model by the square root of that unit’s weight, <span class="math inline">\(\sqrt{w_i}\)</span>. Our model then becomes</p>
<p><span class="math display">\[
\frac{y_i}{\sqrt{w_i}} = \frac{\mathbf{x}_i^\top}{\sqrt{w_i}} \mathbf{\beta} + \frac{\epsilon_i}{\sqrt{w_i}}.
\]</span></p>
<p>It can be shown that the solution for <span class="math inline">\(\mathbf{\beta}\)</span> is</p>
<p><span class="math display">\[
\widehat{\mathbf{\beta}} = (\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1} \mathbf{X}^\top \mathbf{W} \mathbf{y},
\]</span></p>
<p>where <span class="math inline">\(\mathbf{W}\)</span> is a diagonal matrix where each entry is <span class="math inline">\(w_{i}\)</span>, <span class="math inline">\(\mathbf{X}\)</span> is the covariate matrix, and <span class="math inline">\(\mathbf{y}\)</span> is the outcome column vector. Note that all weights have been scaled to sum to 1 (i.e., <span class="math inline">\(\sum_i w_{ii} = 1\)</span>). An easy way to get to compute <span class="math inline">\(\widehat{\mathbf{\beta}}\)</span> is to first weight both <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> by <span class="math inline">\(\mathbf{W}^s\)</span>, which is simply the weight matrix but using instead the square root of the weights. Let’s define these rescaled matrices as</p>
<p><span class="math display">\[
\begin{aligned}
\widetilde{\mathbf{X}} &amp;= \mathbf{X} \mathbf{W}^s \\
\widetilde{\mathbf{y}} &amp;= \mathbf{W}^s \mathbf{y}
\end{aligned}
\]</span></p>
</div>
<div class="section level3">
<h3 id="heteroskedastic-consistent-variance-estimators">Heteroskedastic-consistent variance estimators<a class="anchor" aria-label="anchor" href="#heteroskedastic-consistent-variance-estimators"></a>
</h3>
<p>Turning to variance, the standard sandwich estimator is</p>
<p><span class="math display">\[
\mathbb{V}[\widehat{\mathbf{\beta}}] = (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{X}^\top \Omega \mathbf{X} (\mathbf{X}^{\top}\mathbf{X})^{-1}
\]</span></p>
<p>where <span class="math inline">\(\Omega\)</span> represents <span class="math inline">\(\mathbb{E}[\mathbf{\epsilon}\mathbf{\epsilon}^\top]\)</span>, the variance-covariance matrix of the disturbances. A nice review of the different variance estimators along with their properties can be found in <span class="citation">Long and Ervin (<a href="#ref-longervin2000" role="doc-biblioref">2000</a>)</span> <a href="http://www.indiana.edu/~jslsoc/files_research/testing_tests/hccm/99TAS.pdf" class="external-link">[ungated]</a>. The HC2 and HC3 estimators, introduced by <span class="citation">MacKinnon and White (<a href="#ref-mackinnonwhite1985" role="doc-biblioref">1985</a>)</span>, use the hat matrix as part of the estimation of <span class="math inline">\(\Omega\)</span>. The standard hat matrix is written:</p>
<p><span class="math display">\[
\mathbf{H} = \mathbf{X} (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{X}^\top
\]</span></p>
<p>Where <span class="math inline">\(h_{ii}\)</span> are the diagonal elements of the hat matrix, the HC2 variance estimator is</p>
<p><span class="math display">\[
\mathbb{V}[\widehat{\mathbf{\beta}}]_{HC2} = (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{X}^\top \mathrm{diag}\left[\frac{e^2_i}{1 - h_{ii}}\right] \mathbf{X} (\mathbf{X}^{\top}\mathbf{X})^{-1}  ,
\]</span></p>
<p>where <span class="math inline">\(e_i\)</span> are the residuals. The HC3 estimator is very similar,</p>
<p><span class="math display">\[
\mathbb{V}[\widehat{\mathbf{\beta}}]_{HC3} = (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{X}^\top \mathrm{diag}\left[\frac{e^2_i}{(1 - h_{ii})^2}\right] \mathbf{X} (\mathbf{X}^{\top}\mathbf{X})^{-1} .
\]</span></p>
<p>Both rely on the hat matrix. Crucially, this is where Stata and the packages and modules in R and Python disagree. When weights are specified, Stata estimates the hat matrix as</p>
<p><span class="math display">\[
\mathbf{H}_{Stata} = \mathbf{X} (\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1} \mathbf{X}^\top,
\]</span></p>
<p>while the other software uses</p>
<p><span class="math display">\[
\mathbf{H}_{R} = \mathbf{X} (\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1} \mathbf{X}^\top \mathbf{W}.
\]</span></p>
<p>Thus the HC2 and HC3 estimator differ as the values of <span class="math inline">\(h_{ii}\)</span> are quite different. How different are these results? Let’s use a little example using <code>mtcars</code> a dataset included with R.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Using estimatr</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://declaredesign.org/r/estimatr/">estimatr</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/lm_robust.html">lm_robust</a></span><span class="op">(</span></span>
<span>  <span class="va">mpg</span> <span class="op">~</span> <span class="va">hp</span>,</span>
<span>  data <span class="op">=</span> <span class="va">mtcars</span>,</span>
<span>  weights <span class="op">=</span> <span class="va">wt</span>,</span>
<span>  se_type <span class="op">=</span> <span class="st">"HC2"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;                Estimate Std. Error   t value     Pr(&gt;|t|)    CI Lower</span></span>
<span><span class="co">#&gt; (Intercept) 28.54864505 2.16281844 13.199742 4.975934e-14 24.13158053</span></span>
<span><span class="co">#&gt; hp          -0.06249413 0.01445662 -4.322872 1.561752e-04 -0.09201849</span></span>
<span><span class="co">#&gt;                CI Upper DF</span></span>
<span><span class="co">#&gt; (Intercept) 32.96570958 30</span></span>
<span><span class="co">#&gt; hp          -0.03296977 30</span></span></code></pre></div>
<p>We can also see that Python’s <a href="http://www.statsmodels.org/stable/index.html" class="external-link"><code>statsmodels</code></a> provides the same results as the methods in R (and in fact they note the difference in an <a href="https://github.com/statsmodels/statsmodels/issues/1209" class="external-link">issue on GitHub</a>).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3"></a>dat <span class="op">=</span> pd.read_csv(<span class="st">'mtcars.csv'</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a>wls_mod <span class="op">=</span> sm.WLS(dat[<span class="st">'mpg'</span>], sm.add_constant(dat[<span class="st">'hp'</span>]), weights <span class="op">=</span> dat[<span class="st">'wt'</span>])</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="bu">print</span>(wls_mod.fit().HC2_se)</span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co">#&gt; const    2.162818</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#&gt; hp       0.014457</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co">#&gt; dtype: float64</span></span></code></pre></div>
<p>If we do the same in Stata 13, we get the following output:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">insheet</span> <span class="kw">using</span> mtcars.csv</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="kw">reg</span> mpg hp [<span class="kw">aweight</span>=wt], <span class="kw">vce</span>(hc2)</span></code></pre></div>
<pre><code>Linear regression                                      Number of obs =      32
                                                       F(  1,    30) =   19.08
                                                       Prob &gt; F      =  0.0001
                                                       R-squared     =  0.5851
                                                       Root MSE      =  3.6191

------------------------------------------------------------------------------
             |             Robust HC2
         mpg |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          hp |  -.0624941   .0143083    -4.37   0.000    -.0917155   -.0332727
       _cons |   28.54865   2.155169    13.25   0.000      24.1472    32.95009
------------------------------------------------------------------------------</code></pre>
<p>Stata’s standard errors are somewhat different. The only documentation of Stata’s formula for the hat matrix can be found on the <a href="https://www.statalist.org/forums/forum/general-stata-discussion/general/329653-regress-postestimation-with-weights" class="external-link">statalist forum here</a> and nowhere in the official documentation as far as I can tell.</p>
<div class="section level4">
<h4 id="which-should-we-prefer">Which should we prefer?<a class="anchor" aria-label="anchor" href="#which-should-we-prefer"></a>
</h4>
<p>Just because Stata is not documenting their HC2 and HC3 estimator does not mean they’re wrong. Also the differences tend to be minor. In fact, it is unclear which we should prefer given that there is not a strong literature supporting one or the other. However, there are several arguments to be made for <span class="math inline">\(\mathbf{H}_{R}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>It’s the estimator you get when you weight your data by the square root of the weights (<span class="math inline">\(\mathbf{X} \rightarrow \widetilde{\mathbf{X}}\)</span> and <span class="math inline">\(\mathbf{y} \rightarrow \widetilde{\mathbf{y}}\)</span>) and fit regular ordinary least squares. If one considers the weighted model as simply a rescaled version of the unweighted model, then users should prefer <span class="math inline">\(\mathbf{H}_{R}\)</span>.</li>
<li>The diagonal of <span class="math inline">\(\mathbf{H}_{R}\)</span> are the weighted leverages <span class="citation">(Li and Valliant <a href="#ref-livalliant2009" role="doc-biblioref">2009</a>)</span>, while <span class="math inline">\(\mathbf{H}_{Stata}\)</span> would need to be weighted again for the diagonal to recover the weighted leverage.</li>
</ol>
</div>
</div>
<div class="section level3 unnumbered">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<div id="refs" class="references">
<div id="ref-livalliant2009">
<p>Li, Jianzhu, and Richard Valliant. 2009. “Survey Weighted Hat Matrix and Leverages.” <em>Survey Methodology</em> 35 (1): 15–24.</p>
</div>
<div id="ref-longervin2000">
<p>Long, J Scott, and Laurie H Ervin. 2000. “Using Heteroscedasticity Consistent Standard Errors in the Linear Regression Model.” <em>The American Statistician</em> 54 (3): 217–24. <a href="https://doi.org/10.1080/00031305.2000.10474549" class="external-link">https://doi.org/10.1080/00031305.2000.10474549</a>.</p>
</div>
<div id="ref-mackinnonwhite1985">
<p>MacKinnon, James, and Halbert White. 1985. “Some Heteroskedasticity-Consistent Covariance Matrix Estimators with Improved Finite Sample Properties.” <em>Journal of Econometrics</em> 29 (3): 305–25. <a href="https://doi.org/10.1016/0304-4076(85)90158-7" class="external-link">https://doi.org/10.1016/0304-4076(85)90158-7</a>.</p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Graeme Blair, Jasper Cooper, Alexander Coppock, Macartan Humphreys, Luke Sonnet.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
